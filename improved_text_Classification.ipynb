{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaharyar\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Based Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Based Multinomial Model\n",
    "def naiveBasedMultiNomial(trainData,trainTarget,testData):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Based Gaussian Based\n",
    "def naiveBasedGaussian(trainData,trainTarget,testData):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Naive Based Bernoulli\n",
    "def naiveBasedBernoulli(trainData,trainTarget,testData):\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stochastic \n",
    "def SGD(trainData,trainTarget,testData):\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "def SVM(trainData,trainTarget,testData,kernelparam):\n",
    "    from sklearn import svm\n",
    "    clf = svm.SVC(kernel=kernelparam)\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DecisionTree(trainData,trainTarget,testData):\n",
    "    from sklearn import tree\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RandomForest(trainData,trainTarget,testData):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN(trainData,trainTarget,testData):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    clf.fit(trainData, trainTarget)\n",
    "    prediction=clf.predict(testData)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracyMeasure(targets,prediction):\n",
    "    accuracy=np.mean(targets==prediction)\n",
    "    accuracy=accuracy*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=dict()\n",
    "classes[\"student\"]=1\n",
    "classes[\"project\"]=2\n",
    "classes[\"course\"]=3\n",
    "classes[\"faculty\"]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=dict()\n",
    "classes[\"\"]=1\n",
    "classes[\"project\"]=2\n",
    "classes[\"course\"]=3\n",
    "classes[\"faculty\"]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for train data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=\"processeddata\\\\\"\n",
    "f=open('E:\\Study\\MPhill\\Semester3\\Data\\imdb_labelled.txt' , 'r')\n",
    "data=f.readlines()\n",
    "f.close()\n",
    "trainData=[]\n",
    "trainTargets=[]\n",
    "for x in data:\n",
    "    s=x.split(\"\\t\")\n",
    "    trainData.append(s[0])\n",
    "    trainTargets.append(int(s[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainData,trainTargets,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=\"processeddata\\\\\"\n",
    "f1=open('E:\\Study\\MPhill\\Semester3\\Data\\imdb_labelled.txt' , 'r')\n",
    "data1=f1.readlines()\n",
    "f1.close()\n",
    "testData=[]\n",
    "testTargets=[]\n",
    "for x in data1:\n",
    "    s=x.split(\"\\t\")\n",
    "    testData.append(s[0])\n",
    "    testTargets.append(classes[s[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(testTargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data from scrapped file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loaderOfData(path,classes1):\n",
    "    dataSet = load_files(path,categories=classes1)\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [\"course\",\"department\",\"faculty\",\"other\",\"project\",\"staff\",\"student\"]\n",
    "#classes = [\"course\",\"faculty\",\"project\",\"student\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainData=loaderOfData('improvedData/trainData',classes)\n",
    "testData=loaderOfData('improvedData/testData',classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertTolower(data):\n",
    "    tolowerData=[]\n",
    "    for x in data:\n",
    "        tolowerData.append(x.lower())\n",
    "    return tolowerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainTargets=trainData.target\n",
    "testTargets=testData.target\n",
    "trainData=trainData.data\n",
    "testData=testData.data\n",
    "trainData=convertTolower(trainData)\n",
    "testData=convertTolower(testData)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words in Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(X_train)\n",
    "test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(train_counts)\n",
    "train_tf = tf_transformer.transform(train_counts)\n",
    "test_tf = tf_transformer.transform(test_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Sparse matrix = (700, 2420)\n",
      "Train Data Sparse matrix = (300, 2420)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Data Sparse matrix = \"+ str(train_tf.shape))\n",
    "print (\"Train Data Sparse matrix = \"+ str(test_tf.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Naive based 81.3333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict=naiveBasedMultiNomial(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Naive based \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SVM 76.3333333333\n"
     ]
    }
   ],
   "source": [
    "svmpredict=SVM(train_tf,y_train,test_tf,\"linear\")\n",
    "acc=accuracyMeasure(y_test,svmpredict)\n",
    "print \"Accuracy with SVM \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=train_tf.todense()\n",
    "Y=test_tf.todense()\n",
    "predict=naiveBasedGaussian(X,y_train,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Naive based Gaussian 75.6666666667\n"
     ]
    }
   ],
   "source": [
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Naive based Gaussian \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Naive based Bernoulli 83.0\n"
     ]
    }
   ],
   "source": [
    "predict=naiveBasedBernoulli(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Naive based Bernoulli \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Stochastic Gradient Descent 78.0\n"
     ]
    }
   ],
   "source": [
    "predict=SGD(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Stochastic Gradient Descent \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Decision Tree 68.6666666667\n"
     ]
    }
   ],
   "source": [
    "predict=DecisionTree(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Decision Tree \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Random Forest 67.3333333333\n"
     ]
    }
   ],
   "source": [
    "predict=RandomForest(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Random Forest \"+ str(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Neural Network 49.0\n"
     ]
    }
   ],
   "source": [
    "predict=NN(train_tf,y_train,test_tf)\n",
    "acc=accuracyMeasure(y_test,predict)\n",
    "print \"Accuracy with Neural Network \"+ str(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countword(data):\n",
    "    totalword=0;\n",
    "    for x in data:\n",
    "        f=x.split(' ')\n",
    "        totalword=totalword+len(f)\n",
    "    return totalword\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372009\n"
     ]
    }
   ],
   "source": [
    "#total word in traindata\n",
    "print countword(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188006\n"
     ]
    }
   ],
   "source": [
    "#total word in test data\n",
    "print countword(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unique words in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countUnique(data):\n",
    "    a=set(data[0].split(' '))\n",
    "    for x in data:\n",
    "        f=x.split(' ')\n",
    "        b=set(f)\n",
    "        a=a.union(b)\n",
    "\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unique word in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8035\n"
     ]
    }
   ],
   "source": [
    "trdata=countUnique(trainData)\n",
    "print len(trdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#overall unique word in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5281\n"
     ]
    }
   ],
   "source": [
    "tedata=countUnique(testData)\n",
    "print(len(tedata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trdata.union(tedata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4199"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testData)+len(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shaharyar'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"SHAHARYAR\"\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
