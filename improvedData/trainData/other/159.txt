MIME Version Server CERN Date Monday Dec GMT Content Type text html Content Length Last Modified Tuesday Feb GMT How Scribe How Scribe This page should provide enough information get you started Unfortunately LaTeX can complicated and has many options are unable provide reference the LaTeX system itself What provided commented version the third lecture scribe notes This consists few parts lec tex this the main LaTeX Document similiar the main file program describes the text the document can include other files and details how other files should linked make the final postscript output graph eps and barn scene eps these are the figures seen the document EPS stands for ecapsulated postscript Figures can created number ways Most people will create figures for the first homework converting PGM format pictures EPS using the pnmtops program xfig useful program create drawings lec the final output postscript file You should first look the file lec tex Comments the source begin with symbol Typically you will edit this file that contains your notes Then you can compile the LaTeX file for example latex lec tex This will create few files including lec aux lec log and lec dvi The important file lec dvi this contains the formatted text You can view this file using the xdvi program This file will not include any EPS figures that you might add you will need run dvips lec lec dvi create the final postscript file lec Submissions Eventually your going have turn the mess What need the final postscript file the LaTeX file and the EPS files for any the figures you created you have account the sunlab systems you can just email the locations jmiller cornell edu otherwise you will have mail uuencoded tar file the files References Introduction LaTeX Guide LaTeX LaTeX Commands MIME Version Server CERN Date Tuesday Jan GMT Content Type text html Content Length Last Modified Friday Dec GMT LESS Research AgendaLaboratory for Experimental Software Systems Research AgendaThe Laboratory for Experimental Software Systems LESS the University Texas Austin Department Computer Sciences was formed September four new faculty members Lorenzo Alvisi Robert Blumofe Mike Dahlin and Calvin Lin aggregate resources and promote collaboration research experimental software systems particularly the areas programming support and fault tolerance for cluster and web based applications This document gives brief overview research being conducted the LESS lab Fault tolerant parallel computing with distributed shared memory Alvisi and Blumofe Prior work has shown that the combination well structured parallel programming model the randomized work stealing scheduling algorithm and the dag consistency coherence model distributed shared memory combination that form the basis for the Cilk parallel language and runtime system yields efficient and predictable performance both theory and practice Furthermore claim that using end end design algorithmic properties this combination can leveraged make such system fault tolerant with extremely low overhead and without redundant computation except during recovery propose use combination two new techniques return transactions and causal logging reconciles that take advantage the following key algorithmic property the well structuring work stealing and dag consistency combination When procedure activation stolen all modifications made shared memory the stolen activation and all its descendants not need seen any other extant activation except for the stolen activation parent Moreover these modifications not need seen the parent until after the stolen activation returns The return transactions technique uses this fact turn each stolen activation into atomic transaction This technique coupled with uncoordinated checkpoints has already been shown effective for functional programming model general however with distributed shared memory this technique not sufficient requires that all modifications shared memory made stolen activation and all its descendants are buffered create atomic transaction when the stolen activation returns avoid potentially huge amounts buffering causal logging reconciles will use causal message logging techniques allow modifications shared memory flushed reconciled backing store even before the stolen activation returns general causal message logging requires that extra information fixed size piggy backed each message that effectively logs the message without requiring synchronous write stable storage With well structuring work stealing and dag consistency however this logging only needs done for specific subset the reconcile messages and this overhead can amortized against the cost work stealing Reliable parallel scientific subroutine libraries Blumofe Traditionally parallel scientific subroutine libraries such various parallel implementations the Basic Linear Algebra Subroutines BLAS have been coded statically partitioning work among static set processes threads This approach has been very successful for traditional parallel platforms which each program runs static set effectively dedicated processors With the growing use and acceptance SMPs and clusters for parallel computation however this assumption dedicated resources longer valid and has been shown that applications and libraries coded with static partitioning have very unreliable performance when run non dedicated resources the other hand has been shown that using wait free synchronization techniques and dynamic partitioning such with work stealing performance becomes very reliable make this point propose code and make available set libraries including BLAS for SMPs and later clusters that use these techniques deliver reliable and predictable performance shared resources wFS adaptive data framework for web computing Dahlin Although increasing amount valuable data resides the web current browser centric data access protocols limit its use This project seeks provide stronger cache consistency and data update guarantees that will enable new classes web based applications Because the physical characteristics the Internet make expensive provide some these guarantees wFS will pursue adaptive and application specific approach The system will provide range consistency and update options with different guarantees and different costs and applications will pay for only the guarantees that they require For example web browser may emphasize scalability and continue use the current read only and weak cache consistency approach Conversely distributed parallel computation may require transactional updates and strict cache consistency even these guarantees limit its scalability few hundred nodes Two key aspects the project will providing framework for instantiating different consistency and update algorithms under common interface and providing quantitative criteria that applications can use select appropriate algorithms Lightweight fault tolerance Alvisi and Vin The objective this research support and enable new class truly distributed and fault tolerant applications which distributed agents communicate through messages well files Our proposed lightweight fault tolerance will have the following properties will integrate with applications way that transparent the application programmer Its use will require few additional resources and have negligible impact performance during failure free executions Its cost will very low for the most common failures and will scale depending the severity and number failures that need tolerated will address software generated faults effectively achieve transparency plan engineer our solution middleware minimize dedicated resources plan use rollback recovery techniques minimize the impact application performance and scale the cost our solution with the number failures that need tolerated plan use causal logging Using current techniques tolerating hardware generated faults possible but the cost potentially forcing the application block for every operation while data critical recovery are logged stable storage Specifically one cannot assume that file read during the execution will still available its original form during recovery Hence input from the file system must synchronously logged stable storage Furthermore since the file system general cannot roll back the application must delay output the file system until executes output commit protocol which requires synchronous logging stable storage Tolerating transient software generated faults the called Heisenbugs through rollback based techniques becomes more problematic well since frequent writes the file system can limit the extent which process can roll back address these problems the middleware that plan build will present the file system the application not detached component the external environment but integrated partner that can trusted provide the data needed during recovery expect that this will drastically reduce the costs incurred the application performing file Specifically our solution will have the following benefits Avoid synchronous logging input data client fails the middleware and the file system cooperate guarantee that during recovery the client will receive the same data received before failing Avoid synchronous writes the file server due file sharing our solution clients can pass dirty data directly each other without using the file server make the data stable The middleware guarantees that any dirty data kept the volatile memory client and passed another client without first being saved the file server can regenerated during recovery fails Avoid synchronous output commit protocol before writing file The middleware and the file system cooperate guarantee that the client crashes the application state which the output was generated will never rolled back Enhance the effectiveness rollback based techniques for software fault tolerance The middleware allows client that experiences Heisenbug roll back past its last write the file system increasing the likelihood successful recovery Parallel computing the world wide web with Java Alvisi Blumofe Dahlin and Lin This project will use Java the basis for new parallel computing infrastructure called Jem pronounced gem for the world wide web The Jem language will augment Java with simple primitives express parallelism while maintaining the well structured property The Jem virtual machine runtime system will use work stealing and dag consistency and will provide transparent light weight fault tolerance described above These properties further combination with existing Java technology will allow Jem programs run across heterogeneous resources and untrusting resources Thus applications national and international importance such climate modeling can coded Jem and run reliably the aggregated resources the entire world wide web and applications corporate importance such scheduling data mining and simulation can coded Jem and run reliably the aggregated resources the enterprise intranet Back LESSLast modified December Robert Blumoferdb utexas edu Date Tue Jan GMT Server NCSA Last modified Sun Oct GMT Content type text html Content length MPI MPI for Fast MessagesMPI MPI for Fast MessagesDescriptionMPI high performance implementation MPI based port MPICH Fast Messages the Myrinet MPI latency and peak bandwidth lower latency than many commercial MPP and respectable bandwidth MPI outperforms the version MPICH for messages smaller than shown below The performance MPI shows that MPP like communication latency and bandwidth can achieved with network workstations the user level with carefully tuned messaging layers Our thanks the MPICH creators who produced MPI implementation which both efficient and portable PerformanceThe graphs below compare MPI two SPARCstation with SuperCache MPICH and MPI the IBM Documentation README file for MPI Software distributions MPI version for SunOS MPI version for SolarisBack CSAG home pageLast updated October webmaster Date Tue Nov GMT Server NCSA Content type text html Last modified Tue Nov GMT Content length Architecture Seminar Schedule Computer Architecture Colloquium Architecture colloquia will held Tue unless specified otherwise Click the title talk view the abstract available DateSpeakerTitle Sep Nothing scheduled Nothing scheduled Sep Mark Hill James Larus David Wood Tempest Substrate for Portable Parallel Programs Sep Guri Sohi Computing with billion transistor chips Sep Toshiyuki Shimizu Parallel Server Oct Andy Glew Logical Circuit Speed Limits Oct Oct Jim Smith Prediction and Speculation Current Status and Future Directions Oct Oct Todd Austin Microprocessor Research Challenges Nov Eric Rotenberg Assigning Confidence Conditional Branch Predictions Nov Alain Kagi TBA Nov Dan Scales Shasta Low Overhead Software Only Approach for Supporting Fine Grain Shared Memory Nov Ioannis Schoinas TBA Nov Subbarao Palacharla TBA Dec MICRO Dec Doug Burger Design Issues for Future Chip Memory Hierarchies Dec Stefanos Kaxiras TBA Announced ECE Architecture Seminars This page was created Vijaykumar University Wisconsin Madison Computer Sciences Department Last modified vijay wisc edu Tue Sep CST 