MIME Version Server CERN Date Monday Nov GMT Content Type text html Content Length Last Modified Tuesday Nov GMT SimLab Release SimLab Software Release Includes Algebra Topology and Mesh Generator This the initial release the SimLab software This release includes mathematical functionality for algebraic and topological computations Weyl well code using Weyl for creating guaranteed quality triangulations planar areas How get the SimLab software Implemented using the Common Lisp Object System CLOS Common Lisp the release available ftp compressed gzip tar file bytes together with plain text file README bytes that describes how install the software These are files are available via FTP the site ftp cornell edu the directory pub simlab release README and simlab tar illustration the mesh generation application The purpose mesh generation algorithm take input the boundary region space and create output triangulation This process required for variety numerical modeling methods such the finite element method FEM The quality given triangulation can measured variety ways and important for maintaining the numeric stability the algorithm such FEM that use the mesh The SimLab code for mesh generation described here created Paul Chew provides bounds the minimum and maximum angles the triangles the mesh The process creating guaranteed quality mesh illustrated the following figures The first figure illustrates the input The boundary the region drawn black while the region for which mesh required the area shown green The Input The guaranteed quality mesh created the automatic mesh generator shown below The Output For more information this use the SimLab software see the MADEFAST pages All code copyrighted Cornell University This code has been developed Paul Chew Paul Jackson Sekhar Muddana Rick Palmer Todd Wilson and Richard Zippel the Simlab group Cornell University This material NOT the Public Domain but permission copy this software redistribute and use for any purpose granted subject the restrictions and understandings described the README file contained the distribution This work was supported part the Advanced Research Projects Agency the Department Defense under ONR Contract ONR Contract and part the Army Research Office through the Mathematical Science Institute Cornell University Rick Palmer rick cornell edu Date Mon Jan GMT Server NCSA Last modified Fri Sep GMT Content type text html Content length University Texas Official Academic CalendarsOfficial Academic CalendarsLong Session Summer Session Long Session Summer Session Other University CalendarsUT Home Page Registrar Home Page Catalogs Course Schedules Administrative Directory Office Organization September Registrar Web Team Comments rgweb utxdp utexas edu Date Tue Jan GMT Server NCSA Content type text html Last modified Mon Dec GMT Content length Fortran Compiler Overview Fortran Compiler OverviewProject Leaders John Mellor Crummey and Vikram AdveParticipants Zoran Budimlic Alan Carle Kevin Cureton Gil Hansen Ken Kennedy Charles Koelbel Collin McCurdy Nat McIntosh Dejan Mircevski Nenad Nedeljkovic Mike Paleczny Ajay Sethi Yoshiki Seo Lisa Thomas Lei Zhou Parallel Compiler and Tools GroupCenter for Research Parallel ComputationRice UniversityGroup Mission Develop integrated compiler and tools support effective machine independent parallel programming Contents Compiler Goals Fortran Language Fortran Compiler Organization Compiled Examples Compiler Goals Serve extensible platform for experimental research compilation techniques and programming tools for full applications including unified treatment regular and irregular problems global strategies for computation partitioning parallelism enhancing and latency hiding transformations whole program compilation and interprocedural transformations code generation strategies that approach hand tuned performance architecture independent compilation based machine models message passing shared memory and hybrid communication models optimization the presence resource constraints programming tools that fully support abstract high level programming models Fortran Language Fortran designed support research data parallel programming High Performance Fortran HPF and explore extensions that would broaden HPF applicability enhance performance Features Fortran Fortran array syntax FORALL ALLOCATE High Performance Fortran HPF data mapping directives for regular problems ALIGN DISTRIBUTE REALIGN REDISTRIBUTE TEMPLATE PROCESSORS INDEPENDENT and HOME value based data mapping directives support irregular problems experimental support under development for parallel input output including out core array management complex data structures structured use task parallelism Fortran Compiler Organization Front End Parallelism Preliminary Communication Placement and Computation Partitioning Communication Placement Communication Refinement Code Generation Front End Purpose interpret HPF directives and compute directives affecting each statement and reference Directive Processing semantic analysis directives program infer canonical synthetic layout directives for all program variables unmentioned program directives intraprocedural flow sensitive propagation ALIGN DISTRIBUTE statements and array references Limitations November interprocedural propagation layout information Preliminary Communication Placement Purpose provide feedback the computation partitioner about where conservatively communication might needed Strategy conservatively assume all references non replicated variables may need communication hoist communication for reference the outermost loop level possible while respecting data dependences the reference its subscripts conservatively prevent communication from being hoisted out non loop iterative constructs Limitations November placement independent resource constraints support for pipelining communication achieve partial parallelism lacks dataflow placement optimization eliminate partial redundancies hide communication latency inspector placement for irregular data accesses Computation Partitioning Selection Purpose framework evaluate and select from several computation partitioning alternatives not restricted the owner computes rule Approach explicitly enumerate candidate partitioning choices and use explicit cost estimation select the best partitioning enumerate candidate choices for loop nest set loop nests example refine communication information for each candidate estimate performance each candidate load balance unimplemented communication overhead propagate computation partitionings statements and computations involving only privatizable variables Limitations November load balance not considered ignores message coalescing across loop nests communication cost estimates are very simplistic requires constant loop bounds but simplistic handling symbolics will straightforward Communication Refinement Purpose given computation partition choice compute projection the conservatively placed communication example eliminate communication for references local that eliminate redundant communication coalescing determine communication pattern perform message coalescing optimization Limitations November assume one single reaching layout per reference conservative unless single processors statement perfect alignment and same number distributed dimensions communication pattern recognition somewhat limited dataflow analysis for eliminating partial redundancies and latency hiding not yet fully place Code Generation Principal Functionality source for running example Computation partitioning transformations reduce loop bounds and insert guards where necessary example separate loop iterations that might access non local values minimize overhead from runtime locality checks example Communication generation and storage management compute data sets send recv between processor pairs generate code pack unpack buffers and send recv data example generate run time dynamic storage management cope with dynamic layouts example localize and linearize subscripts example Current Strategy Except for storage management all the code generation tasks require heavy manipulation integer sets especially for compiling regular applications for distributed memory machines Examples data send recieve for particular reference given its computation partition processor loop iterations that access local non local data Current implementation uses the Omega library University Maryland arbitrary integer sets rich language for mappings between sets almost complete set operations sets and mappings union intersection difference inverse composition good code generation and optimization code generation slow limited support for symbolics Limitations November run time resolution guards currently handle only one all processors per dynamic statement instance lack library support for dynamic remapping current localization and linearization strategy produces general but slow code Compiled Examples simple shift kernel HPF MPI Jacobi iteration HPF MPI Livermore explicit hydrodynamics kernel HPF MPI Non owner computes partitioning fragmenthttp www rice edu mpal index html 