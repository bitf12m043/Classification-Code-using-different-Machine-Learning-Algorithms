MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Tuesday Mar GMT This Month Favorites This Month Favorites Favorite Vegetable Cabbage All pounds looks like cabbage going next month favorite vegetable too Sigh Favorite Tune Telemann Oboe Concerto minor Favorite Quote Prof Langevin There special French word for that course all French words are special Favorite Flavor Wombat Fudge Favorite Place Williamsport pierce cornell edu MIME Version Server CERN Date Monday Jan GMT Content Type text html Content Length Last Modified Monday Aug GMT Papers view paper click the open book image Uncertain Reasoning Refinement Bayesian Networks Combining Connectionist and Symbolic Techniques Sowmya Ramanchandran proposal Department Computer Sciences University Texas Austin Bayesian networks provide mathematically sound formalism for representing and reasoning with uncertain knowledge and are such widely used However acquiring and capturing knowledge this framework difficult There growing interest formulating techniques for learning Bayesian networks inductively While the problem learning Bayesian network given complete data has been explored some depth the problem learning networks with unobserved causes still open this proposal view this problem from the perspective theory revision and present novel approach which adapts techniques developed for revising theories symbolic and connectionist representations Thus assume that the learner given initial approximate network usually obtained from expert Our technique inductively revises the network fit the data better Our proposed system has two components one component revises the parameters Bayesian network known structure and the other component revises the structure the network The component for parameter revision maps the given Bayesian network into multi layer feedforward neural network with the parameters mapped weights the neural network and uses standard backpropagation techniques learn the weights The structure revision component uses qualitative analysis suggest revisions the network when fails predict the data accurately The first component has been implemented and will present results from experiments real world classification problems which show our technique effective will also discuss our proposed structure revision algorithm our plans for experiments evaluate the system well some extensions the system Revising Bayesian Network Parameters Using Backpropagation Sowmya Ramachandran and Raymond Mooney appear the Proceedings the International Conference Neural Networks ICNN Washington June Special Session Knowledge Based Artificial Neural Networks The problem learning Bayesian networks with hidden variables known hard problem Even the simpler task learning just the conditional probabilities Bayesian network with hidden variables hard this paper present approach that learns the conditional probabilities Bayesian network with hidden variables transforming into multi layer feedforward neural network ANN The conditional probabilities are mapped onto weights the ANN which are then learned using standard backpropagation techniques avoid the problem exponentially large ANNs focus Bayesian networks with noisy and noisy and nodes Experiments real world classification problems demonstrate the effectiveness our technique Qualitative Modeling Diagnosis Learning Qualitative Models for Systems with Multiple Operating Regions Sowmya Ramachandran Raymond Mooney and Benjamin Kuipers Proceedings the Eight International Workshop Qualitative Reasoning about Physical Systems Nara Japan June The problem learning qualitative models physical systems from observations its behaviour has been addressed several researchers recent years Most current techniques limit themselves learning single qualitative differential equation model the entire system However many systems have several qualitative differential equations underlying them this paper present approach learning the models for such systems Our technique divides the behaviours into segments each which can explained single qualitative differential equation The qualitative model for each segment can generated using any the existing techniques for learning single model show that results applying our technique several examples and demonstrate that effective Neural Networks Information Measure Based Skeletonisation Sowmya Ramachandran and Lorien PrattAdvances Neural Information Processing Systems Vol Denver Colorado Automatic determination proper neural network topology trimming over sized networks important area study which has previously been addressed using variety techniues this paper present Information Based Skeletonisation IMBS new approach this problem where superfluous hidden units are removed based their information measure This measure borrowed from decision ttree induction techniques refelcts the degree which the hyperplane formed hidden unit discriminates between training data classes show the results applying IMBS three classification tasks and demonstrate that removes substantial number hidden units without significantly affecting network performance Date Tue Jan GMT Server Apache Content type text html Content length Last modified Sun Dec GMT CAVE Line PublicationsPUBLICATIONSPhysics Based VisionFeature Detection Shape Recovery and Model AcquisitionVisual Learning and RecognitionReal Time Vision Sensors and Systems WebMaster Date Tue Nov GMT Server NCSA Content type text html Last modified Mon Oct GMT Content length Error Warning CodesAssignment Error Warning Codes Code Meaning comments output Program didn work Failed check return values from system calls Didn convert from network order Didn use gethostbyname Didn have correct packet structure int not always bytes Sent packet without removing gaps Used pointer cast memcpy for extracting data Sent entire object structure packet Invalid requests not handled properly Didn initialize length sockaddr structure before recvfrom Make failed Make generated unexplained warnings points were deducted for these warnings Sending bytes everytime even when the string field less than bytes Using perror all places not just after system calls library functions Sendto recvfrom should not fail EINTR Should not hardwire client return address Server exits receiving invalid requests 