MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Monday May GMT Fine Grain Parallel RIVLFine Grain Parallel RIVL Step Towards Real Time Multimedia ProcessingJonathan Barber barber cornell edu Sugata Mukhopadhyay sugata cornell edu Final ProjectProfessor Thorsten von EickenDepartment Computer ScienceCornell University Table Contents Abstract Introduction RIVL and the Generic Parallel Paradigm The RIVL Graph Parallelizing RIVL Continuous Media Parallel RIVL Implementations Shared Memory Implementation Networked Implementation Implementation Caveats Performance Results Extensions and Robustness Conclusions ReferencesGo Back Abstract Any form multimedia processing typically computationally expensive even harder problem performing some form multimedia processing multiple real time continuous streams data such paradigm each frame sequence images incurs very large computational expense obvious yet difficult solution divide the problem and compute the solution parallel This paper details the nature the problems and the solutions for dealing with parallel multimedia processing both shared memory and distributed environments Click here view slide show presentation this paper Back Introduction The Evolution RIVL Over the course the past two years large effort has been mounted develop applications that can efficiently and reliably process multimedia data The effort manifested itself with the construction RIVL Resolution Independent Video Language RIVL multimedia processing package that given set images set sequence images can efficiently process these multimedia streams and generate outgoing image sequence images RIVL implemented tcl extension that capable performing common image operations such overlay smoothing clipping cropping etc The tcl interface simplifies the process coding image processing script Recently RIVL has been extended process continuous streams multimedia data and generate corresponding output stream images The extended RIVL package called RIVL was made possible treating RIVL evaluation midpoint continuous media object This work was facilitated using CMT The Continuous Media Toolkit Image processing continuous streams media real time very hard problem considering today current state computer technology Performing even simple image oper ation over single sequence images and outputting the resultant image real time requires the order million CPU cycles approach real time image processing frame rate frames per second which the standard frame rate for perceiving continuous motion would require one the following items true able perform image processing operations less than linear time single processorto able utilize high performance technology that does not yet existto able divide the work and perform the image processing parallel achieve less than linear time performance Since have little control over the first two items have focused our efforts the third Most image processing routines can performed super linear time the work divided among array parallel processors This true for RIVL and also for RIVL Bearing this mind established the project goal develop easy use fast and inexpensive real time multimedia processing application Section describe generic method for parallelizing most the image operations RIVL exploiting the way that RIVL processes inputted set images Section describe two implementations Parallel RIVL PRIVL The first version designed run shared memory machines The second version designed run over cluster Workstations Section present analysis performance results Section describe some improvements our implementations Finally Section draw some conclusions and analyze our progress Back RIVL and the Generic Parallel ParadigmGo Back The RIVL Graph begin our discussion RIVL introducing the RIVL Evaluation Graph order for RIVL execute requires set multimedia input data and control RIVL script The RIVL script sequence tcl rivl commands that specify what image processing operations should occur the input data Once RIVL invoked the RIVL script translated into the RIVL graph pictured above Each node corresponds some image operator smooth canny etc and each edge signal corresponds the actual image data Those nodes lying inside the illustrated rectangle above correspond true image operators Those nodes lying outside the rectangle are the RIVL nodes The nodes outside and the left the rectangle correspond read nodes one read node per image stream and the node right the rectangle corresponds the write node want emphasize that construction the RIVL graph does not compute any multimedia data The RIVL graph merely the control flow structure through which each inputted sequence data must propagate generate the outputted processed image There are two phases processing data using the RIVL graph once has been constructed The first phase manifests itself graph traversal from right left This what makes RIVL efficient image processing mechanism The first node that evaluated the Write node the right most node traversing the graph reverse order RIVL decides each node exactly how much data the output signal requires from the input signal The evaluation reverse propagated from the write node through the graph and back every read node Once the reverse propagation completes every node the graph knows exactly how much data from each input signal required compute the node corresponding output signal The multimedia data then processed the second traversal which conforms left right traversal the RIVL graph propagating the input data forwards through the graph only operating data that relevant the final output image Back Parallelizing RIVL can summarize the preceding section into the statement that the amount data that fetched from each Read node exactly function the output the Write node Combining this notion with the fact that most the image processing operations RIVL not create dependencies from one pixel another given input image can derive simple for mechanism for dividing the work and parallelizing RIVL Instead running RIVL single processor spawn multiple RIVL processes different processors and have each process work towards computing different segment the output data define the notion single Master RIVL process and multiple slave RIVL processes Each slave process started different processor Once started the slave process sits idle listening for instructions from Master process After the slave processes have been started Master process created The Master Process determines how many slaves are available for work Once control connection established between the Master and every Slave the Master assigns each slave logical the Master the Slave ranges from slaves After each slave assigned the Master sends each slave the total number processes available for work followed copy the RIVL script Once each slave and the master receives the RIVL script they each generate copy the RIVL graph and perform the right left traversal independently The difference between the right left traversal now that the logical for the current processor and the total number processes becomes factor determining how much computation gets done for each process According the figure above the amount data fetched from each read node longer function the output the write node but now function the process Logical the total number processes and function the write node output That each RIVL process responsible for computing different independent portion the final output data which based the above parameters Hence the term Fine Grain Parallel RIVL Our approach fine grained that each RIVL process performs the same set computations different data Actual data computation the left right graph traversal occurs when the master says Each slave and the master process computes their appropriated portion the output image Back Continuous Media Parallel RIVL The model parallelization for RIVL just described maps smoothly RIVL With RIVL there initial setup phase for each slave process and the master process previously described the Master process sends each slave its logical the total number processes and copy the RIVL script Each RIVL process then computes the RIVL graph and makes the right left traversal The image processing for computing each output frame continuous media stream occurs follows There CMO Continuous Media Object which captures and manages continuous streams data and resides part the Master Process When the CMO has captured all its input data for single output image contacts the master Parallel Synchronization Device and tells each RIVL process slaves and the Master that data ready fetched and that computation can begin ASAP Each RIVL process then fetches only the input data needs generate its segment the output data and makes the left right traversal through the graph The output data from each RIVL process then written back buffer within the CMO where the data assembled into single data output object Each RIVL process then blocks listening for further instructions from the CMO when another image will ready for processing Using this method for given stream multimedia data the construction the RIVL graph and reverse traversal the graph are performed only once setup time The actual image processing only requires one traversal the graph each RIVL process where the computation area distributed among all the RIVL processes Back Implementations Based the generic parallelization scheme described the preceding section have developed two implementations Parallel RIVL Each implementation has its own synchronization mechanism for parallelizing the independent RIVL processes and its own mechanism for transferring data Back Shared Memory Implementation The shared memory implementation illustrated above Each RIVL process resides different processor but each processor resides the same machine which has access the same shared memory segment This implementation mirrors the generic parallel model described Section Implementation Details The initial setup facilitated using TCP multi cast via Tcl The Process synchronization facilitated using UNIX semaphores The Data Transfer facilitated using shared memory reads and writes via UNIX IPC The Program was compiled for SparcStation running SunOS This model operates follows Following the initial setup phase the CMO works capturing all data necessary compute single RIVL output frame Once the CMO captures all the necessary data tells each RIVL process begin processing means entry semaphore Each RIVL process then reads only the data relevant its own output via shared memory read Once the left right evaluation the RIVL graph completes the RIVL process then performs shared memory write the memory region containing the output image that accessible the CMO The RIVL process then blocks exit semaphore until all the RIVL processes complete computation for the same frame data Once every RIVL process blocks the master RIVL process sets the exit semaphore and each RIVL process waits again the entry semaphore until the CMO again releases Back Networked Implementation The networked implementation illustrated above Each RIVL process resides different processor and each processor resides different machine This implementation also mirrors the generic parallel model described Section Implementation Details The initial setup again facilitated using TCP multi cast via Tcl The Data Transfer facilitated using Active Messages over Net The Synchronization Mechanism implicit via the Active Messages paradigm The Program was compiled for SparcStation running SunOS This model operates follows Like its shared memory counterpart this model performs the initial setup using multicast establish the Active Message connections from the master each slave RIVL process The CMO works capturing all data necessary compute single RIVL output frame This model differs from the generic model that the master process knows exactly what portion the input data each RIVL process needs evaluate their RIVL graph Once the CMO captures all the necessary data tells each RIVL process begin processing issuing gam store each RIVL process Once the message received each RIVL process handler invoked which tells the RIVL process that can begin evaluating its RIVL graph the transferred data Once the output data computed the RIVL process then issues gam store the Master process specifying exactly where the sent data should stored the final output image buffer managed the CMO Eventually handler routine the Master process will update received from list Once the Master receives data from each RIVL process the CMO outputs the computed frame and begins processing the next multimedia frame The process synchronization mechanism implicit with the actual data transfer that RIVL process cannot begin evaluating its graph given frame segment until receives Active message from the Master process Similarly the Master process cannot move the next multimedia image until receives Active message from each slave process Another subtle point that having the Master determine how much the input data each RIVL process requires rather than having the RIVL process itself determine this information reduce the round trip communication rate from master slave Having each RIVL process compute its own region would require gam request followed gam reply the Master process Instead the Master decides how much data each RIVL process needs and simply issues single gam store Back Implementation Caveats Our actual executables are not SPMD There separate executable for the Master process and another executable for each Slave process This didn cause any problems when developing the shared memory implementation However since Active Messages ver assumes SPMD model ran into problems when specifying handlers both the Master process and the Slave processes When the Master process received active messages from any slave process the slave process attempted invoke handler the Master that existed the slave but not the handler The situation was the same when slave process received Active Message from the Master overcame this shortcoming modifying the Active Message source code The modification allows application register handler with Active Messages callinghid uam reg handler handler handler Handler handler corresponds the handler virtual address The process returns hid which integer but stands for handler our implementation since only the Master executable and slave executable are different the Master and each slave must register their handlers with the Active Message library Now when process sends Active Message from slave master and vice versa longer ships the processes virtual address the handler but rather ships logical corresponding the handler invoked The Active Message library maintains look table that indexed the logical The logical corresponds process handler virtual address which then invoked from Active Messages Back Performance Results ran our shared memory experiments Quad Processor SparcStation running SunOS Our Networked Implementation was tested using ATM connected SparcStation running SunOS constructed two different test cases named Test and Test The two tests perform the following image operations Test There are input sequences images The first image sequence scaled rotated and copied four times The resulting output then overlayed onto the second image sequence and then output Test There are input sequences images scaled rotated and copied four times smoothed The output from then overlayed ontop the output for Overall Test more computationally expensive set operations than Test This fact illustrated our experimental results From our graphed results above the shared memory implementation performs somewhat better than our Networked implementation Both implementations however perform better than their serial counterparts the green bar graph One observation was that the networked implementation exhibited large spread timings for different frames and this attributed our process getting preempted The behavior was not visible the shared memory implementation our process was sleeping waiting for the semaphores change while the process the network implementation busy waits Hopefully interrupt driven implementation active messages would cure this Note all tests the processor speed relatively equal Results Shared Memory both tests and the performance gains exhibited the following patterns From Processors Performance nearly doubled From Processors Again our performance nearly doubled From Processors The performance increase negligble Performance not increasing either because the communication overhead exceeds the performance gain because the processors are optimally load balanced probably the latter Networked Implementation From Processors Performance nearly doubled From Processors There small improvement performance however the shared memory implementation appears little better From Processors The performance increase again negligble The explanation for this probably the same the shared memory experiment Back Extensions Robustness There are number improvements that can and should made improve overall performance and robustness our parallelization scheme Improve the Load Balance The largest improvement involves improving the load balance among all the RIVL processes using Hungry Puppy Strategy for dividing the work Our current implementations statically allocate work each RIVL process The location and the amount data that needed for each RIVL process determined function the number processes and the process indicated from our experimental results there significant boost from RIVL processes using our shared memory implementation can partly attribute this problem optimal load balance Modifying the Networked implementation should prove more trouble some and while improving the overall load balance will probably increase the communication overhead more Active Message will have sent and processed Modifying the Shared Memory version should easier The current synchronization mechanism implemented using UNIX semaphores RIVL process allowed begin executing the next frame until all RIVL processes have completed execution the current frame The output image currently divided the number processes available for work could improve the load balance for this implementation doing two things dividing the output image work regions into more numerous smaller segments and for current frame allow RIVL processes complete executing their output segment and grab another segment from the Still Need Computed Queue residing the Master process This implementation will improve load balance allowing less busy processes contribute equally the entire output image while giving busier processors the time they need compute their data without becoming bottleneck for the entire output image Improve Reliability and Fault Tolerance real time systems not uncommon for things wrong Specifically what should happen the even that slave RIVL process crashes Our current implementations not account for such mishaps process were malfunction due either hardware communication failure our implementation would fail Port our ATM Sparc Implementations over Fast Ethernet designing any system cost always issue The purpose for implementing PRIVL over Active Messages was utilize the lower cost workstations and networks compared expensive parallel machines The cost higher performance PCs rapidly the decline Adapting our implementations Fast Ethernet natural step reducing the cost high performance PRIVL The actual transition from ATM Sparc Fast Ethernet merely matter getting Active Messages work over Fast Ethernet Back Conclusions were looking for significant speedups Parallel RIVL moved from processors being more than Our results are definitely encouraging both our shared memory implementation and our networked implementation obtained good speedups four processors order process real time data need approach frame processing rate close frames per second rougly per frame For the operations have tested will require upwards similar processors achieve the desired frame rate not have results for more than four processors However examining our results can determine that under the current implementations the processes running Parallel RIVL will not load balanced Unfortunately must conclude that our implemenations they stand will not scale upwards processors achieve the desired frame rate However further work under way address this load balancing problem Furthermore Hungry Puppy object tracking algorithm currently being incorporated into PRIVL The experimental results from this should available shortly have however made significant progress parallelizing RIVL RIVL non trivial application and our parallelization scheme works for most the standard RIVL image operations Back References Jonathan Swartz Brian Smith Resolution Independent Video Language Proc the Third ACM International Conference Multimedia San Francisco November Lawrence Rowe Brian Smith Continuous Media Player Third International Workshop Network and Operating Systems Support for Digital Audio and Video Nov San Diego Brian Smith Lawrence Rowe Stephen Yen Tcl Distributed Programming Proc the Tcl Workshop Berkeley June von Eicken Culler Goldstein and Schauser Active Messages Mechanism for Integrated Communication and Computation Proceedings the Int Symp Computer Architecture May Gold Coast Australia Anindya Basu Vineet Buch Werner Vogels Thorsten von Eicken Net User Level Network Interface for Parallel and Distributed Computing Proc the ACM Symposium Operating Systems Principles Copper Mountain Colorado December Sugata Mukhopadhyay Arun Verma CMRivL Programmable Video Gateway Cornell University Spring MIME Version Server CERN Date Monday Jan GMT Content Type text html Content Length Last Modified Saturday Nov GMT Nimar Singh Arora BookmarksNimar Singh Arora BookmarksFUN AND GAMESGeneral links for various fun activities Movies AustinAn updated list movies showing Austin WebChessInteresting stories and poetry repositoryAdventure games CDROMCoast Coast Games ArchiveStart Online Chess GameGame Games Happy Puppy Front PageIIT KANPUR DBPC These are links past IIT undergrad college and Don Bosco school and friends from those wonderful days Indian Institute Technology Kanpur IndiaChatDon Bosco Park Circus Batch IIT Kanpur The Class Naughty LinksdigitalNATION Greeting Card CenterRomance for you and DarlingNaughty Linx Arts and Entertainment Photography Female RESEARCH ENGINESVarious search engines look for research material Specially papers computers science UCSTRI Cover PageFielded SearchSearching the HBP BibliographiesWelcome the Electric LibraryTHEORY LINKSLinks various pages theorists lectures research material Collected Advice Research and WritingUT Algorithms and Computational Theory GroupCambridge University PressECCC The Electronic Colloquium Computational ComplexityRajeev Motwani Research PapersDavid ZuckermanFoundations Cryptography Oded GoldreichOpen ProblemsINFORMATIONLinks information various topics like emacs plain dictionaries yellow pages Mailing ListsGNU Emacs Manual Table ContentsHTML based manual dictionary comBigBook Directory SearchUT Courses and JobLinks various courses and text book links Links various job prospects GRACS Fellowship Committee gracs fellowship Office the RegistrarCS Distributed Computing ITEXbook The Textbook ExchangeNatural Sciences Placement CenterNEWSNewspapers India live cricket score cards etc Indian Express Home PageLive Scorecards from CricInfoSEARCH ENGINESFour Directory ServicesWhoWhere mail AddressesFREE StuffGenerally some free offers money savers tree source code for the Pick operating systemLEDA library data structures India Travel BBSFaxaway Test Drive InstructionsFTP Gateway Wisconsin MadisonWelcome HoTMaiLCOUNTERVIDEO VAULT Date Tue Jan GMT Server NCSA Content type text html Last modified Thu Nov GMT Content length The Daily Planet UofIText Only Guide MeteorologyThe Weather VisualizerDepartment Home PageGeosciences Web ServerDevelopment Using JavaWx and Climate ProductsFor Faster Hurricane Information Satellite Images Hurricane TrackingHurricane Module Date Tue Nov GMT Server NCSA Content type text html Last modified Fri Apr GMT Content length Put your title here Here large Heading Notice how looks different when you select View Source from the Menu adding quite bit extra text make point look really More regular text this time with few fancy extras added Lokk these here Italics Bold Showing how those fun Line break smaller heading even smaller heading really tiny heading Notice what each heading does Next have picture Could Nate don think Look what happens text with pictures How about list things The List Things This Thing That Thing The Other Thing And finally link another page home page Yet another link more info HTML 