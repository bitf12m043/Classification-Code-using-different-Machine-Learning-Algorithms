MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Monday May GMT Education and work experiences Koichi KamijoEducation and work experiences got degree the University Tokyo Electrical Engineering Inose Saitolab currently MEng student Computer Science Cornell University also working for IBMJapan Yamato lab recent work was developing ThinkPad notebook such ThinkPad and ThinkPad was mainly charge developing systems such docking stations and imbedding multimedia functions such ROM Video Capture function Video Accelerator NTSC PAL output and MPEG viewer into notebook visited several IBM labs Following are the labs visited far visiting order IBM Poughkeepsie Kingston stayed here for months fix electrical problem IBM console IBM Poughkeepsie nice place along Hudson river and with lots green also close New York City and Boston hrs IBM Raleigh Charlotte stayed here for months liaison Raleigh the capital North Carolina and also nice quiet place Duke and state university are close IBM Raleigh located RTP Research Triangle Park Wright brothers were born North Carolina you can see the plate cars here IBM Hursley stayed here for weeks fix EMI problem terminal were developing Hursley close London and also close Wimbledon One the buildings IBM Hursley used castle There bar inside IBM Boca Raton visited here twice and stayed for months all together once help designing Microchannel SCSI adapter and once liaison mentioned Where lived summer all the year and close many cool spots IBM Taiwan ROC stayed for weeks have meeting with IBM Taiwan and vendors Taipei and Hshinchu love the foods Taipei because their tastes are close ours Japan often visit Chinese town Yokohama visit Aoba one favorite restaurants where very good Taiwanese food served MIME Version Server CERN Date Tuesday Jan GMT Content Type text html Content Length Last Modified Monday Nov GMT Dissertation AbstractsDissertation Abstracts Daniel Berleant Yung Tai Byun James Crawford Daniel Dvorak Adam Farquhar David Franke Richard Froom John Hartman Akira Hayashi Herbert Kay New Wan Yik Lee New Wood Wai Lee David Pierce Raman Rajagopalan David Throop The Use Partial Quantitative Information with Qualitative Reasoning Daniel Berleant The Use Partial Quantitative Information with Qualitative Reasoning Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract There need for combining qualitative and quantitative simulations simulation tasks that would difficult using either alone This task made more difficult the fact that available quantitative information may incomplete bounding values with intervals describing them with probability distribution functions This research demonstrates the combination qualitative and quantitative simulation implemented system utilizes partial complete quantitative information gradually refine qualitative simulation into simulation that has properties and advantages both qualitative simulations and quantitative ones The technique exemplified shown possess properties often used analyzing both qualitative and quantitative simulators Qualitative and quantitative inferences are correct Theoretical convergence the true solution and stability the presence partial model inputs are also shown has been applied the problem finding probabilities qualitative behaviors important problem Partial quantitative characterization model inputs the form intervals and probability distributions may used bound the probabilities different behaviors This demonstrated for simple models including one the dependability analysis application domain Spatial Learning Mobile Robots with Spatial Semantic Hierarchical Model Yung Tai Byun Spatial Learning Mobile Robots with Spatial Semantic Hierarchical Model Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract The goal this dissertation develop spatial exploration and map learning strategy for mobile robot use unknown large scale environments Traditional approaches aim building purely metrically accurate maps Because sensorimotor errors hard construct accurately such maps However spite sensory and computation limitation humans explore environments build cognitive maps from exploration and successfully path plan navigate and place find Based the study human cognitive maps develop spatial semantic hierarchical model replace the global absolute coordinate frame used traditional approaches The semantic hierarchical model consists three levels control level topological level and geometrical level The topological level provides the basic structure the hierarchy the control level robot finds places follows travel edges which can described qualitatively definable features The distinctive features allow development distinctiveness measures The robot uses these measures find with negative feedback control the distinctive places hill climbing search algorithms and the travel edges edge following algorithms Distinctive places and travel edges are connected build topological model This model created prior the construction global geometrical map Cumulative location error essentially eliminated while traveling among distinctive places and travel edges alternating between the hill climbing search control algorithms and the edge following control algorithms top the topological model metrical information accumulated first locally and then globally Using simulation package with robot instance demonstrate the robustness our method against sensorimotor errors The control knowledge for distinctive places and travel edges the topological matching process and the metrical matching process with local geometry make our approach robust the face metrical errors addition robust navigation the control and topological levels our framework can incorporate certain metrically based methods and thus provide the best both approaches Access Limited Logic Language for Knowledge Representation James Crawford Access Limited Logic Language for Knowledge Representation Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract Access Limited Logic ALL language for knowledge representation which formalizes the access limitations inherent network structured knowledge base Where deductive method such resolution would retrieve all assertions that satisfy given pattern access limited logic retrieves all assertions reachable following available access path The time complexity inference thus polynomial function the size the accessible portion the knowledge base rather than the size the entire knowledge base Access Limited Logic though incomplete still has well defined semantics and weakened form completeness Socratic Completeness which guarantees that for any query which logical consequence the knowledge base there exists series queries after which the original query will succeed have implemented ALL Lisp and has been used build several non trivial systems including versions Qualitative Process Theory and Pearl probability networks ALL step toward providing the properties clean semantics efficient inference expressive power which will necessary build large effective knowledge bases Monitoring and Diagnosis Continuous Dynamic Systems Using Semiquantitative Simulation Daniel Louis Dvorak Monitoring and Diagnosis Continuous Dynamic Systems Using Semiquantitative Simulation Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract Operative diagnosis diagnosis physical system operation essential for systems that cannot stopped every time anomaly detected such the process industries space missions and medicine Compared maintenance diagnosis where the system offline and arbitrary points can probed operative diagnosis limited mainly sensor readings and diagnosis begins while the effects fault are still propagating Symptoms change the system dynamic behavior unfolds This paper presents design for monitoring and diagnosis deterministic continuous dynamic systems based the paradigms monitoring model corroboration and diagnosis model modification which semiquantitative model aphysical system simulated synchrony with incoming sensor readings When sensor readings disagree with predictions variant models are created representing different fault hypotheses These models are then simulated and either corroborated refuted new readings arrive The set models changes new hypotheses are generated and old hypotheses are exonerated contrast methods that base diagnosis snapshot behavior this simulation based approach exploits the system time varying behavior for diagnostic clues and exploits the predictive power the model forewarn imminent hazards The design holds several other advantages over existing methods semiquantitative models provide greater expressive power for states incomplete knowledge than differential equations thus eliminating certain modeling compromises semiquantitative simulation generates guaranteed bounds variables thus providing dynamic alarm thresholds and thus fewer fault detection errors than with fixed threshold alarms the guaranteed prediction all valid behaviors eliminates the missing prediction bug diagnosis the branching time descruption behavior permits recognition all valid manifestations fault and interacting faults hypotheses based predictive semiquantitative models are more informative because they show the values unseen variables and can predict future consequences and fault detection degrades gracefully multiple faults are diagnosed over time Automated Modeling Physical Systems the Presence Incomplete Knowledge Adam Farquhar Automated Modeling Physical Systems the Presence Incomplete Knowledge Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract This dissertation presents approach automated reasoning about physical systems the presence incomplete knowledge which supports formal analysis proof guarantees has been fully implemented and applied substantial domain modeling problems Predicting and reasoning about the behavior physical systems difficult and important task that essential everyday commonsense reasoning and complex engineering tasks such design monitoring control diagnosis capability for automated modeling and simulation requires expressiveness represent incomplete knowledge algorithms draw useful inferences about non trivial systems and precise semantics support meaningful guarantees correctness order clarify the structure the knowledge required for reasoning about the behavior physical systems distinguish between the model building task which builds model describe the system and the simulation task which uses the model generate description the possible behaviors the system This dissertation describes QPC implemented approach reasoning about physical systems that builds the expressiveness Qualitative Process Theory Forbus and the mathematical rigor the QSIM qualitative simulation algorithm Kuipers The semantics QPC modeling language are grounded the mathematics ordinary differential equations and their solutions This formalization enables the statement and proof QPC correctness the domain theory adequate and the initial description the system correct then the actual behavior the system must the set possible behaviors QPC predicts QPC has been successfully applied problems Botany and complex examples drawn from Chemical Engineering well numerous smaller problems Experience has shown that the modeling language expressive enough describe complex domains and that the inference mechanism powerful enough predict the behavior substantial systems Theory Teleology David Wayne Franke Theory Teleology Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract representation language for teleological descriptions descriptions purpose defined The teleological language TeD expresses the descriptions purpose terms design modifications that guarantee the satisfaction design specifications These specifications express potential behaviors the designed artifact should should not exhibit define abstraction relation behavior and implement model checking and classification algorithms that computethis abstraction relation The model checking algorithm determines whether not behavior satisfies specification The classification algorithm provides effective indexing behaviors and teleological descriptions implement acquistion technique for teleological descriptions and demonstrate how teleological descriptions can subsequently used diagnosis explanation case based reasoning design analogy and design reuse demonstrate the behavior language teleology language acquisition teleological descriptions and application teleological descriptions explanation diagnosis and design reuse via examples the thermal hydraulic electrical and mechanical domains define additional teleological operators that express purposes like prevent order synchronize maintain and regulate demonstrating the ability represent common human generated descriptions purpose TeD Expressing the purpose preventing undesirable behavior unique TeD and example TeD ability express purposes regarding missing behaviors and components removed from design The teleology language developed this work represents significant advance over previous work providing formal language that independent any particular domain mechanisms behavior language can effectively acquired during the design process and provides effective means classifying and indexing teleological descriptions High Speed Navigation with Approximate Maps Richard Allan Froom High Speed Navigation with Approximate Maps Dissertation The University Texas Austin Abstract global map mobile robot environment essential for high performance navigation large scale space When portions the environment are not visible map needed for route planning and enables high performance allowing the robot anticipate regions that are occluded beyond sensor range Yet autonomously acquired global map information inevitably uncertain due the low positioning accuracy mobile robots and the possibility changes the environment Previous work high speed navigation falls into two categories Global optimization approaches assume that accurate model environment geometry and robot dynamics are available and address the problem efficiently approximating the minimum time control between start and goal state Reactive navigation methods use only immediately sensed environment geometry avoid obstacles while moving specified goal position The global optimization approach has the theoretical advantage high performance but does not address the significant uncertainty typical mobile robots The reactive navigation approach can respond unanticipated geometry but its overall performance limited This dissertation describes method for high speed map guided navigation realistic conditions uncertainty previously developed method used acquire topologically correct metrically approximate map the environment despite positioning errors Information the approximate map guides the operation novel high performance reactive navigator Performance does not critically depend the availability expensive accurate metrical information Nonetheless the map may elaborated with more detailed information and its level detail and accuracy improved performance smoothly improves Automatic Control Understanding for Natural Programs John Hartman Automatic Control Understanding for Natural Programs Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract Program understanding involves recognizing abstract concepts like read process loop existing programs Programmers spend much their time understanding programs studying and automating the process has many benefits Programming plans are units programming knowledge connecting abstract concepts and their implementations Existing research assumes that plan instances can recognized recover the programmer abstract concepts and intentions but this approach has not been confirmed empirically present practical method for bottom control concept recognition large unstructured imperative programs Control concepts are abstract notions about interactions between control flow data flow and computation such loop read process loop and bounded linear search They are recognized comparing abstract program representation against library standard implementation plans The program representation hierarchical control flow data flow graph decomposed into tree sub models using propers single entry exit control flow sub graphs Plans are represented similar graphs with added qualifications Recognition based simple matching between sub models and plans The method was implemented the UNPROG program understander and tested with Cobol and Lisp source programs This method robust efficient and scalable The program representation can formed for all language constructs which permit static determination control and data flow Comparing sub models and comparisons increases linearly with program size UNPROG has been applied automatic Cobol restructuring Knowledge associated with plans and concepts permits more specific and insightful transformation code generation and documentation than possible with syntactic methods Control understanding can similarly raise the level other reverse engineering and engineering tools for applications like analysis documentation and translation also showed how our method and UNPROG can used for empirical study programs the conceptual level Results can used improve recognizer performance acquire plans catalog natural plans and concepts test the hypothesis that programs are planful and characterize program populations Geometrical Motion Planning for Highly Redundant Manipulators Using Continuous Model Akira Hayashi Geometrical Motion Planning for Highly Redundant Manipulators Using Continuous Model Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract There need for highly redundant manipulators work complex cluttered environments Our goal plan paths for such manipulators efficiently The path planning problem has been shown PSPACE complete terms the number degrees freedom DOF the manipulator present method which overcomes the complexity with strong heuristic utilizing redundancy means continuous manipulator model The continuous model allows change the complexity the problem from function both the DOF the manipulator believed exponential and the complexity the environment polynomial polynomial function the complexity the environment only The power the continuous model comes from the ability decompose the manipulator into segments with the number size and boundaries the segments varying smoothly and dynamically First develop motion schemas for the individual segments achieve basic set goals open and cluttered space Second plan smooth trajectory through free space for point robot with maximum curvature constraint Third the path generates set position subgoals for the continuous manipulator which are achieved the basic motion schemas Fourth the mapping from the continuous model available jointed arm provides the curvature bound and obstacle envelopes required step guarantee collision free path The validity the continuous model approach also supported extensive simulation which performed While the simulation has been performed show natural extension for each technique have implemented for the simulation Refining Imprecise Models and Their Behaviors Herbert Kay Refining Imprecise Models and Their Behaviors Doctoral dissertation Department Computer Sciences The University Texas Austin December Abstract This dissertation describes methods for simulating and refining imprecisely defined Ordinary Differential Equation ODE systems When constructing model physical process modeler must cope with uncertainty due incomplete knowledge the process For tasks such design and diagnosis the effects this uncertainty must considered However predicting the behavior imprecisely defined model not easy since the model covers space many precise instances each which behaves differently While model uncertainty cannot completely eliminated possible reduce Model refinement uses observations physical process rule out portions the model space that could not have produced the observations more experience with the physical process gained the imprecision the model further reduced This dissertation describes three methods for reasoning with imprecise ODE models SQSim simulator that produces guaranteed bound the behavior imprecise ODE model using multiple level representation and inference methods that span the qualitative quantitative spectrum SQSim produces predictions whose uncertainty consistent with model imprecision demonstrate SQSim complex nonlinear chemical process and compare other methods for simulating imprecise ODE models MSQUID function estimator for fitting and bounding noisy data that known monotonic uses neural network inspired model and nonlinear constrained optimization search space monotonic functions prove that MSQUID can estimate any monotonic function and show that produces better estimates than does unconstrained optimization SQUID which uses SQSim and MSQUID components system identification method that refines imprecise model using stream observations from physical process SQUID uses refutation rule out portions the model space that are inconsistent with the observations show that this approach refinement significantly more efficient than parameter estimation for models with functional uncertainty and that provides greater robustness the face uninformative observations Spatial Semantic Hierarchy for Physical Mobile Robot Wan Yik Lee Spatial Semantic Hierarchy for Physical Mobile Robot Doctoral dissertation Department Computer Sciences The University Texas Austin December Abstract This dissertation describes research extend and improve the Spatial Semantic Hierarchy SSH approach robot exploration and mapping and demonstrate and evaluate its effectiveness controlling physical mobile robots The SSH approach for robot exploration and mapping was first developed the context simulated robot and tested simulated environments with very simple models sensorimotor error Physical implementations aspects the SSH approach have been built other researchers but they not provide adequate demonstration its strengths adequate analysis its conditions applicability The dissertation work extended and improved the SSH mapping theory from its original prototype version capable handling real sensorimotor interaction with real office environment The underlying goal this research demonstrate how symbolic representations and symbol based behaviors autonomous robot can grounded non symbolic continuous sensorimotor interaction with real environment through the SSH approach The extended theory implemented physical robot explore previously unknown environment and create SSH spatial description the environment This dissertation describes the improved SSH mapping theory the details its implementation physical robot and demonstration and evaluation several features the implemention Qualitative Simulation Based Method Construct Phase Portraits Wood Wai Lee Qualitative Simulation Based Method Construct Phase Portraits Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract have designed qualitative simulation based method construct phase portraits for significant class systems two first order autonomous differential equations intended step toward automated understanding continuous physical systems Differential equation models are powerful tools for reasoning about physical systems but they typically require precise information about systems Recently developed methods for qualitative simulation make possible predict all possible behaviors consistent with state incomplete qualitative knowledge the world expressed qualitative differential equation QDE However qualitative simulation can fail due intractable branching and spurious predictions The field nonlinear dynamics has introduced the phase portrait representation powerful tool for the global analysis nonlinear differential equations state the system represented point phase space its behavior over time represented trajectory When the phase portrait two dimensional the solutions differential equation can characterized the system fixed points bundles adjacent trajectories called flows and certain bounding trajectories Numeric methods for constructing phase portraits require numerically specific information about the system demonstrate method and implemented program QPORTRAIT that constructs two dimensional phase portraits from QDE Starting with the total envisionment finite transition graph representation the possible behaviors system QPORTRAIT progressively identifies classifies and combines features the phase portrait abstracting away uninteresting distinctions and filtering out inconsistent combinations features Because each step the analysis validity preserving the prediction guaranteed cover all real phase portraits consistent with QDE its current form QPORTRAIT phase applies restricted but nontrivial set QDE models requires that all fixed points non degenerate and landmark values for the phase variables QPORTRAIT has produced tractable results when applied qualitative generalizations several well known nonlinear systems Guaranteed coverage the behavior qualitatively described set QDE complements the precision numeric methods based approaches Map Learning with Uninterpreted Sensors and Effectors David Pierce Map Learning with Uninterpreted Sensors and Effectors Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract This dissertation presents set methods which learning agent called critter can learn sequence increasingly abstract and powerful interfaces control robot whose sensorimotor apparatus and environment are initially unknown The result the learning rich hierarchical model the robot world its sensorimotor apparatus and environment The learning methods rely generic properties the robot world such almost everywhere smooth effects actions sensory features the lowest level the hierarchy the critter analyzes the effects its actions order define control signals one for each the robot degrees freedom uses generate and test approach define sensory features that capture important aspects the environment uses linear regression learn action models that characterize context dependent effects the control signals the learned features uses these models define high level control laws for finding and following paths defined using constraints the learned features The critter abstracts these control laws which interact with the continuous environment finite set actions that implement discrete state transitions this point the critter has abstracted the robot world finite state machine and can use existing methods learn its structure Qualitative Reasoning about Dynamic Change the Spatial Properties Physical System Raman Rajagopalan Qualitative reasoning about dynamic change the spatial properties physical system Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract Spatial reasoning essential part human interaction with the physical world the many models that have been developed support automated spatial reasoning most rely numerical descriptions spatial scene This dissertation addresses problems where only qualitative descriptions spatial scene are available such natural language understanding qualitative design and physics problem solving provide the first set solutions given only qualitative description spatial scene for reasoning about dynamic change both the spatial and non spatial properties physical system use diagrams compactly input the spatial scene for problem and text describe any non spatial properties match diagram and text objects their descriptions can integrated have developed method for describing the conceptual class objects directly diagrams Then diagram and text objects can matched based their conceptual class The given problem solved through qualitative simulation and all spatial reasoning done with respect extrinsic Cartesian coordinate system model the relative positions objects through inequality constraints the coordinates the points interest Changes due translational motion are detected noting changes the truth values inequality constraints model the orientation object through knowledge its extremal points and its qualitative angle rotation with respect each coordinate axis This model has been used reason qualitatively about the effects rotational motion such changes the area projected one object onto another have implemented our spatial representation production rules and model fragments the QPC qualitative modeling system The former has been used for solving static world problems such understanding descriptions urban scene The latter has been used reason about situations where changes spatial properties play critical role such the operation transformers oscillators generators and motors support dynamic spatial reasoning have expanded the modeling capabilities QPC include methods for modeling piecewise continuous variables non permanent objects and variables with circular quantity spaces Model Based Diagnosis Complex Continuous Mechanisms David Rutherford Throop Model Based Diagnosis Complex Continuous Mechanisms Doctoral dissertation Department Computer Sciences The University Texas Austin Abstract diagnosis when hypothesis proposes variable value several different lines evidence may considered the different evidence must arbitrated The result this arbitration consists single best estimate the variable value and measure that estimate plausibility The plausibility measure reflects the degree agreement among the lines evidence This report describes HEATX program for model based diagnosis non linear mechanisms with continuous variables Previous work model based diagnosis has avoided arbitrating numeric evidence often representing continuous variables discrete symbols high cold Such restricted representation have had difficulty diagnosing mechanisms with feedback reconvergent fanout HEATX represents numerical data explicitly the hypotheses and the inferencing procedures thereby able arbitrate evidence numerically HEATX uses both nonlinear numerical simulations and approximate linear models perform diagnosis the domain heat exchanger networks The response these networks changes their inputs nonlinear the networks also have feedback and reconvergent fanout This dissertation introduces several novel techniques for diagnosing such networks interleaves the generation complete fault hypotheses with several tests partially formed hypotheses Two these tests are the qualitative filter and the clustering filter The qualitative filter analyzes the signs gains between fault and symptom variables The clustering filter constructs linear approximations individual components and assembles these into linear model the network then uses the linear model assess the consistency hypothesis does determining whether there value for the candidate fault variable which consistent with the quantitative values the symptom variables the degree agreement between the symptoms and best value for the fault variable used score the hypothesis This filter extended multi fault diagnosis which values for several fault variable may estimated and judged simultaneously Date Tue Jan GMT Server NCSA Content type text html Computer Science Department Courses InstructionComputer Science DepartmentGeneral Information Course map Course Schedule for Fall Semester Course Schedule for Spring Semester Academic Calendar Official Staff Holidays Degree RequirementsCourse Home Pages current next semester Introduction Computers Section Introduction Computers Section Introduction Computer Science Programming Introduction Analysis Algorithms Software Systems Unix Programming Introduction Computer Graphics Cryptography Advanced Computer Architecture Graduate Intro Computer GraphicsF Fall Spring Summer Summer Course Home Pages previous semesters Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Evening Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Section Introduction Computers Section Computing Technology Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science Introduction Computer Science with Intensive Introduction Computer Science with Intensive Introduction Computer Science with Intensive Computer Systems Computer Systems Computer Systems Automata and Formal Languages Automata and Formal Languages Concepts Programming Languages Concepts Programming Languages Concepts Programming Languages Introduction Algorithms Unix Programming Introduction Parallel Computing Computer Architecture Computer Architecture Computer Architecture Introduction Computer Graphics Introduction Computer Graphics Software Engineering Principles Programming Languages Principles Programming Languages Principles Programming Languages Compiler Design Analysis Algorithms Analysis Algorithms Complexity Theory Natural Language Processing Advanced Computer Architecture Advanced Computer Architecture Parallel Computing Models Languages and Architectures Operating Systems Operating Systems Image and Video Computing Seminar Computer Graphics Graduate Introduction Computer Graphics Advanced Operating Systems Seminar Introduction Lambda Calculus and Type Theory Distributed Systems Seminar Networked Computing Systems Seminar Real Time Systems Seminar Seminar Image and Video Computing Seminar Tools for Parallel SystemsF Fall Spring Summer Summer This page maintained Azer Bestavros Please email comments corrections best edu Created Updated Date Tue Nov GMT Server NCSA Content type text html Last modified Wed Aug GMT Content length Lecture notes Chapter Architectures Chapter Architectures PERSPECTIVE ARCHITECTURE DESIGN factors computer design speed fast possible course dependent technology and cost cost price profit non profit mass market single use useablility shared single user size machine software issues power requirements depends intended use intended market mass market scientific research home use multiple users instructional application specific technology price performance curve perf Want the left these have higher performance for the price More bang for the buck price technology perspective electromechanical used mechanical relays vacuum tubes space requirement room Manchester Mark late transistors discrete late space requirement large cabinet room Examples CDC Atlas PDP SSI MSI mid late transistors space requirement cabinet Examples Cray VAX LSI early transistors space requirement board Examples VLSI late today transistors space requirement chip chip set board Examples MIPS Intel transistors Sparc RISC CISC RISC Reduced Instruction Set Computer The term was first used name research architecture Berkeley the RISC microprocessor has come loosely mean single chip processor that has the following qualities load store architecture very few addressing modes simple instructions pipelined implementation small instruction set easily decoded instructions fixed size instructions CISC Complex Instruction Set Computer This term was coined distinguish computers that were not RISC generally applied computers that have the following qualities complex instructions large instruction set many addressing modes difficulties with these terms not precisely defined term introduced applied earlier machines RISC has become marketing tool single chip constraint technologies advanced became possible put processor single VLSI chip Designs became driven how much how many transistors could the chip Why The time takes for electrical signal cross chip are significantly less than the time for the signal get driven off the chip somewhere else The number pins available was limited the desire have little interaction the chip with the outside world possible cannot eliminated but can minimized The earliest single processors chip had carefully pick and choose what went the chip Cutting edge designs today can fit everything but main memory the chip how the world has changed earliest computers had their greatest difficulties getting the hardware work technology difficulties space requirements cooling requirements given working computer scientists would jump through whatever hoops necessary use hardware has gotten much faster and cheaper attention has been diverted software compilers optimizers IPC inter process communication instruction time isn enough The technology isn keeping more than one instruction time parallelism instruction level ILP pipelining superscalar more than one instruction time multis VLIW supercomputer WHICH THESE BEST and FASTEST DEPENDS WHAT PROGRAM BEING RUN THE INTENDED USEAGE the Family released the late early processor chip lot its limitations have with what could fit VLSI chip the late INSTRUCTIONS relatively simple set like the MIPS but NOT load store arch two address architecture most instructions are specified bits fixed size tight encoding difficult distinguish opcode from operands but the bits are always part the opcode integer arithmetic different opcode for varying size data add add add logical different opcode for varying size data control instructions conditional branches jumps condition code mechanism used where most instructions had the effect setting the condition codes procedure mechanisms call and return instructions floating point guess not decimal string arithmetic presuming representation binary coded decimal REGISTERS bit general purpose registers only one not general purpose stack pointer the not part the general purpose registers the registers are divided into two register files one called the data registers and the other called the address registers This distinction similar the CRAY the stack pointer DATA TYPES byte word bits longword bits addresses are really their own data type arithmetic registers bit arithmetic However pin limitations the VLSI chip required reduced size address Addresses that travel off chip are bits and the memory byte addressable bit address specifies one Mbyte memory locations each instruction operates fixed data type OPERAND ACCESS the number operands for each individual instructions fixed like the VAX the addressing mode operand does not depend the instruction simplify things one the operands operand instruction must usually come from the registers the number type addressing modes much larger than the MIPS but fewer than the VAX the text has detailed discussion the addressing modes READ PERFORMANCE they got faster new technologies got faster SIZE pin VLSI chip huge number pins that time the Intel iAPX the late release one two address architecture depending how you look part chip set pin limitations the chips made for some unusual architectural design decisions compatible with earlier chip set memory memory architecture sort bit registers plus accumulator stack pointer and plus more that deal with segments condition codes are set most instructions and are used branching unusual addressing scheme due bit limitation for pins used for addresses divide all memory into fixed size byte pieces call each piece segment addresses are bits and specify offset within one the segments extra registers hold segment base addresses and effective address computed sort specifying which segment register adding the bit address the contents the segment register this addressing scheme cramps programmer style code has fit into segment does data and does stack all about the Cray There has always been drive design the best fastest computer the world Whatever computer the fastest has generally been called supercomputer The Cray earned this honor and was the fastest for relatively long period time The man who designed the machine Semour Cray bit eccentric but can get away with because good The Cray has exceptionally clean design and that makes fast This probably bit exaggerated due bias the Cray probably favorite computer Mostly opinion make the circuitry fast possible the Cray took paths Physical relatively time tested technology was used but much attention was paid making circuits physically close Semour was aware the limits imposed the speed light and the technology was pushed its limits Include only what was necessary but that don spare the horses philosophy was used This means that extra hardware was used not paying attention the cost wherever could make the machine faster And the same time any functionality that wasn necessary Semour opinion was left out see soon what that really means Just remember something seems out place you some functionality computer that you think essential and was not included the Cray wasn necessary And leaving something out made the machine faster What the Cray good for was designed used for scientific applications that required lots and lots floating point manipulations wouldn make good instructional machine don want hook lotsa terminals and wouldn much fun try implement modern operating system How used most often separate not fast powerful computer was hooked what commonly called host computer The host where you all you editing and debugging programs The host also maintains queue jobs run the Cray One one the jobs are run the only thing that the Cray doing running the final jobs often with LOTS data Although its operating system would allow the multi tasking had more than program running simultaneously ability was not often used instruction set fixed length instructions either bit variablility that depends the number operands number operands possible for instruction number and kind instructions codes are bits long giving instrucitons This includes complete integer and floating point instructions Notice that missing from the instruction set are character byte manipulation duplicates anything integer divide etc Data representation vastly simpified from what seen far There are ONLY complement integers and floating point numbers ALL accesses memory are done WORD chunks word the Cray bits All instructions operate single size data Either bit word address bits addressing modes strikingly similar MIPS Register Mode instruction code specifies exactly where the data Base Displacement Mode Used only for load and store instructions REGISTERS There are ENORMOUS number registers There are types registers registers stands for scalar These are bit regs They are used for all sorts data but not addresses There them registers These are bit backup registers for the registers you were some heavy programming the Cray you find these registers very useful This partially because you run out registers quickly you need temporary storage but don want your program store main memory slow There also instruction that allows you load block memory the registers That instruction bunch loads registers stands for address These are bit regs They are used for addresses and rather limited extent integer counters registers These are backups the regs and are used the same manner the regs registers stands for vector There are sets regs Each set has bit registers That lot They are used mainly for processing large quantities array data Their use makes the Cray very fast single instruction that uses vector register set will cause something happen each the registers within that set SIMD hardware stack support for stack accesses all There special stack pointer register cache none There many registers that there isn really need for one size machine bit bigger than refridgerators speed machine Significantly faster than the VAX and For while was the fastest machine around price machine analogy some very pricey restaurants you need see the prices the menu you can afford eat there Probably about million for the basic machine when they first came out Cray came with full time hardware engineer field service person Why Down time Cray very expensive due the way they are expected used Waiting for field service come was considered too expensive how many instructions get executed one time its debatable There can more than instruction some point its execution time pipelined machine This can only far only new instruction can started each clock cycle complexity ALU There are actually quite few alu the machine Cray calls them functional units Each one specialized piece hardware that does its own job fast can done Each them could conceivably working the same time the VAX The VAX was popular and commercially successful computer put out the early DEC Digital Equipment Corp might characterized the term CISC RISC Reduced Instruction Set Computer CISC Complex Instruction Set Computer CISC computer often characterized many instructions lots addressing modes this one debatable variable length instructions memory memory architecture Some details LOTS INSTRUCTIONS integer arithmetic different opcode for varying size data logical different opcode for varying size data address manipulations bit manipulations control instructions conditional branches jumps looping instructions procedure mechanisms call and return instructions there were more than floating point character string manipulations crc Cyclic Redundancy Check decimal string arithmetic presuming representation binary coded decimal string edit overall more than instructions opcodes were variable length but always multiple most opcodes were specified the first bits instruction REGISTERS bit general purpose registers except that they really weren all general purpose the note that the user can change the will stack pointer frame pointer argument pointer address where procedure parameters are stored sometimes the stack and sometimes main memory DATA TYPES byte word bits longword bits quadword bits octaword bits floating point bits bits exponent floating point bits bits exponent floating point bits bits exponent floating point bits bits exponent character string consecutive bytes memory specified always starting address and the length bytes numeric string the ASCII codes that represent integer packed decimal string consecutive sequence bytes memory that represent BCD integer BCD digits are each bit quantities nibble example the integer represented numbering each instruction operates fixed data type OPERAND ACCESS the number operands for each individual instructions fixed the location operands definitely not fixed they can memory registers and the variety addressing modes that specify the location operand large equivalent MIPS add addl operands operate bit quantity there also addb addw addb addw addl and this just for complement addition This VERY simple use addressing modes The syntax operand specification allows MANY possible addressing modes every one discussed chapter plus more for example addl uses Register Direct addressing mode for the first operand operation the address the first operand load the operand the address add the contents and place the result into The addressing mode for each operand can often different One type addressing mode not discussed the text sticks out auto increment and auto decrement They have the side effect changing the address used get operand well specifying address addl operation the address the first operand load the operand the address then increment the contents the address then add data loaded from memory the contents and place the result into the amount added the contents depends the size the data being operated this case will longwords are bytes MACHINE CODE Together with each operand addressing mode specification Each operand specification requires least byte Format for the simple addl bit opcode mode register which register Format for the addl same bit opcode mode which register Each instruction has bit opcode There will bit operand specifier for each operand that the instruction specifies Because the large number and variety addressing modes operand specification can much more than byte Example Immediates are placed directly after their specification within the code PERFORMANCE the term MIPS millions instructions per second really came from the VAX the VAX ran just about MIPS note that this term misleading Instructions take variable times fetch and execute the performance depends the program SIZE one version the VAX was about the size large capacity washing machine another version the VAX was about the size refridgerators standing side side 