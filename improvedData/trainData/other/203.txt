MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Wednesday Nov GMT Virtual Reality Video ConferencingVirtual Reality Video Conferencing Implemented Canvas High Performance Graphics Engine Projects being developed part course Virtual Reality Video Conferencing Video Texture Mapping Design Canvas dRelated Links Brian Smith project advisor homepageCU SeeMe Immersive Desktop TeleconferencingInteractive Media Games MicrosoftTcl Project Sun Microsystems Laboratories Tcl ManualVirtual Reality Modeling LanguageDesktop Video Conferencing Product SurveyMBONE the Multicast Backbone the Internet Graphics Engines List MIME Version Server CERN Date Tuesday Jan GMT Content Type text html Content Length Last Modified Wednesday Aug GMT Theory RefinementTheory Refinement view paper click the open book image Combining Symbolic and Connectionist Learning Methods Refine Certainty Factor Rule Bases Jeffrey Mahoney Thesis Department Computer Sciences University Texas Austin May This research describes the system RAPTURE which designed revise rule bases expressed certainty factor format Recent studies have shown that learning facilitated when biased with domain specific expertise and have also shown that many real world domains require some form probabilistic uncertain reasoning order successfully represent target concepts RAPTURE was designed take advantage both these results Beginning with set certainty factor rules along with accurately labelled training examples RAPTURE makes use both symbolic and connectionist learning techniques for revising the rules order that they correctly classify all the training examples modified version backpropagation used adjust the certainty factors the rules information gain heuristic used add new rules and the Upstart algorithm used create new hidden terms the rule base Results refining four real world rule bases are presented that demonstrate the effectiveness this combined approach Two these rule bases were designed identify particular areas strands DNA one for identifying infectious diseases and the fourth attempts diagnose soybean diseases The results RAPTURE are compared with those backpropagation KBANN and other learning systems RAPTURE generally produces sets rules that are more accurate that these other systems often creating smaller sets rules and using less training time Refinement Bayesian Networks Combining Connectionist and Symbolic Techniques Sowmya Ramanchandran proposal Department Computer Sciences University Texas Austin Bayesian networks provide mathematically sound formalism for representing and reasoning with uncertain knowledge and are such widely used However acquiring and capturing knowledge this framework difficult There growing interest formulating techniques for learning Bayesian networks inductively While the problem learning Bayesian network given complete data has been explored some depth the problem learning networks with unobserved causes still open this proposal view this problem from the perspective theory revision and present novel approach which adapts techniques developed for revising theories symbolic and connectionist representations Thus assume that the learner given initial approximate network usually obtained from expert Our technique inductively revises the network fit the data better Our proposed system has two components one component revises the parameters Bayesian network known structure and the other component revises the structure the network The component for parameter revision maps the given Bayesian network into multi layer feedforward neural network with the parameters mapped weights the neural network and uses standard backpropagation techniques learn the weights The structure revision component uses qualitative analysis suggest revisions the network when fails predict the data accurately The first component has been implemented and will present results from experiments real world classification problems which show our technique effective will also discuss our proposed structure revision algorithm our plans for experiments evaluate the system well some extensions the system Novel Application Theory Refinement Student Modeling Paul Baffes and Raymond MooneyProceedings the Thirteenth National Conference Aritificial Intelligence Portland August AAAI Theory refinement systems developed machine learning automatically modify knowledge base render consistent with set classified training examples illustrate novel application these techniques the problem constructing student model for intelligent tutoring system ITS Our approach implemented ITS authoring system called Assert which uses theory refinement introduce errors into initially correct knowledge base that models incorrect student behavior The efficacy the approach has been demonstrated evaluating tutor developed with Assert with students tested classification task covering concepts from introductory course the programming language The system produced reasonably accurate models and students who received feedback based these models performed significantly better post test than students who received simple reteaching Refinement Based Student Modeling and Automated Bug Library Construction Paul Baffes and Raymond MooneyJournal Artificial Intelligence Education critical component model based intelligent tutoring sytems mechanism for capturing the conceptual state the student which enables the system tailor its feedback suit individual strengths and weaknesses useful such modeling technique must practical the sense that models are easy construct and effective the sense that using the model actually impacts student learning This research presents new student modeling technique which can automatically capture novel student errors using only correct domain knowledge and can automatically compile trends across multiple student models This approach has been implemented computer program ASSERT using machine learning technique called theory refinement which method for automatically revising knowledge base consistent with set examples Using knowledge base that correctly defines domain and examples student behavior that domain ASSERT models student errors collecting any refinements the correct knowledege base which are necessary account for the student behavior The efficacy the approach has been demonstrated evaluating ASSERT using students tested classification task covering concepts from introductory course the programming language Students who received feedback based the models automatically generated ASSERT performed significantly better post test than students who received simple teaching Revising Bayesian Network Parameters Using Backpropagation Sowmya Ramachandran and Raymond MooneyProceedings the International Conference Neural Networks ICNN Special Session Knowledge Based Artificial Neural Networks Washington June The problem learning Bayesian networks with hidden variables known hard problem Even the simpler task learning just the conditional probabilities Bayesian network with hidden variables hard this paper present approach that learns the conditional probabilities Bayesian network with hidden variables transforming into multi layer feedforward neural network ANN The conditional probabilities are mapped onto weights the ANN which are then learned using standard backpropagation techniques avoid the problem exponentially large ANNs focus Bayesian networks with noisy and noisy and nodes Experiments real world classification problems demonstrate the effectiveness our technique Automatic Student Modeling and Bug Library Construction using Theory Refinement Paul Baffes Thesis Department Computer Sciences University Texas Austin December The history computers education can characterized continuing effort construct intelligent tutorial programs which can adapt the individual needs student one one setting critical component these intelligent tutorials mechanism for modeling the conceptual state the student that the system able tailor its feedback suit individual strengths and weaknesses The primary contribution this research new student modeling technique which can automatically capture novel student errors using only correct domain knowledge and can automatically compile trends across multiple student models into bug libraries This approach has been implemented computer program ASSERT using machine learning technique called theory refinement which method for automatically revising knowledge base consistent with set examples Using knowledge base that correctly defines domain and examples student behavior that domain ASSERT models student errors collecting any refinements the correct knowledge base which are necessary account for the student behavior The efficacy the approach has been demonstrated evaluating ASSERT using students tested classification task using concepts from introductory course the programming language Students who received feedback based the models automatically generated ASSERT performed significantly better post test than students who received simple reteaching Comparing Methods For Refining Certainty Factor Rule Bases Jeffrey Mahoney and Raymond Mooney Proceedings the Eleventh International Workshop Machine Learning Rutgers July This paper compares two methods for refining uncertain knowledge bases using propositional certainty factor rules The first method implemented the RAPTURE system employs neural network training refine the certainties existing rules but uses symbolic technique add new rules The second method based the one used the KBANN system initially adds complete set potential new rules with very low certainty and allows neural network training filter and adjust these rules Experimental results indicate that the former method results significantly faster training and produces much simpler refined rule bases with slightly greater accuracy Modifying Network Architectures For Certainty Factor Rule Base Revision Jeffrey Mahoney and Raymond Mooney Proceedings the International Symposium Integrating Knowledge and Neural Heuristics Pensacola May ISIKNH This paper describes RAPTURE system for revising probabilistic rule bases that converts symbolic rules into connectionist network which then trained via connectionist techniques uses modified version backpropagation refine the certainty factors the rule base and uses information gain heuristic Quinlan add new rules Work currently under way for finding improved techniques for modifying network architectures that include adding hidden units using the UPSTART algorithm Frean case made via comparison with fully connected connectionist techniques for keeping the rule base close the original possible adding new input units only needed Extending Theory Refinement Rules Paul Baffes and Raymond Mooney Informatica recent years machine learning research has started addressing problem known theory refinement The goal theory refinement learner modify incomplete incorrect rule base representing domain theory make consistent with set input training examples This paper presents major revision the EITHER propositional theory refinement system Two issues are discussed First show how run time efficiency can greatly improved changing from exhaustive scheme for computing repairs iterative greedy method Second show how extend EITHER refine MofN rules The resulting algorithm Neither New EITHER more than order magnitude faster and produces significantly more accurate results with theories that fit the MofN format demonstrate the advantages NEITHER present experimental results from two real world domains Learning Model Students Using Theory Refinement Detect Misconceptions Paul Baffes proposal Department Computer Sciences University Texas Austin new student modeling system called ASSERT described which uses domain independent learning algorithms model unique student errors and automatically construct bug libraries ASSERT consists two learning phases The first application theory refinement techniques for constructing student models from correct theory the domain being tutored The second learning cycle automatically constructs the bug library extracting common refinements from multiple student models which are then used bias future modeling efforts Initial experimental data will presented which suggests that ASSERT more effective modeling system than other induction techniques previously explored for student modeling and that the automatic bug library construction significantly enhances subsequent modeling efforts Symbolic Revision Theories With Rules Paul Baffes and Raymond Mooney Proceedings the Thirteenth International Joint Conference Artificial Intelligence Chambery France IJCAI This paper presents major revision the EITHER propositional theory refinement system Two issues are discussed First show how run time efficiency can greatly improved changing from exhaustive scheme for computing repairs iterative greedy method Second show how extend EITHER refine rules The resulting algorithm NEITHER New EITHER more than order magnitude faster and produces significantly more accurate results with theories that fit the format demonstrate the advantages NEITHER present preliminary experimental results comparing EITHER and various other systems refining the DNA promoter domain theory Combining Connectionist and Symbolic Learning Refine Certainty Factor Rule Bases Jeffrey Mahoney and Raymond Mooney Connection Science Special issue Architectures for Integrating Neural and Symbolic Processing This paper describes Rapture system for revising probabilistic knowledge bases that combines connectionist and symbolic learning methods Rapture uses modified version backpropagation refine the certainty factors Mycin style rule base and uses information gain heuristic add new rules Results refining three actual expert knowledge bases demonstrate that this combined approach generally performs better than previous methods Refinement First Order Horn Clause Domain Theories Bradley Richards and Raymond Mooney Machine Learning Knowledge acquisition difficult and time consuming task and error prone any human activity The task automatically improving existing knowledge base using learning methods addressed new class systems performing theory refinement Until recently such systems were limited propositional theories This paper presents system FORTE First Order Revision Theories from Examples for refining first order Horn clause theories Moving first order representation opens many new problem areas such logic program debugging and qualitative modelling that are beyond the reach propositional systems FORTE uses hill climbing approach revise theories identifies possible errors the theory and calls library operators develop possible revisions The best revision implemented and the process repeats until further revisions are possible Operators are drawn from variety sources including propositional theory refinement first order induction and inverse resolution FORTE has been tested several domains including logic programming and qualitative modelling Combining Symbolic and Neural Learning Revise Probabilistic Theories Jeffrey Mahoney Raymond Mooney Proceedings the Machine Learning Workshop Integrated Learning Real Domains Aberdeen Scotland July This paper describes RAPTURE system for revising probabilistic theories that combines symbolic and neural network learning methods RAPTURE uses modified version backpropagation refine the certainty factors Mycin style rule base and uses information gain heuristic add new rules Results two real world domains demonstrate that this combined approach performs well better than previous methods Using Theory Revision Model Students and Acquire Stereotypical Errors Paul Baffes and Raymond Mooney Proceedings the Fourteenth Annual Conference the Cognitive Science Society Bloomington July Student modeling has been identified important component the long term development Intelligent Computer Aided Instruction ICAI systems Two basic approaches have evolved model student misconceptions One uses static predefined library user bugs which contains the misconceptions modeled the system The other uses induction learn student misconceptions from scratch Here present third approach that uses machine learning technique called theory revision Using theory revision allows the system automatically construct bug library for use modeling while retaining the flexibility address novel errors Preliminary PAC Analysis Theory Revision Raymond Mooney March Computational Learning Theory and Natural Learning Systems Vol Petsche Judd and Hanson Eds MIT Press This paper presents preliminary analysis the sample complexity theory revision within the framework PAC Probably Approximately Correct learnability theory formalizing the notion that the initial theory close the correct theory show that the sample complexity optimal propositional Horn clause theory revision algorithm delta epsilon where the syntactic distance between the initial and correct theories the size initial theory the number observable features and epsilon and delta are the standard PAC error and probability bounds The paper also discusses the problems raised the computational complexity theory revision Automated Debugging Logic Programs via Theory Revision Raymond Mooney Bradley Richards Proceedings the Second International Workshop Inductive Logic Programming Tokyo Japan June This paper presents results using theory revision system automatically debug logic programs FORTE recently developed system for revising function free Horn clause theories Given theory and set training examples performs hill climbing search attempt minimally modify the theory correctly classify all the examples FORTE makes use methods from propositional theory revision Horn clause induction FOIL and inverse resolution The system has has been successfully used debug logic programs written undergraduate students for programming languages course Batch versus Incremental Theory Refinement Raymond Mooney Proceedings AAAI Spring Symposium Knowledge Assimilation Standford March Most existing theory refinement systems are not incremental However any theory refinement system whose input and output theories are compatible can used incrementally assimilate data into evolving theory This done continually feeding its revised theory back its input theory incremental batch approach which the system assimilates batch examples each step seems most appropriate for existing theory revision systems Experimental results with the EITHER theory refinement system demonstrate that this approach frequently increases efficiency without significantly decreasing the accuracy the simplicity the resulting theory However the system produces bad initial changes the theory based only small amount data these bad revisions can snowball and result overall decrease performance Multistrategy Approach Theory Refinement Raymond Mooney Dirk Ourston Machine Learning Multistrategy Approach Vol Michalski Teccuci eds Morgan Kaufman San Mateo This chapter describes multistrategy system that employs independent modules for deductive abductive and inductive reasoning revise arbitrarily incorrect propositional Horn clause domain theory fit set preclassified training instances combining such diverse methods EITHER able handle wider range imperfect theories than other theory revision systems while guaranteeing that the revised theory will consistent with the training data EITHER has successfully revised two actual expert theories one molecular biology and one plant pathology The results confirm the hypothesis that using multistrategy system learn from both theory and data gives better results than using either theory data alone Theory Refinement Combining Analytical and Empirical Methods Dirk Ourston and Raymond Mooney Artificial Intelligence This article describes comprehensive approach automatic theory revision Given imperfect theory the approach combines explanation attempts for incorrectly classified examples order identify the failing portions the theory For each theory fault correlated subsets the examples are used inductively generate correction Because the corrections are focused they tend preserve the structure the original theory Because the system starts with approximate domain theory general fewer training examples are required attain given level performance classification accuracy compared purely empirical system The approach applies classification systems employing propositional Horn clause theory The system has been tested variety application domains and results are presented for problems the domains molecular biology and plant disease diagnosis Improving Shared Rules Multiple Category Domain Theories Dirk Ourston and Raymond Mooney Proceedings the Eighth International Machine Learning Workshop Evanston June This paper presents approach improving the classification performance multiple category theory correcting intermediate rules which are shared among the categories Using this technique the performance theory one category can improved through training entirely different category Examples the technique are presented and experimental results are given Constructive Induction Theory Refinement Raymond Mooney and Dirk Ourston Proceedings the Eighth International Machine Learning Workshop Evanston June This paper presents constructive induction techniques recently added the EITHER theory refinement system These additions allow EITHER handle arbitrary gaps the top middle and bottom incomplete domain theory Intermediate concept utilization employs existing rules the theory derive higher level features for use induction Intermediate concept creation employs inverse resolution introduce new intermediate concepts order fill gaps theory that span multiple levels These revisions allow EITHER make use imperfect domain theories the ways typical previous work both constructive induction and theory refinement result EITHER able handle wider range theory imperfections than does any other existing theory refinement system Theory Refinement with Noisy Data Raymond Mooney and Dirk Ourston Technical Report Artificial Intelligence Lab University Texas Austin March This paper presents method for revising approximate domain theory based noisy data The basic idea avoid making changes the theory that account for only small amount data This method implemented the EITHER propositional Horn clause theory revision system The paper presents empirical results artificially corrupted data show that this method successfully prevents over fitting other words when the data noisy performance novel test data considerably better than revising the theory completely fit the data When the data not noisy noise processing causes significant degradation performance Finally noise processing increases efficiency and decreases the complexity the resulting theory estlin utexas edu Date Tue Jan GMT Server Apache dev Connection close Content Type text html Expires Tue Jan GMT Last Modified Fri Dec GMT ETag baecbd Content Length Accept Ranges bytes MIT Artificial Intelligence Laboratory Home PageMIT Artificial Intelligence Laboratory The principal goals the Artificial Intelligence Laboratory are develop computational theory intelligence and develop high impact practical applications areas such information transportation enhanced reality the human computer interface modeling and simulation image understanding decision analysis and impact prediction model based engineering design medicine and supporting computing technology You can learn about specific projects through our InfoLab Group natural language server working through some the following links Director IntroductionPublicationsResearchEventsPeopleCompany SpinoffsAround MIT EECS Lab for Comp Sci MIT Phone Book Food Fun etc Reference topics Libraries MIT and Net pages and more Other topics Social issues Finance and just plain fun Around the lab Info files Reading Room and other resources Robert Thau webmaster mit eduA nearly icon free version this page available Date Mon Nov GMT Server NCSA Content type text html Last modified Wed Mar GMT Content length Section Late Policy Late Policy Programming assignments are due the end class the date specified Any assignments handed after class but before midnight the following day receive automatic penalty For each subsequent day late another deducted weekends count two days Finally assignment will accepted five more days late Many your programming assignments will handed online When you hand assignment online the files are timestamped with the current time and date when you copy them your handin directory This timestamp will used check they were handed time whether late day penalties apply you are asked hand printed copy your program and output then hand class the date specified you must hand printouts late then please give them person this not possible then you must get another consultant sign and date your work and slip under office door put mailbox the floor the absence signature and date the hand time determined when receive which could several days later Make sure you have your name and section number clearly written any printouts that you hand avoid handing your assignments late strongly recommend starting them soon possible Debugging program and getting work correctly can take significantly longer than you expect Copyright copy Gareth Bestor bestor wisc edu Last modified March 