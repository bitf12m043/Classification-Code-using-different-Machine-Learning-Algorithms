MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Thursday Jan GMT JPEG Encoding Using Perceptual Quality Multimedia SystemsJPEG Encoding using Perceptual Quality Nobuhiko Mukai mukai cornell edu Lucy yuwu cornell edu Mikio Sakurai msakurai sunlab cit cornell edu Abstract The key point image compression achieve low bit rate the digital representation input image video signal with minimum perceived loss picture quality Over the past several years there have been many attempts incorporate perceptual masking models into image compression system Based the pre quantization developed two new models Compared JPEG default setting both our models significantly lower the bit rate and keep the almost same image quality Introduction The key point image compression achieve low bit rate the digital representation input image video signal with minimum perceived loss picture quality Since the ultimate criterion quality judged measured the human receiver important that the compression coding algorithm minimizes perceptually meaningful measures signal distortion JPEG default quantization tables are based psychovisual thresholding and are derived empirically But because only one available for every image the default image independent and can not used achieve the optimized compression result for each specific image Some perceptual models have been developed calculate the image dependent But because every block the image contributes different properties the total image one that best for the whole image not always best for every block can quantize every block using different specifically suitable for that block can get the most optimized compression result for every block Because JPEG allows only one for each image pre quantization proposed Johnston and Safranek For every block one specific masking threshold calculated and used zero out the perceptual irrelevant coefficients while the other coefficients passed unchanged Then one base will finally used quantize for all the remaining coefficients each block Despite the benefits simple implementation the model has the disadvantage computing single masking elevation for each input block This means that there information about the distribution energy within the block This problem can overcome applying the contrast masking model for each DCT coefficient model The computation for model somewhat complex This led design second one model based the luminance ratio block total image replace the model This second model has the same single masking elevation problem but the calculation more simple Our test result shows compared the JPEG default setting both our models reduced the bit rate with little perceived loss quality The rest this paper organized follows Section describes algorithms prequantize JPEG image Section describes two perceptual models designed Section describes the detailed evaluation our models and section reviews related work and future extensions Prequantization Quantization The Baseline JPEG encoder consists three major components Forward DCT Quantization and Entropy Coding The step the quantization take the raw output the DCT and quantize the coefficients dividing coefficient coefficient and rounding the nearest integer The purpose quantization achieve compression representing DCT coefficients with greater precision than necessary achieve the desired image quality other words the goal this processing step discard information which not visually significant Perceptual Model Many studies have attempted derive computational model this visual masking level For each block the input image the model attempts determine what degree the features present that block inhibit the visual system from the distortion introduced the compression decompression process From these points possible determine masking threshold for each DCT coefficient model Johnston and Safranek have developed framework for computing locally adaptive masking model based engineering framework They assume that the total masking level for any block the input can represented base masking level and other multiplicative elevation factors that represent the contribution input dependent properties the visual system the total mask This model may expressed Global Local where the masking level for frequency the input block Global the base masking level which depends only global properties and Local handles the image specific local variation the masking threshold The adaptation derived function the block standard deviation using the following formula Figure model This applies all the coefficients The masking elevation for the coefficient always set unity This model has the advantage simple implementation and works well practice has the disadvantage computing single masking elevation for each input block Figure illustrates the structure such encoder The forward transformation identical the one baseline JPEG this point the DCT coefficients are input the perceptual model which generates the data dependent quantization table for that block This table and the raw DCT coefficients are now input pre quantizer The purpose this module zero out the coefficients that have magnitude less than the corresponding entry the quantization table for that block and pass the other coefficients through unchanged Finally these prequantized coefficients are quantized and entropy coded standard JPEG the dequantization step only the base used Figure structure encoder with prequantization Our Models Our models intends take advantage the above prequantization method Model The model uses the perceptual model but does not consider the distribution the energy within the block when calculating the block specific masking threshold overcome this problem employ visual masking that has been widely used vision models based work Legge and Foley Given DCT coefficient and luminance threshold the masked threshold MAX constant that lies between and When masking occurs and when have Weber Law behavior For our experiment empirical value was used our implementation calculate the masking threshold did not calculate the luminance threshold using Peterson model suggested Watson addition indicated JPEG standard JPEG default quantization tables are based psychovisual thresholding and are derived empirically divided the almost indistinguishable image can reconstructed That means the default can treated general luminance threshold replaced the equation JPEG default value Global masking level used default JPEG Model The masking threshold computation for model rather complex This led design the second model model based the luminance ratio block total image This model has the same single masking elevation problem but the calculation more simple Basically model follows the masking model equation But for the calculation multiplicative elevation factors Local use the luminance ratio each block the total image Well known Weber Law expressed constant luminance and the just noticeable difference This equation means our perception sensitive luminance contrast rather than the absolute luminance values themselves given luminance the block luminance only little bit differ from luminance then the block less visible and can drop lot perceptually unimportant information The adaptation derived function the ratio the block average luminance the luminance average the total image using the following formula Figure model masking model based luminance ratio Maximum threshold elevation max and Minimum Threshold Minimum luminance ratio min are the parameters need experiment for Global masking level used default JPEG Image Quality and Bitrate compared the bitrate bits pixel and Image quality our model and model with those the Baseline JPEG For model first need optimize the parameter worked several images and found that these two parameters max min are not strongly sensitive SNR the different value luminance ratio parameter min SNR almost constant Threshold elevation parameter max has weak relation with SNR and gets bigger SNR becomes worse This feature common all images Table shows result got image Lena Table Parameter max min dependence SNR For the following experiment choose the preferable value max and min for each parameter model Five images were used this experiment photo human face Lena flower scene flowers photo animal face baboon two photo airplane and Pitts Bitrate calculated after compressing the image file using the pack huffman coding program For the evaluation the image quality used two evaluation method The first SNR signal noise ratio order provide further insight into the subjective quality the models used DCON metric This algorithm takes input two images reference and test compare the difference luminance pixel pixel The formula follows DCON sum This method simple but very competitive with other complicated human eye model metric Table summarize the results these experiments Table Image quality SNR DCON Bitrate Both our model and model compress better than the Baseline JPEG with almost perceptual loss quality Figure shows one example flowers output image our models comparison with original image and that Baseline JPEG original image Baseline JPEG model model Figure sample image comparison Related work and Conclusions There have been many attempts incorporate perceptual masking model into image compression systems Johnston Safranek model and Watson model are perhaps the most well known perceptual model model has investigated locally optimized prequantization table Watson model has investigated image dependent masking model which incorporates not only global conditions but also accounts for local contrast masking Klein Berkery optometry school has reported techniques for improving the quality JPEG with high compression rate viewpoint vision community suggests that with improved human vision models the quantization step could made more effective considering effects such mean luminance color bandpass filters spatio temporal frequency and orientation contrast masking and human contrast sensitivity The primary contribution our work that details encoding specific prequantization algorithms that compress images high compression rate with minimal artifact Our future work will include extending this work include other human eye related factors such spatio temporal frequency and orientation References Johnston and Safranek Perceptually Tuned Sub band Image Coder With Image Dependent Quantization and Post quantization Data Compression Proc ICASSP Glasgow Scotland vol May Legge and Foley Contrast masking human vision Journal the Optical Society America Ahumada and Peterson Luminance Model Based DCT quantization for color image compression SPIE Human Vision Visual Processing and Digital Display III Vol Watson DCT quantization matrices visually optimized for individual images SPIE Human Vision Visual Processing and Digital Display Vol Feb Daniel Fuhrmann John Baro and Jerome Cox Experimental evaluation psychophysical distortion metrics for JPEG encoded images SPIE Human Vision Visual Processing and Digital Display Vol Daly The visible difference predictor algorithm for the assessment image fidelity SPIE Human Vision Visual Processing and Digital Display III Vol Mannos and Sakrison The effects visual fidelity criterion the encoding images IEEE Transaction Information Theory Stanley Klein Amnon Silverstein and Thom Carney Relevance human vision JPEG DCT compression SPIE Human Vision Visual Processing and Digital Display III Vol postscript fileFile last modified December MIME Version Server CERN Date Monday Jan GMT Content Type text html Content Length Spy Sammy Spy Sammy rwho This output will tell you which machines have session running finger This output will tell you about account here utexas edu utexas edu phingerd responds Mon Jan Last login never logged Name Samuel Guyer Org Computer Sciences TAY Austin Austin Office Office Home Birthday May Login sammy Sponsor porter Group grad Type phd Shell lusr bin tcsh Expires Dec Server hank sammy Quota unlimited Mailbox UTxCS local net via NFS Status mailbox was modified Mon Jan mailbox was accessed Fri Jan PLAN logged Try finger sammy darkwing utexas edu Back home page Date Tue Jan GMT Server Apache Content type text html Content length Last modified Wed Sep GMT LecturesCS Lectures What Expert System January Elementary Logic January Reasoning Knowledge and Learning January Development Process and Experts January Lecture Notes for Feb Lecture Notes for Feb Lecture Notes for Feb Lecture Notes for March Lecture Notes for March and March Lecture Notes for March Lecture Notes for March These other ones are not updated yet keep you posted Prolog Syntax Unification Grammars and Natural LanguagesClick HERE return the homepage Date Tue Nov GMT Server NCSA Content type text html Last modified Thu Oct GMT Content length Fix for Project Fix for Project mentioned class the suggested algorithm for Project algorithm has very small change deadlocking preemptive scheduling effect couple teams have actually experienced this problem showing that Murphy law valid something can wrong eventually will Deadlocks due the bug have been reported under the Windows Java implementation which has built preemptive scheduling know anybody has observed them under Solaris even with the ThreadScheduler Disclaimers This problem applies only the second hygienic algorithm your algorithm deadlocks you have some other bug your program You are not required fix this bug get full credit for the assignment only telling your about case you having problems tracking down the cause deadlock and suspect might due this problem very likely that the deadlock you seeing not due this problem but some more ordinary bug your program your program deadlocks under Solaris without the ThreadScheduler certainly because some other bug turn off the ThreadScheduler simply comment out the line sched start deadlocks only under Windows more likely but not certain that the bug caused this problem The problem arises because synchronized methods contain calls other synchronized methods and possible set circular pattern calls between distinct objects For example and are neighboring Philosopher objects takeForks calls requestFork and putForks calls giveFork Suppose thread preempted while active not waiting takeForks and thread allowed enter putForks this point locking and locking When calls giveFork will block waiting for mutex and when subsequently resumed and calls requestFork will block mutex that point and are deadlocked today class Oct Joni Baker pointed out that this particular scenario cannot occur the code carefully written prevent duplicate requests the sample code wrote the blackboard putForks only calls giveFork has previously requested the fork from but takeForks only calls requestFork has not previously requested class said that more complicated scenario could devised show that deadlock still possible but couldn think one the spot seems require least three philosophers Consider circular pattern philosophers and each pair sharing one fork three philosopher version the original dining philosophers problem Assume eating has the forks shares with and and has the fork she shares with Let and represents the threads for philosophers and Suppose gets hungry just before finishes eating and gets hungry just after The following sequence events possible gets hungry thread enters takeForks and calls requestFork which returns false because eating Thread preempted finishes eating enters putForks and seeing that there request from tries call giveFork Thread blocked because still active takeForks gets hungry enters getForks She already has the fork she shares with tries call requestFork but blocked because still active putForks Thread resumed and tries call getFork that point the three threads are deadlocked Here the example couldn show this morning because there was projector This the original version takeForks from the solution the project private synchronized void takeForks state HUNGRY int forksHave Number forks currently owned while forksHave forks length for int forks length forks have forksHave else forks haveRequested phil forks neighborId requestFork forks forkId forks clean true forks have true forksHave else forks haveRequested true forksHave forks length forksHave try wait catch InterruptedException state EATING The trick split takeForks into two pieces The first called forksNeeded synchronized procedure that does all the necessary manipulation shared variables The remaining code does not touch any shared variables that ever change does not have synchronized This procedure finds fork that this philosopher doesn have and needs request and returns its index such fork exists because all forks are here returns and sets the local state EATING such fork exists because all absent forks have already been requested waits and tries again private synchronized int neededFork state HUNGRY for int forksHave Number forks currently owned for int forks length forks have forksHave else forks haveRequested forks haveRequested true return forksHave forks length state EATING return try wait catch InterruptedException private void takeForks for int neededFork return phil forks neighborId requestFork forks forkId giveFork forks forkId give myself the fork the end class Patrick Gaffney pointed out that there still danger race condition What happens thread preempted takeForks after its call requestFork has returned true but before gets chance call giveFork this point neither nor thinks has the fork The call requestFork has updated data structure indicate that does not have but giveFork has not had chance update variables show that has This not necessarily problem but the code has carefully written that can cope with this unusual situation For example allowed run next may become hungry and seeing that longer has the fork may call requestFork which will find that doesn have the fork that being requested this point neither philosopher thinks has the fork Copyright Marvin Solomon All rights reserved 