Date Mon Nov GMT Server NCSA Content type text html Last modified Fri Sep GMT Content length Project Ideas Fall Term Project Ideas Marvin Solomon solomon wisc edu Last updated Fri Sep CDT Contents General Comments Due Dates Project Proposal Project Suggestions Naming Large Computer Networks Group Communication Security Audit File Servers for Workstations Load Balancing Security and Authentication Random Software testing Navigating the World Wide Web Topology the Web Self perpetuating programs General Purpose Transaction Package Distributed Shared Memory Performance Study Distributed Persistent Garbage Consumer Reports Condor Specialized NFS Servers Shore Madison Research Projects Tempest General Comments The projects are intended give you opportunity study particular area related operating systems Some the projects will require test implementations measurement studies simulations some combination Most will require literature search before you begin The project suggestions below are briefly stated They are intended guide you into particular areas and you are expected expand these suggestions into full project descriptions This gives you more freedom selecting area and more burden defining your own project There may more issues listed for project than you can cover would prefer you think topic that not listed below you you might want come and talk with can work out reasonable project description Some projects are appropriate for groups two more There upper bound the size the group but beware that groups more than persons are very hard manage will not get involved labor disputes you will all hang together you will all hanged separately Feel free ask for opinions whether the size proposed team appropriate for given project some cases project area straddles the boundary between operating systems and some other area such database architecture artificial intelligence programming languages Such projects are intended for students with background and interests the second area explore the interface They are not intended substitutes for the regular courses the second area For example you have little background database you should take before choosing topic that requires database sophistication Most topics call for careful literature search before the proposal due date Due Dates Project Proposal Due Tuesday October Final Report Due Thursday December Project Proposal You are hand expanded description your project see the due date above you are free turn sooner The project proposal should brief two pages less but very specific about what you intend must long enough convince that you have reasonable and achievable project not trivial and not too large You may have revise your description before will acceptable The project description should describe the problem that you are addressing how you will about working this project the steps you will take what results you expect and what you expect produce what resources you will need and brief schedule for your project must reasonably well written Projects that involve implementation simulation should indicate what resources are required You should make ordered list features together with your current best guess what you intend accomplish together with contingency plans case unforeseen problems will definitely and then turns out impractical however will instead time allows will also things especially well would also like try and that order You should have already done substantial amount background work the project before writing the proposal For example you intend simulation you should have familiarized yourself with all available software tools and decided which are most appropriate you intend build useful tool such threads package distributed make tool you should know about all such tools that have been built before and described the open literature There reason why you shouldn something that has been done before After all the main purpose this project learning But has been done before you should learn about previous attempts that you can learn from their mistakes rather than simply repeating them yourselves will review all proposals and offer comments Sketchy proposals will get sketchy comments will also indicate opinion the quality each proposal The Project Report the end the semester you will hand project report The length will vary depending the type project but paper should over pages unless you get specific prior approval for longer report famous person once wrote letter Please excuse the length this letter did not have the time make shorter all cases the quality the writing will factor the grade You will also make short oral presentation the class and appropriate demonstrate your software Peer Reviewing Your project report should read and reviewed least one other person the class you select the person This person will critique your paper and you will use the critique revise your paper Project Suggestions Naming Large Computer Networks Consider the naming resources mail address servers etc distributed environment with many more computers This environment might include universities companies and government agencies Each these areas might include other environments the university might include department computer center ECE department etc name service for such environment special purpose distributed database server can register services Each registration includes description the service provided mail delivery and information necessary use the service connect address port client can look for specific service How deliver mail host gjetost wisc edu make more generic request Find nearby printer that allows student access and supports PostScript Design name service for such environment Issues such performance local autonomy scope authority reliability protection and expandability may discussed How are names used What studies might you find out What are the limits the size the environment that your design will able support Evaluate your design through pilot implementation simulation For background read about Grapevine Clearinghouse the Arpanet Domain Name Service see for more specific references Group Communication Several researchers have developed protocols and software packages facilitate communication among processes distributed program process supplies information delivering messages the system and consumes registering requests The system forwards each message processes that expressed interest Details differ considerably among the various proposals Examples include the FIELD system from Brown university the ISIS system from Cornell and the Linda language from the University Maryland Numerous other proposals may seen variations this theme including other past and proposed projects such DREGS Condor and the switchboard Among the dimensions variability are Implementation Some systems are implemented central server Others are fully distributed using broadcasts messages and requests Other possibilities include establishment explicit routing trees using central server only introduce processes one another and allowing them engage bilateral multilateral communication thereafter Reliability and Security Some systems great lengths cope with process and network failures authentication and security out order delivery while others largely ignore these problems Matching and Synchronization Systems differ criteria for matching messages with requests The simplest approach require exact match Each message has message type and each request specifies interest all messages that type Other schemes involve regular expression string matching general Boolean expressions Prolog like unification related issue whether message delivered single process perhaps with some priority ordering multicast all who are interested saved for those who may request the future Requests can blocking non blocking Data Types Messages may simple untyped byte strings they may typed structures The system may provide type checking facilities make sure the receiver interprets the data the sender intended and may even provide automatic data conversion among integer floating point representations character sets etc concrete example Linda which maintains single conceptually global tuple space Linda provides the primitives put which adds tuple tuple space get which waits for tuple with give first component appear and then removes from the space and read which waits for matching tuple but does not remove from the space Security Audit properly managed computer system should secure from illegal entry Normal users should not able obtain privileges beyond what they are given Most systems everyday have security holes Normally considered violation standards ethical behavior take advantage such holes However tiger team team specifically authorized find many security holes possible and report them responsible management Select facility the Computer Sciences Department elsewhere and find demonstrate and document many security problems possible You may attack the system either from the position ordinary user with account but special privileges from the point view outsider someone who not supposed able access the facility all You should find many security problems possible These problems include system flaws improper management and careless users The results this study should report the problems with suggestions for fixes the system system design and changes management procedures You should not explore denial service attacks such jamming networks crashing systems Warning project this kind must approved advance the person responsible for the facility you are proposing attack File Servers for Workstations Workstations are available with and without local disks Bulk storage provided combination remote file servers local disk and local RAM memory Servers provide remote devices remote files other abstractions variety schemes for providing seamless global file service have been suggested including remote disk simulation remote file access NFS from Sun Microsystems whole file caching local disk the Carnegie Mellon ITC system Andrew file system and use large local RAM for file caching the Sprite system from Berkeley The Locus system should also studied for ideas about transparent global file naming Design scheme for file access for network workstations You should specify the functionality that provided the server and the responsibility the client workstation You will want discuss reliability fault tolerance protection and performance Compare your design the designs published the literature Evaluate the design performing simulation See the Spritely NFS paper Srinivasan and Mogul and the award winning paper Shirriff and Ousterhout from the Winter USENIX see for copy for examples similar studies See also related papers SOSP proceedings over the last several years Load Balancing Many systems such LOCUS Sprite Condor allows you start processes any machine move processes during execution and access files transparently across machine boundaries Automatic placement processes and other system resources could substantially improve overall system performance There are several interesting issues load balancing including Collection Data for Load Balancing make load balancing decision you might need data from each machine the network There are many forms that this data can take and many designs for communicating this among machines You must decide what data needed from where the data must come and how must communicated This problem becomes interesting the scope very large network computers machines You not want consume huge amounts system resources making these decisions and you not want make decisions based extremely old data Policies for Load Balancing Decisions How you decided when move process what you base your decision How frequently can move processes what thrashing like this environment What about groups processes that are cooperating Metrics for Load Evaluation What load metrics you use evaluating individual machine capacity Are these related processing storage communication How can measure these Are they accurate reflections machine performance How can you demonstrate this File migration can move files well processes When you move files processes only one needed Which better How can you tell You are warned that quite easy suggest many plausible schemes for load balancing but not easy evaluate them Therefore major component any project this area will evaluation through simulation Security and Authentication The Popek and Kline paper the reading list discusses use encryption for authentication distributed systems considers both conventional and public key schemes One popular implementation based these ideas the Kerberos system from MIT Kerberos has been used provide secure remote login file transfer and remote file access Use Kerberos hoc package enhance the security some existing system Random Software testing This suggestion from Prof Bart Miller This past Fall had some students work more that random software testing The result pretty nice paper that just submitted CACM One interesting result was that the utilities from GNU and Linux were substantially more crash resistant than ones from the seven commercial systems that tested SunOS Solaris AIX Ultrix Irix NEXTSTEP There are bunch more things that can done this work test more the new BSD UNIX systems such netBSD freeBSD BSDi test applications Windows and Macs test more the system library interfaces happy help supervise any projects this area Navigating the World Wide Web The World Wide Web growing unbelievable pace There tremendous amount information available but finding what you want can next impossible Quite few line search engines have been created aid resource location the web Check the Directory pull down menu NetScape for some examples particular note WebCrawler written Wisconsin alumnus Brian Pinkerton who recently sold America Online reputedly for over million There are lots ways tackling this problem but none discovered thus far entirely satisfactory Among the variables design space are Server Support Does the provider information cooperate advertising the search entirely client driven Caching Does each search start from scratch some sort database used guide the search the latter case where the database kept the client the server somewhere between How created How stale information detected and updated How the cache purged valid but seldom referenced information Search Strategy How does the search determine which information will interest the user How does determine which links traverse and what order When does know when has gone far enough Topology the Web project closely related the previous suggestion collect and analyze information about the current structure the web The web can viewed vast directed graph Gather much information you can about this graph analyze What the average number links out page What the average size page What the average distance between the pages the two ends link where distance the number links along shortest path More generally what are the distributions these statistics How these things vary over time Information from this project would great interest people proposing algorithms for traversing the web This project has two distinct parts both potentially quite challenging gathering the data and analyzing Self perpetuating programs The Worm program propagated itself across many machines automatically repairing parts that were damaged destroyed worm extremely difficult kill You should design strategy building worms one our systems You will also need determine how you might constructively use worm program what applications are there for this type program This project could involve design test implementation and study and evaluation the implementation there generic structure such that you can take large class algorithms and automatically make them into worm type programs General Purpose Transaction Package The concept transaction sequence actions that are executed atomicly and either commit are reliably preserved forever abort are completely undone was developed the context database systems but transactions are useful many areas outside traditional database applications Design and implement portable transaction package Look Camelot developed the context Mach and libtb built Margo Seltzer and described recent Usenix proceedings Distributed Shared Memory There been great deal interest recently architecture called distributed shared memory The basic idea simulate shared memory multiprocessor programming model top distributed system local area network altering the page fault handler traditional operating system fetch pages over the network rather than the local disk The SOSP contains paper operating system called Munin which explores some the tradeoffs page placement and replacement policies support variety applications efficiently Explore these issues constructing simulation See also the Wisconsin Wind Tunnel WWT project for related research Performance Study Monitor one more the Computer Science Department machines networks determine its characteristics Where are the bottlenecks What sorts programs are producing most the load What causes spikes usage and corresponding drops response For example recent USENIX conference Matt Blaze describes publicly available program for eavesdropping NFS traffic local area Ethernet and gathering statistics Install this program use gather some statistics and compare them with similar data from the literature See also the suggestions regarding distributed file systems above Distributed Persistent Garbage The problem garbage collection finding and reclaiming space allocated inaccessible objects has been well studied for almost years Algorithms can roughly classified explicit deletion data and throw away when want reference counting Will the last one out please turn off the lights mark and sweep Unclaimed goods will recycled and generational When the ashtray full time buy new car Recently there been resurgence research garbage collection spurred two developments distributed systems can throw this away because somebody France may still want and persistent programming languages the Pampers problem The only thing worse than garbage persistent garbage Well known garbage collection algorithms that work fine for physical virtual memory are terrible when pointers can cross continents disk cylinders Interesting algorithms for disk based distributed environment have been proposed see for references Study some these algorithms and either suggest improvements implement them and study their performance Consumer Reports Many people are generating software and making freely available the network for anonymous ftp Often there are several packages available for the same similar purposes Much this software worth exactly what costs but some good not better than expensive commercial products Select two more related programs and careful comparative critical review Depending the nature programs the review might benchmarking study relative performance analysis functionality ease use some combination these factors One area particular interest file accessing and indexing packages this were would call them low level database facilities Examples are the WISS and Exodus storage managers both written here and the dbm and libdb packages from Berkeley the latter the yet released BSD version Unix but have early version this code related suggestion compare implementations Unix and alternative ways achieving the same function different ways For example consider the question What the best way get data from one process another Under various flavors Unix you can use TCP UDP Unix domain sockets pipes fifo shared memory files least three different flavors remote procedure call The answer depends the versions Unix involved and various characteristics the communication desired such the amount data transferred the sizes messages whether replies are required the degree reliability needed etc written rough program that tests many these techniques would like someone polish the program bit and use evaluation many the IPC mechanisms available Condor Condor locally written utility that makes unused cpu power idle workstations available for productive use daemon process each workstation monitors activity and reports central resource manager client who wishes run long cpu bound program contacts the resource manager obtain the name idle workstation then contacts the selected server workstation and sends the job executed Jobs run under Condor are linked with version the library that handles system calls specially File calls are turned into requests sent back shadow process running the submitting host the server workstation should become non idle before the job finishes the job checkpointed and restarted another workstation the pool One user Condor had program successfully complete after consuming over cpu days during period that spanned the department move new building Several enhancements Condor have been considered Security Server security seems adequate Application processes runs with non privileged guest user under control trusted starter that can kill them any time Providing security for condor users seems much more tricky Here the problem that the shadow which design runs under the UID the job owner and has all that person privileges vulnerable spoofing software the server machine assume that the server workstation owned hostile user who has super user capabilities the problem becomes quite difficult Design and implement mutual authentication protocol perhaps using the Kerberos package Multiprocess Jobs Currently Condor only supports jobs consisting single UNIX process Condor does not support the UNIX fork call Design extensions Condor that support collection processes connected pipes Your design must deal with problems such scheduling making sure all processes are running the same time and maintaining connections processes are checkpointed and moved Condor Lite Condor designed for single processes that consume many hours cpu time Fixed overhead makes Condor impractical for short jobs such compilation Consider how use some the Condor machinery produce network make facility Other enhancements suggested Mike Litzkow principal implementor and maintainer Condor include Execution condor jobs across wide area networks Support for parallel programming model other than pipe fork exec Linda More sophisticated matching jobs available resources Checkpointing mechanisms which require less data movement Implementation applications which are well suited Condor capabilities and can really show off its power Applications such trendy areas code decryption genetic engineering are obvious choices The current implementation Condor available anonymous ftp Specialized NFS Servers The Unix File System interface provides convenient abstraction for variety data beyond ordinary files For example classic Unix makes devices and communication channels pipes look like files Some flavors Unix support other kinds objects that look like files including network connections named pipes and shared memory regions The Network File System NFS provides convenient path for adding new kinds file like objects without modifying the operating system kernel NFS server running user level process can mounted the Unix name space Any requests open read write files this space are forwarded the server This trick used the CAPITL program development environment and the SHORE object oriented database system allow access database objects from legacy applications such compilers editors grep etc without the need modify even link them have written package classes that encapsulate all the messy details the NFS protocol create yourself NFS server kit All you have implement the necessary data structures simulate Unix file behavior Use this kit provide Unix compatible veneer over some other service representative example FTP Write server that allows you navigate the space files accessible via anonymous FTP they were part the local file system Shore Shore experimental object oriented database being developed our department combines many the features traditional databases concurrency control and recovery and high speed bulk operations object oriented databases fine grained strongly typed objects with identity and file systems hierarchical name space with secure protection objects and Unix compatibility Write persistent application using the facilities Shore and critically evaluate how well served your needs work extend improve Shore some way see for ideas Madison Research Projects Detailed descriptions several the research projects mentioned above and more are available via the Department Home Page Most the projects listed there would welcome participation interested students Tempest From markhill reggiano wisc edu Mark Hill Date Mon Feb CST Here project that think would interesting Background Future parallel computers must execute efficiently both hand coded applications and also programs written high level programming languages Today machines limit programs single communication paradigm message passing shared memory which results uneven performance address this problem have developed the Tempest interface which supports shared memory message passing and hybrid applications Tempest enhances portability parallel programs allowing low cost networks workstations provide the same abstractions shared memory high performance parallel machines The Tempest interface consists low level communication and memory system mechanisms Policies such shared memory are implemented user level software which allows programmers and compilers customize policies application semantics and sharing patterns Experiments show that custom cache coherency policies can produce upto order magnitude performance improvement The Wisconsin Wind Tunnel Project has developed implementations Tempest for the and cluster workstations COW Sun running Solaris complete our portability story and facilitate program development would like see Tempest run single workstation either uniprocessor multiprocessor The project Implement Tempest that all processes run single two processor node COW The key challenge implementing the messaging that functionally looks exactly the same the version that sends messages between nodes Interested groups should read the paper before talking with him further solomon wisc edu Fri Sep CDT 