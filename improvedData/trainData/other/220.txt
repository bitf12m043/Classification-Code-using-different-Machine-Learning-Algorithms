MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Saturday May GMT Improved Version Parallel Object Tracker RivLAn Improved Version Parallel Object Tracker RivL http www cornell edu Info People barber potrivl potrivl htmlSicco Tans stans cornell eduJonathan Barber barber cornell edu Final ProjectProfessor Ramin ZabihDepartment Computer ScienceCornell University Table Contents Abstract Introduction RivL and the Generic Parallel Paradigm The RivL Graph Generic Parallel RivL RivL Object Tracker The Object Tracker Script The Algorithm behind search Parallelizing search Problems with search and Generic Parallel RivL Parallelizing search RivL Course Grain Parallelization Scheme Implementation Inefficient Parallel search Implementation Persisent Parallel Object Tracker Passing Sequence Information The Contents Shared Memory Setting Shared Memory Updating Shared Memory New Semaphore Implementation Issues Performance Results Extensions Improvements Conclusions ReferencesGo Back Abstract The fields multimedia image processing and Computer Vision are converging the same time lot work being spent making image vision processing algorithms more efficient accessible and usable programmers strong example this merging technologies exists RivL Object Tracker which has been the focus our work this paper detail the inception and development efficient parallel Object Tracker that available with RivL Back Introduction There are many similarities between the fields multimedia image processing and Computer Vision many instances hard distinguish one from the other Both fields involve operating single continuous stream images These operations typically incur very large computational expense Object Tracking example such multimedia vision application recent years lot effort has been spent attempting make image processing and vision related algorithms easier program adding many layers abstraction between the image data the image operations themselves and the interface the programmer user the same time these higher levels abstraction should not add the computational complexity the operation This left researchers and developers with the extraordinarily difficult problem making multimedia vision operations fast efficient and easy use The effort manifested itself with the construction RivL Resolution Independent Video Language RivL multimedia software processing package that given set images set sequence images can efficiently process these multimedia streams and generate outgoing image sequence images RivL implemented tcl extension that capable performing common image operations such overlay smoothing clipping cropping etc also includes more complex vision related image processing operations such object tracking which has been the focus our work The tcl interface simplifies the process coding image vision processing script recent months several developers have improved RivL performance measures via fine grained parallelization scheme using shared memory machine and distributed computing environment The parallelization independent most the image operations resident the RivL library clip smooth canny Unfortunately this scheme does not lend itself more complicated computer vision applications particular the scheme does not work for Object Tracking Bearing this mind established the project goal develop backwards compatible parallel implementation Object Tracking tailored for RivL Section introduce RivL and describe the generic parallelization scheme Section describe the Hausdorff based Object Tracking algorithm implemented RivL Section introduce the scheme for parallelizing RivL Object Tracking operation Section describe our implementation parallel Object Tracking RivL operation Section present our performance results Section present some extensions for future work and improvements the current implementation Section draw some conclusions Back RivL and the Generic Parallel ParadigmGo Back The RivL Graph begin our discussion RivL introducing the RivL Evaluation Graph order for RivL execute requires set multimedia input data and control RivL script The RivL script sequence tcl RivL commands that specify what image processing operations should occur the input data Once RivL invoked the RivL script translated into the RivL graph pictured above Each node corresponds some image operator smooth canny etc and each edge signal corresponds the actual image data Those nodes lying inside the illustrated rectangle above correspond true image operators Those nodes lying outside the rectangle are the RivL nodes The nodes outside and the left the rectangle correspond read nodes one read node per image stream and the node right the rectangle corresponds the write node want emphasize that construction the RivL graph does not compute any multimedia data The RivL graph merely the control flow structure through which each inputted sequence data must propagate generate the outputted processed image There are two phases processing data using the RivL graph once has been constructed The first phase manifests itself graph traversal from right left This what makes RivL efficient image processing mechanism The first node that evaluated the Write node the right most node traversing the graph reverse order RivL decides each node exactly how much data the output signal requires from the input signal The evaluation reverse propagated from the write node through the graph and back every read node Once the reverse propagation completes every node the graph knows exactly how much data from each input signal required compute the node corresponding output signal The multimedia data then processed the second traversal which conforms left right traversal the RivL graph propagating the input data forwards through the graph only operating data that relevant the final output image Back Generic Parallel RivL can summarize the preceding section into the statement that the amount data that fetched from each Read node exactly function the output the Write node Combining this notion with the fact that most the image processing operations RivL not create dependencies from one pixel another given input image can derive simple for mechanism for dividing the work and parallelizing RivL Instead running RivL single processor RivL spawns multiple processes different processors and has each process work towards computing different segment the output data define the notion single master RivL process and multiple slave RivL processes Each slave process should run different processor Once started the slave process sits idle listening for instructions from the master During the initial setup period the master sends each slave process logical addition each slave aware the total number processes available for work Following the control setup period the master sends each slave copy the RivL script Once each slave and the master receives the RivL script they each generate copy the RivL graph and perform the right left traversal independently The difference between the right left traversal now that the logical for the current processor and the total number processes becomes factor determining how much computation gets done for each process According the figure above the amount data fetched from each read node longer function the output the write node but now function the process Logical the total number processes and function the write node output That each RivL process responsible for computing different independent portion the final output data which based the above parameters The approach fine grained that each RivL process performs the same set computations different data Actual data computation the left right graph traversal occurs when the master says Each slave and the master process computes their appropriated portion the output image Back RivL Object TrackerGo Back The Object Tracker Script The RivL Object Tracker implemented tcl script which executes set RivL image operations Given image sequence and model look for the job the RivL Object Tracker determine where object model resides given image for each frame sequence images The image sequence can represented any RivL datatype MPEG continuous JPEG The model string points which bounding box specifying the location the object given image The Tracker operates follows looks adjacent images sequence which will define here Prev for previous and Next want determine where the object model went from Prev Next For every adjacent set images the Tracker performs the following sequence operations first smooths using the RivL smooth operation and then edge detects using the canny operator which Canny Edge Detector Next Prev was smoothed and edge detected the previous iteration The search command then invoked which actually performs the object tracking The search command extracts the actual object tracked from Prev specified model search then searches for instance the object Next When search completes returns new bounding box model which corresponds the location the tracked object Next modifying the RivL script can generate output sequence images that illustrates the object being tracked The sequence images above illustrates the output RivL Object Tracker The tracked object appears highlighted while rest the image dimmed Back The Algorithm behind search The search itself based the Hausdorff distance which measure the similarity between two different sets points The search command compares the object with different locations inside Next find Hausdorff distance and within some threshold value then match found more than one found within then pick the match with the smallest corresponding the best possible match The search utilizes multi resolution approach The image Next evenly divided into separate regions Each region then pre searched determine there anything interesting that region interesting mean that there substantial clustering edges again within some other threshold For each region that was determined interesting then recursively sub divided and pre searched recursively dividing the image and locating only interesting regions the overall search space decreased The Hausdorff distance comparisons between the model and the region interests can then proceed only the reduced search space Back Parallelizing search The multi resolution approach lends itself parallelization each level the resolution separate independent regions must pre searched These pre searches can processed parallel hungry puppy fashion When the pre search recursively moves down lower level each region again sub divided and pre searched These searches can also done parallel And forth Back Problems with search and Generic Parallel RivL mentioned the introduction the generic parallel scheme described earlier works for the majority the image operations RivL Unfortunately this not the case for search generic parallel RivL the output write region sub divided based the process logical and the total number processes willing work this paradigm each process responsible for its own portion the output region Computation each output region does not rely upon the output any other regions generic RivL there communication between different processes for given traversal the RivL graph Each process independent one another Unlike the more general operations the output region search cannot simply sub divided into different regions and computed independently one another This true for the reason that object being tracked may overlap several write regions Since there communication between processes for given traversal the RivL graph search will not work using Generic RivL Back Parallelizing search RivLGo Back Course Grain Parallelization Scheme Section introduced method for parallelizing search based the multi resolution approach for object tracking This exactly the scheme that has been implemented RivL Unfortunately this scheme currently incompatible with fine grain generic parallel RivL for the reasons described above Rather parallel search was implemented over the original sequential version RivL The alternative parallelization scheme works follows RivL initially invoked only one process the master Process The master constructs the RivL graph and performs the right left traversal all itself search like any other image operation constructed RivL node When the image sequence tracked loaded and ready each image makes its left right traversal through the RivL graph When the data encounters the search node the following sequence events happens RivL spawns slave processes extension searchThe master process organizes the multi resolution pre searches maintains high priority queue and low priority queue The high priority queue contains list pre searches the sub divided image Each slave process pulls these jobs from the queue and performs the pre search each job interesting region found the Slave process will further sub divide that region into smaller regions and place each sub divided region job onto the low priority queue The master can only write the high priority queue and read from the low priority queue The slave can only read from the high priority queue and write the low priority queue Essentially each slave process performs the pre searches hungry puppy fashion narrow down the scope the overall search region The master process responsible for maintaining the queues initially places work onto the high priority queue for the slaves fetch then clears new pre search jobs specified each slave process from the low priority queue and places them back onto the high priority queue for the next level recursion Once the pre searches have concluded the slaves have fulfilled their tasks for the current iteration The master then computes the Hausdorff distances between the object and the interesting regions and looks for the best possible match any one found outputs the new bounding box the object based the current image Next Back Implementation Inefficient Parallel search discovered implementation the parallelized search RivL node Unfortunately are unable give credit the developer the implementation because completely documented The implementation utilizes the parallelization scheme described the previous section The design meant run over shared memory machine When the left right traversal the RivL graph hits the search node RivL attaches the high and low priority job queue data structure shared memory and generates UNIX IPC semaphores govern access this shared object prevent race conditions and synchronize the parallelization Once the shared memory and semaphores are set RivL then forks slave processes want emphasize that this implementation SPMD The only shared data the job queue which simply data structure that contains pointers different portions Next The object model and image data are completely replicated each RivL process and reside exactly the same address each process address space The parallel computation proceeds described above When the slave processes are done all interesting regions have been found the master kills each slave and allocates the shared memory segment The master then proceeds finish the object tracking computation the next traversal the RivL graph the above sequence events are repeated The master again sets shared memory and the semaphores forks and then kills the slaves believe that this very wasteful implementation search every iteration expensive UNIX kernel system calls are generated setup shared memory and the semaphores doing expensive resources are wasted allocating the same memory segment fork slave processes This involves replicating not only the search node but the entire RivL address space This includes replicating the RivL graph and all RivL data including the model and image data believe that the developers this implementation forked new slaves every iteration eliminate lot work and complications involved establishing efficient means communication between the processes This wastefulness led develop smarter implementation search that uses resources and improves performance the object tracker Back Implementation Persistent Parallel search improved way implementing the object tracking algorithm seeks reduce the overhead creating shared memory segment and forking off series child processes for each frame object tracking sequence With little information about the position the current frame larger tracking problem the object tracker can keep the shared memory and the child processes alive while the same sequence images continue tracked This way the master process can simply put the new image and model into shared memory and wake the children start work the current tracking sub problem Only when sequence has been completely tracked will the shared memory cleaned and the children killed anticipation new sequence tracked Back Passing Sequence Information The first issue dealt with was the passing sequence information into the object tracker This required information from RivL tcl interface into the procedures The basic idea was figure out how many images were the sequence being tracked and the index the current frame being processed the frame was the first frame its sequence the object tracker ran the startup procedure set shared memory segment large enough for the current image sequence and forked off the child processes the current frame was the last frame sequence the object tracker would run shutdown and remove the shared memory segment and clean the child processes after completing the tracking algorithm Any other frame position meant that the frame was somewhere the middle the sequence and required special action Back The Contents Shared Memory The master process responsible for keeping the shared memory segment date with the current tracking task Because the child processes longer contain the most recent image and model information these structures have explicitly maintained shared memory Basically shared memory extended from the rudimentary object tracker contain large body additional data addition the basic jobs structure outlined above the points the current model the points the current image some distance transforms the current image various levels scaling and their associated image structures Back Setting Shared Memory Shared memory basically set contain these various data structures one big contiguous block Certain parts the data not have constant length throughout image sequences The points the model and the image particular have varied length requiring some assumptions about the maximum number points that might expected present The remaining structures particular the image distance transforms have consistent size that dependent the size the images the sequence other words knowing the size the first image sequence enables single allocation that will sufficient for the entire sequence course the dependence the size the images the sequence the reason that particular shared memory segment can only kept around for one sequence images Making assumptions about the maximum size sequence would enable shared memory segments and child processes stay around for multiple sequences tracked but did not make this extension The diagram above illustratest the contents the shared memory segment The segment contains the main job queue data structure the high and low priority queues also contains vital model and image data along with their corresponding distance transforms Back Updating Shared Memory convenient side effect the constant size the image distance transforms the fact that only the data portion these structures have changed this way updating the data these structures shared memory was simple call memset with the properly aligned position the source and destination pointers Back New Semaphore The rudimentary parallel implementation had series semaphores synchronize the access the children and the master process the shared memory segment new semaphore was required however synchronize the reentry the children into their main work procedure with each new tracking task Back Implementation Issues The first concern developing this implementation was climbing series learning curves These included familiarization with RivL shared memory and UNIX semaphores The biggest learning curve however was understanding the existing code for search and determining the changes that would required change the parallelization paradigm while using much the existing code possible Shared memory added some significant hurdles due the difficulty tracing pointers into and out Some data structures remained unchanged from initialization the child processes and were explicitly left out shared memory for that reason Some these structures however were pointed some structures shared memory The invariant that had maintained was that the pointers shared memory the constant structures could not changed The easiest way keep track the structures shared memory turned out putting them the same order every time and maintaining some global information the location the structures shared memory relative the start the shared memory segment Back Performance Results tested our implementation the parallel RivL object tracker frame MPEG sequence the sequence track motorcycle hurtles through the air courtesy Terminator Judgment Day illustration the sequence appears earlier this paper tested our implementation MHZ processor Sparc station running Solaris version tested the performance our implementation using master process and slave processes For comparison also tested the first implementation the RivL parallel object tracker the same sequence from processors control also tested the sequential RivL object tracker the same sequence the same machine graph our results appears the following diagram Unfortunately our current performance results indicates not only that our implementation slower than the first implementation but that also slower than the sequential version However believe that these results are not truly indicative the advantage our implementation over the older one Due the fact that ran out time were unable fully iron out the bugs and inefficiencies our implementation and fine tune that would reach its full potential believe that this not reflective the soundness our ideas However notable that our implementation scales better from processors than the previous implementation This implies that our implementation the parallel object tracker does significantly improve overall performance increase the number slave processes Back Extensions Improvements There are number extensions and improvements that can made improve the overall performance and extensibility tracking objects parallel RivL Fine tune our current implementation this improvement goes without saying Due the time constraints this project were unable get the kind overall performance results would have liked need determine the bottleneck that are killing performance Once this done would expect see performance results greater than the original parallel object tracking implementation Integrate our Parallel search with Generic Parallel RivL RivL was developed with goals make multimedia data processing easy program and efficiently process multimedia data Bearing these goals mind the parallelization RivL should remain transparent the tcl programmer this sense the programmer should not restricted generic set image operations excluding search but should able use every RivL operator and the processing every node should proceed parallel This work involves designing Special Operator Detector The generic RivL operators are run parallel using the fine grained generic parallel approach while complex operators such search run parallel using our scheme The Detector would find all such special nodes the RivL graph and handle them accordingly Port our Parallel search over ATM and Fast Ethernet using Distributed Shared Memory Extension Our current parallel implementation restricted shared memory machine However there are Distributed Shared Memory software extension that generates shared memory paradigm over distributed architecture should not difficult port our current implementation over distributed environment using the DSM software extension Incorporate our Parallel search RivL RivL version RivL that was developed Cornell University which allows RivL process sequences images feeding from real time continuous media stream object tracking can very useful real time application this makes for interesting extension Back Conclusions were looking for significant speedup the new implementation RivL parallel object tracker moved from processors While the performance scaling from processors encouraging are disappointed thus far with our overall performance results were hoping that this time would have fine tuned parallel RivL object tracker that was faster than the first attempt are confident that little more work will yield the results are looking for Intuitively makes sense that our implementation should run faster than the previous implementation for the simple reason that have significantly reduced the overhead involved setting and running RivL multi processor environment Back References Jonathan Swartz Brian Smith Resolution Independent Video Language Proc the Third ACM International Conference Multimedia San Francisco November Jonathan Barber Sugata Mukhopadhyay Fine Grain Parallel RivL Step Towards Real Time Multimedia Processing Cornell University May Canny Computational Approach Edge Detection IEEE Trans Pattern Analysis and Machine Intelligence November Dan Huttenlocher Klanderman Rucklidge Comparing Images Using the Hausdorff Distance IEEE Trans Pattern Analysis and Machine Intelligence Dan Huttenlocher Rucklidge Multi Resolution Technique for Comparing Images Using the Hausdorff Distance Proceedings the IEEE Computer Vision and Pattern Recognition Conference with Rucklidge Eugene Ortenberg Vijay Menon Distributed Shared Memory Over ATM Cornell University May Sugata Mukhopadhyay Arun Verma CMRivL Programmable Video Gateway Cornell University December MIME Version Server CERN Date Tuesday Jan GMT Content Type text html Content Length Last Modified Sunday Aug GMT UTCS Neural Nets Alumni and Visitors Alumni and Recent Visitors Justine Blackmore justine arlut utexas edu Andrea Haessly andrea cnd com Daniel James djames bnr Wee Kheng Leow leowwk iscs nus Mark Moll moll cmu edu Joseph Sirosh sirosh utexas edu Ren eacute Steetskamp steets utwente Gert Westermann gert cogsci Back UTCS Neural Networks home page martym utexas edu Date Tue Jan GMT Server NCSA Last modified Fri Jan GMT Content type text html Content length NYU Center for Advanced TechnologyKen Perlin won Academy Award The Academy Motion Picture Arts Sciences Board Governors has voted present Ken Perlin our wonderful director Technical Achievement Award Academy Certificate for the development Turbulence Perlin Noise technique used produce natural appearing textures computer generated surfaces for motion picture visual effects New released Baltimore college singing group Shades has just released new album called Sisters and Brothers Techno Seduction Collected Visions included the exhibition Techno Seduction The Cooper Union School Art Street Avenue NYC The opening reception Thursday January from and the exhibit runs from January February What was new the CATEducation Resourceslast updated Thur Jan EDT Date Mon Nov GMT Server NCSA Content type text html Last modified Wed Feb GMT Content length Quiz Reviews for Quiz Reviews for Quiz Review Windows Email Quiz Review Word Quiz Review Excel Quiz Review Paradox Vocabulary Words You might want know these for exams Return the Home Page 