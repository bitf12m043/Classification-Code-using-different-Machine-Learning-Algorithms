Some Papers With Geometric FlavorSome Papers With Geometric Flavor publisher CORNELLCS series any number any author Donald title any abstract any CORNELLCS Simplified Voronoi Diagrams John Canny and Bruce Donald CORNELLCS The Complexity Planar Compliant Motion Planning Under Uncertainty Bruce Donald CORNELLCS Planning Multi Step Error Detection and Recovery Strategies Bruce Donald CORNELLCS Geometric Approach Error Detection and Recovery for Robot Motion Planning With Uncertainty Bruce Donald CORNELLCS the Complexity Kinodynamic Planning John Canny Bruce Donald John Reif and Patrick Xavier CORNELLCS Provably Good Approximation Algorithm for Optimal Time Trajectory Planning Bruce Donald and Patrick Xavier CORNELLCS Planning and Executing Robot Assembly Strategies the Presence Uncertainty Bruce Donald CORNELLCS Computing the Homology Type Triangulation Bruce Randall Donald and David Renpang Chang CORNELLCS Provably Good Approximation Algorithms for Optimal Kinodynamic Planning for Cartesian Robots and Open Chain Manipulators Bruce Donald and Pat Xavier CORNELLCS Real Time Robot Motion Planning Using Rasterizing Computer Graphics Hardware Jed Lengyel Mark Reichert Bruce Donald and Donald Greenberg CORNELLCS Mathematical Questions Robotics Roger Brockett John Ballieul Bruce Donald Richard Murray Madhusudan Raghavan and Shankar Sastry CORNELLCS Sensor Interpretation and Task Directed Planning Using Perceptual Equivalence Classes Bruce Donald and Jim Jennings CORNELLCS Rational Rotation Method for Robust Geometric Algorithms Extended Abstract John Canny Bruce Donald and Gene Ressler CORNELLCS The EIGHT Manual System for Geometric Modelling and Three Dimensional Graphics the Lisp Machine Bruce Donald CORNELLCS The Motion Planar Compliantly Connected Rigid Bodies Contact With Applications Automatic Fastening Bruce Donald and Dinesh Pai CORNELLCS Information Invariants Robotics Bruce Randall Donald Some other papers are listed here More papers are avalable through the Cornell server tkbook directory tkbook fussell app defaults app defaults color arc tcl ash bind tcl bind tcl bindall tcl bindHier tcl bindprint tcl bitmaps tcl borders tcl borders tcl browse tcl browse tcl orig browse tcl browse tcl orig button resources button tcl button tcl button tcl buttonResource tcl buttonSize tcl canBitmap tcl canImage tcl canOval tcl canPoly tcl canRect tcl canvasEdit tcl canvasHello tcl canvasScroll tcl canvasSelect tcl canvasWidget tcl clock tcl color tcl commandEntry tcl COPYRIGHT cprog crossref tcl crossref tcl cursor tcl cursor tcl orig cursor tcl cursor tcl orig cursor tcl cursor tcl orig cursorfont debug tcl dialog tcl entryWide tcl eval tcl eval tcl orig evalServe tcl evalServe tcl orig execlog tcl execlog tcl orig feedback tcl filecomplete tcl fileeq tcl findfile tcl fixfont tcl focusHybrid tcl focusMouse tcl font tcl fontsel orig tcl fontsel tcl fontsel tcl orig grouping tcl hello tcl hourglass bitmap hourglass mask hourglass bitmap incr tcl label tcl ldelete tcl library tcl listbox tcl listbox tcl listbox tcl makedir tcl Makefile menu resources menu tcl menuPackage tcl message tcl message tcl mytkapp tcl newer tcl optionColor tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl pack tcl packedButton tcl parcftp expect pingtool tcl pingtool tcl orig place tcl postscript tcl pref exmh tcl pref tcl prefTest tcl printbyname tcl printenv tcl prog prompt tcl protoapp tcl protoapp tcl orig random random random tcl read tcl read tcl orig README regexp tcl relief tcl rvideo tcl scale tcl send tcl send tcl orig sendSetup tcl sendSetup tcl orig Setup tcl showproc tcl spacing tcl stack tcl stroke tcl supertcl tclInvoke tclInvoke tclMain tclMain tclMain orig testfile textbutton tcl textScroll tcl textStyles tcl tkclock tkCustomMain tkerror tcl tkImgPixmap tkMain tkMain tkWidget tkWidget trace tcl trace tcl xload tcl xload tcl orig multical directory multical multical tar README SQL Date Tue Nov GMT Server NCSA Content type text html Last modified Thu Oct GMT Content length Processes Lecture NotesProcesses and Synchronization Contents Using Processes What Process Why Use Processes Creating Processes Process States Synchronization Race Conditions Semaphores The Bounded Buffer Problem The Dining Philosophers Monitors Messages Tanenbaum mixes presentation the features processes interest programmers creating concurrent programs with discussion techniques for implementing them The result least confusing will attempt first present processes and associated features from the user point view with little concern possible for questions about how they are implemented and then turn the question implementing processes Using Processes What Process process little bug that crawls around the program executing the instructions sees there Normally called sequential programs there exactly one process per program but concurrent programs there may several processes executing the same program The details what constitutes process differ from system system The main difference the amount private state associated with each process Each process has its own program counter the register that tells where the program also needs place store the return address when calls subroutine that two processes executing the same subroutine called from different places can return the correct calling points Since subroutines can call other subroutines each process needs its own stack return addresses Processes with very little private memory are called threads light weight processes minimum each thread needs program counter and place store stack return addreses all other values could stored memory shared all threads the other extreme each process could have its own private memory space sharing only the read only program text with other processes This essentially the way Unix process works Other points along the spectrum are possible One common approach put the local variables procedures the same private stack the return addresses but let all global variables shared between processes stack frame holds all the local variables procedure together with indication where return when the procedure returns and indication where the calling procedure stack frame stored Java follows this approach has global variables but threads all share the same heap The heap the region memory used allocate objects response new short variables declared procedures are local threads but objects are all shared course thread can only see object can reach that object from its base object the one containing its run method from one its local variables class Foo implements Runnable Object obj obj Foo Object obj public void run Object obj new Object obj new Object for int something class Bar static public void main String args Object obj new Object Runnable foo new Foo obj Thread new Thread foo Runnable foo new Foo obj Thread new Thread foo start start something here There are three treads this program the main thread and two child threads created Each child thread has its own stack frame for Foo run with space for obj and Thus there are two copies the variable obj each which points different instance Object Those objects are the shared heap but since one thread has way getting the object created the other thread these objects are effectively private Similary the objects pointed obj are effectively private But both copies obj and the copy obj the main thread all point the same shared object Other names sometimes used for processes are job task possible combine threads with processes the same system For example when you run Java under Unix each Java program run separate Unix process Unix processes share very little with each other but the Java threads one Unix process share everything but their private stacks Why Use Processes Processes are basically just programming convenience but some settings they are such great convenience would nearly impossible write the program without them process allows you write single thread code get some task done without worrying about the possibilty that may have wait for something happen along the way Examples server providing services others One thread for each client timesharing system One thread for each logged user real time control computer controlling factory One thread for each device that needs monitoring Networking One thread for each connection Creating Processes When new process created needs know where start executing Java thread given object when created When started starts execution the beginning the run method that object Unix new process started with the fork command starts execution the statement immediately following the fork call After the call both the parent the process that called fork and the child are both executing the same point the program The child given its own memory space which initialized with exactly copy the memory space globals stack heap objects the parent Thus the child looks like exact clone the parent and indeed hard tell them apart The only difference that fork returns the child but non zero value the parent char str main int str the main program cout str endl void int fork str the child has value return else str the parent has value return This program starts with one process executing main This process calls and inside calls fork Two processes appear return from fork parent and child process Each has its own copy the global global variable str and its own copy the stack which contains frame for main with variable and frame for with variable After the return from fork the parent sets its copy non zero value while the child sets its copy zero Each process then assigns different string its copy the global str and returns different value which assigned the process own copy Two lines are printed the parent has value the child has value actually the lines might intermingled Process States Once process started either runnable blocked can become blocked doing something that explicitly blocks itself such wait doing something that implicitly block such read request some systems also possible for one process block anther Thread suspend Java runnable process either ready running There can only many running processes there are CPUs One the responsibilities the operating system called short term scheduling switch processes between ready and running state Synchronization Race Conditions Consider the following extremely simple procedure void deposit int amount balance amount where assume that balance shared variable two processes try call deposit concurrently something very bad can happen The single statment balance amount really implmented most computers buy sequence instructions such Load Reg balance Add Reg amount Store Reg balance Suppose process calls deposit and process calls deposit one completes before the other starts the combined effect add the balance desired However suppose the calls happen exactly the same time and the executions are interleaved Suppose the initial balance and the two processes run different CPUs One possible result loads into its register loads into its register adds its register giving adds its register giving stores balance stores balance and the net effect add only tot balance This kind bug which only occurs under certain timing conditions called race condition extremely difficult kind bug track down since may disappear when you try debug and may nearly impossible detect from testing since may occur only extremely rarely The only way deal with race conditions through very careful coding avoid these kinds problems systems that support processes always contain constructs called synchronization primatives Semaphores One the earliest and simplest synchronization primitives the semaphore will consider later how semaphores are implemented but for now can treat them like Java object that hides integer value and only allows three operations initialization specified value increment decrement class Semaphore private int value public Semaphore int value public void public void down There operation read the current value There two bits magic that make this seemingly useless class extremely useful The value never permitted negative the value zero when process calls down that process forced wait goes into blocked state until some other process calls the semaphore The and down operations are atomic correct implementation must make appear that they occur instantaneously other words two operations the same semaphore attempted the same time must not interleaved the case down operation that blocks the caller the actual decermenting that must atomic other things happen while the calling process blocked Our first example uses semaphores fix the deposit function above shared Semaphore mutex new Semaphore void deposit int amount mutex down balance amount mutex assume there one semaphore which call mutex for mutual exclusion shared all processes The keyword shared which not Java will omitted clear which variables are shared and which are private have separate copy for each process Semaphores are useless unless they are shared will omit shared before Semaphore Also will abreviate the declaration and initialization Semaphore mutex Let see how this works only one process wants make deposit does mutex down decreasing the value mutex zero adds its amount the balance and returns the value mutex one two processes try call deposit about the same time one them will get the down operation first because down atomic The other will find that mutex already zero and forced wait When the first process finishes adding the balance does mutex returning the value one and allowing the other process complete its down operation there were three processes trying the same time one them would the down first before and the other two would forced wait When the first process did one the other two would allowed complete its down operation but then mutex would zero again and the third process would continue wait The Bounded Buffer Problem Suppose there are producer and consumer processes There may many each Producers somehow produce objects which consumers then use for something There one Buffer object used pass objects from producers consumers will not show the implementation Buffer easy exercise Buffer can hold objects The problem allow concurrent access the Buffer producers and consumers while ensuring that The shared Buffer data structure not screwed race conditions accessing Consumers don try remove objects from Buffer when empty Producers don try add objects the Buffer when full When condition dropped the Buffer assumed have infinite capacity the problem called the Producer Consumer Problem but Tanenbaum calls the Bounded Buffer problem the Producer Consumer Problem Here solution shared Buffer Semaphore mutex empty full class Producer implements Runnable public void run Object item for item produce empty down mutex down enter item item mutex full class Consumer implements Runnable public void run Object item for full down mutex down item remove item mutex empty before surround operations the shared Buffer data structure with mutex down and mutex prevent interleaved changes two processes which may screw the data structure The semaphore full counts the number objectx the buffer while the semphore empty counts the number free slots The operation full down Consumer atomically waits until there something the buffer and then lays claim decrementing the semaphore Suppose was replaced while count nothing mutex down before would possible for one process see that the buffer was non empty and then have another process remove the last item before got chance grab the mutex semapore There one more fine point notice here Suppose revesed the down operations the consumer mutex down full down and consumer tries these operation when the buffer empty first grabs the mutex semaphore and then blocks the full semaphore will blocked forever because other process can grab the mutex semaphore add item the buffer and thus call full This situation called deadlock will study length later The Dining Philosophers There are five philosopher processes numbered through Between each pair philosophers fork The forks are also numbered through that fork between philosophers and all arithmetic fork numbers and philosopher numbers modulo fork between philosophers and Each philosopher alternates between thinking and eating eat needs exclusive access the forks both size him class Philosopher implements Runnable int which philosopher public void run for think take forks eat put forks first attempt solve this problem represents each fork semaphore Semaphore fork void take forks int fork down fork down void put forks int fork fork The problem with this solution that can lead deadlock Each philosopher picks his right fork before tried pick his left fork What happends the timing works out such that all the philosophers get hungry the same time and they all pick their right forks before any them gets chance try for his left fork Then each philosopher will holding fork and waiting for fork and they will all wait forever There very simple solution Instead trying for the right fork first try for the lower numbered fork first will show later that this solution cannot lead deadlock You will implementing generalization this technique project This solution while deadlock free still not good could Consider again the situation which all philosophers get hungry the same time and pick their lower numbered fork Both philosopher and philosopher try grab fork first Suppose philosopher wins Since philosopher stuck waiting for fork philosopher will able grab both forks and start eating Philosopher gets eat but philosophers and are waiting even though neither them shares fork with philosopher and hence one them could eat right away Dijkstra suggests better solution shows how derive the solution thinking about two goals any synchronization problem Safety Make sure nothing bad happens Liveness Make sure much good happens consistent with the safety criterion For each philosopher let state the state philosopher one THINKING HUNGRY EATING The safety requirement that adjacent philosophers are simultaneously eating The liveness criterion that there philosopher hungry unless one his neighbors eating hungry philosopher should start eating unless the saftey criterion prevents him More formally Safety For all state EATING state EATING Liveness For all state HUNGRY state EATING state EATING With this observation the solution almost writes itself See also Figure page Tanenbaum Semaphore mayEat Semaphore mutex int state THINKING THINKING THINKING THINKING THINKING void take forks int mutex down state HUNGRY test mutex mayEat down void put forks int mutex down state THINKING test test mutex void test state HUNGRY state EATING state EATING state EATING mayEat The method test checks for violation liveness position Such violation can only occur when philosopher gets hungry one his neighbors finishes eating Monitors Although semaphores are all you need solve lots synchronization problems they are rather low level and error prone saw before slight error placement semaphores such switching the order the two down operations the Bounded Buffer problem can lead big problems also easy forget protect shared variables such the bank balance the buffer object with mutex semaphore better higher level solution provided the monitor also invented Dijkstra you look the example uses semaphores above you see that they are used two rather different ways One simple mutual exclusion semephore always called mutex our examples associated with shared variable variables Any piece code that touches these variables preceded mutex down and followed mutex Since hard for programmer remember this but easy for compiler why not let the compiler the work monitor class BankAccount private int balance public void deposit int amount balance amount etc The keyword monitor tells the compiler add field Semaphore mutex the class add call mutex down the beginning each method and put call mutex each return point each method The other way semaphores are used block process when cannot proceed until another process does something For example consumer discovering that the buffer empty has wait for producer philosopher getting hungry may have wait for neighbor finish eating provide this facility monitors can have special kind variable called condition variable class Condition public void signal public void wait condition variable like semaphore with two differences semaphore counts the number excess operations but signal operation condition variable has effect unless some process waiting wait condition variable always blocks the calling process wait condition variable atomically does the monitor mutex and blocks the caller other words condition variable wait rather like mutex down except that both operations are done together single atomic action Here solution the Bounded Buffer problem using monitors monitor BoundedBuffer Buffer Condition nonfull nonempty public void enter item Object item isFull nonfull wait enter item item nonempty signal public Object remove item isEmpty nonempty wait item result remove item nonfull signal return result general each condition variable associated with some logical condition the state the monitor some expression that may either true false process discovers part way through method that some logical condition needs not satisfied waits the corresponding condition variable Whenever process makes one these condtions true signals the corresponding condition variable When the waiter wakes knows that the problem that caused him sleep has been fixed and may immediately proceed For this kind reasoning valid important that nobody else sneak between the time that the signaller does the signal and the waiter wakes Thus calling signal blocks the signaller yet another queue and immediately wakes the waiter there are multiple processes blocked the same condition variable the one waiting the longest wakes When process leaves the monitor returns from one its methods sleeping signaller any allowed continue Otherwise the monitor mutex released allowing new process enter the monitor summary waiters are give precedence over signallers This strategy while nice for avoiding certain kinds errors very inefficient will see when consider implemenation expensive swith processes Consider what happens when consumer blocked the nonempty condition variable and producer calls enter item The producer adds the item the buffer and calls nonempty signal The producer immediately blocked and the consumer allowed continue The consumer removes the item from the buffer and leaves the monitor The producer wakes and since the signal operation was the last statement enter item leaves the monitor There unnecessary switch from the producer the consumer and back again avoid this inefficiency all recent implementations monitors replace signal with notify The notify operation like signal that awakens process waiting the condition variable there one and otherwise does nothing But the name implies notify hint that the associated logical condition might true rather than guarantee that true The process that called notify allowed continue Only when leaves the monitor the awakened waiter allowed continue Since the logical condition might not true anymore the waiter needs recheck when wakes For example the Bounded Buffer monitor should rewritten replace isFull nonfull wait with while isFull nonfull wait Java has built into something like this but with two key differences First instead marking whole class monitor you have remember mark each method synchronized Every object potentially monitor Second there are explicit condition variables effect every monitor has exactly one anonymous condition variable Instead writing wait notify where condition variable you simply write wait notify solution the Bounded Buffer problem Java might look like this class BoundedBuffer Buffer synchronized public void enter item Object item while isFull wait enter item item notifyAll synchronized public Object remove item while isEmpty wait item result remove item notifyAll return result Instead waiting specific condition variable corresponding the condition you want buffer non empty buffer non full you simply wait and whenever you make either these conditions true you simply notifyAll The operation notifyAll similar notify but wakes all the processes that are waiting rather than just the one that has been waiting the longest general process has use notifyAll rather than notify since the process that has been waiting the longest may not necessarily waiting for the condition that the notifier just made true this particular case you can get away with notify because there cannot both producers and consumers waiting the same time Messages Since shared variables are such source errors why not get rid them altogether this section assume there shared memory between processes That raises new problem Instead worrying about how keep processes from interferring with each other have figure out how let them cooperate Systems without shared memory provide message passing facilities that look something like this send destination message receive source messsage buffer The details vary substantially from system system Naming How are destination and source specified Each process may directly name the other there may some sort mailbox message queue object used the destination send the source receive Some systems allow set destinations called multicast and meaning send copy the message each destination and set sources meaning receive message from any one the sources particularly common feature allow source any meaning that the reciever willing receive message from any other process that willing send message Synchronization Does send receive block the sender can immediately continue One common combination non blocking send together with blocking receive Another possibility rendezvous which both send and receive are blocking Whoever gets there first waits for the other one When sender and matching receiver are both waiting the message transferred and both are allowed continue Buffering Are messages copied directly from the sender memory the receiver memory are first copied into some sort system memory between Message Size there upper bound the size message Some systems have small fixed size messages send signals status information and separate facility for transferring large blocks data These design decisions are not independent For example non blocking send generally only available systems that buffer messages Blocking receive only useful there some way say receive from any receive from set sources Message based communication between processes particularly attractive distributed systems such computer networks where processes are different computers and would difficult impossible allow them share memory But also used situations where processes could share memory but the operating system designer chose not allow sharing One reason avoid the bugs that can occur with sharing Another build wall protection between processes that don trust each other Some systems even combine message passing with shared memory message may include pointer region shared memory The message used way transferring ownership the region There might convention that process that wants access some shared memory had request permission from its current owner sending message The second algorithm project has this flavor Unix message based system the user level Processes not share memory but communicate through pipes pipe looks like output stream connected input stream chunk memory used make queue bytes One process sends data the output stream the same way would write data file and another reads from the way would read from file the terms outlined above naming indirect with the pipe acting mailbox message queue send called write Unix non blocking while recieve called read blocking and there buffering the operating system first glance would appear that the message size unbounded but would actually more accurate say each message one byte The amount data sent write recieved read unbounded but the boundaries between writes are erased the pipe the sender does three writes bytes each and the receive does two reads asking for bytes will get back the first bytes the first time and the remaining bytes the second time Continued the original semaphore the and down operations were called and respectively but people had trouble remembering which was which Some books call them signal and wait but will using those names for other operations later Monitors are not available this form Java are using Java vehicle for illustrating various ideas present other languages See below for similar feature that available Java There are many versions Unix that just about any blanket statement about sure lie Some versions Unix allow memory shared between processes and some have other ways for processes communicate other than pipes solomon wisc edu Thu Oct CST Copyright Marvin Solomon All rights reserved 