MIME Version Server CERN Date Sunday Dec GMT Content Type text html Content Length Last Modified Thursday May GMT Regular Language SQL Query Translation Translation Regular Questions into SQL ConstructsCOM Final Project Report Spring Alfred Hong May Table Contents Problem Description General Approach Results and Evaluation Discussion Conclusion and Future ReferencesProblem Description Web sites today that provide query front end backend database are done mostly via keyword categorical search forms These search parameters are preselected and usually inhuman Since the query parameters are preselected the answers are fixed and static the user Replacing these fixed query forms with natural language query front end could make things more human more natural and more flexible middleware mechanism that converts natural language question into the backend database language perform the user query request might the job Since relational databases are very popular SQL will the target database language for conversion Table Contents General Approach The approach general involves Identifying target domain for testing concepts Researching possible techniques for dealing with the problem Implementation using questions the author came with Testing out implementations and Refinement and retesting Identifying Target Domain Natural language processing difficult subject tackle the focus this project specific domain chosen for ideas and code testing The domain querying for flight schedules thus chosen Using sample schedule information from USAir flight schedule database the following relational database table definition and record shows the type information that dealt with FLTS toCity fromCity beginDate endDate leaveTime arriveTime flightNum frequency stops stopCities meals fare San Francisco Ithaca PHL With the domain specified certain assumptions are made simplify the task natural language question SQL construct translation Focus simple queries user usually not ask complex SQL queries that involve not exists groupings for instance Time and dates these need special treatment because the variety and complexity formats used Query against one database table only dealing with multiple tables complex task because ambiguity resolution difficulties with table joins Punctuations not dealt with One sentence questions onlyTechniques Researched Several possible concepts techniques tackle the problem were looked GAP and semantic features Bottom chart parsing with semantic features Procedural semantics and question answering conversational agents Information retrieval concepts and Template matching these techniques although some tests were initially done with using and GAP features not with flight schedules the extra and GAP features are really not necessary for the problem Simple bottom chart parsing with semantic features suffice The idea using some combination question answering conversational agents information retrieval concepts and template matching came about from the realization that the number synonyms and phrasings possible for asking for flight schedule actually quite diverse requiring rather large lexicon for small domain Table Contents Results and EvaluationBottom Chart Parsing with Semantic Features Because the nice structured format SQL queries flight schedule questions can directly mapped that parts SQL queries shown Table for San Francisco can mapped the WHERE destCity San Francisco construct and for May can mapped the WHERE departDate construct Table Translation Mapping for the Sentence What flights are available for San Francisco from Ithaca for May SentenceSQL What flights are availableSELECT flights FROM schedules for San FranciscoWHERE destCity San Francisco AND from IthacadepartCity Ithaca AND for May departDate The following the result from parsing the sentence What are the departure times for houston tomorrow SELECT TIME DEPART TOMORROW IAH PRO from Sample questions for testing were solicited from users given that they need purchase ticket San Francisco tomorrow from Ithaca The following are example questions What are the available arrival times for Miami for tomorrow What are the departure times for Houston for tomorrow How many stops are there San Francisco for flight When does flight arrive Orlando today What the cheapest flight available San Francisco tomorrow Can you book the cheapest flight can take San Francisco tomorrow need stay Saturday night get the lowest fares How many flights you have available going San Francisco tomorrow Can you check tomorrow flight schedule San Francisco for need fly San Francisco tomorrow there any flights available Question types can parsed but not the others for reasons mainly not anticipating certain words and different sentential structures For results see the results documentation and grammar lexicon code note questions and involve the realization that the cheap concept means SELECT MIN FARE operation needed Question yes type question Question involves COUNT operation and question has sentences that violates the defined assumptions Question Answering Conversational Agents Information Retrieval Template Matching The results the bottom chart parsing method could improved with further refinement non anticipated sentential constructs are discovered This not ideal however which motivates the search for other means tackling the problem Questions are often asked bits and pieces this quite true for querying flight schedules This requires the flight schedule answering system aware what has been asked session then results can further refined the user with several questions Viewed this way multiple sentences would not major problem since allowed Even though the number synonyms required are quite large lexicon need exhaustively cover all possibilities that the user may present the system For example flight flight schedule schedule reservation refer the same thing other inferences are possible through other combinations words with helper words and different word arrangements For instance miami the context flight schedules implies flying miami parse all possible combinations questions also require large number rules The sentences need fly San Francisco tomorrow there any flight available and the sentence there any flight available San Francisco tomorrow are the same queries Notice however that key phrases are the same San Francisco tomorrow and any flight The idea that these can identified then maybe sentence boundaries and syntactic structure are not important and the lexicon need concentrate only key words phrases Fig Interface Flight Schedule Query Application test the idea out Tcl application has been written Fig shown there are several parts the interface The user inputs queries clicks the Analyze button and key words phrases are extracted from the input and stored Extraction key concepts done regular expression matching with built lexicon that ignores irrelevant words akin stop lists information extraction the context flight schedule query the figure the history text box shows that the concepts flights atlanta and tomorrow are extracted from the sentence which shown directly under the line Actually the extraction atlanta instead just atlanta would better for indicating atlanta destination city followup question that requests for flights houston instead The extracted information then used template matching SQL syntax this has not been implemented yet The user can input successively refine change their queries until the Reset button chosen restart new session Using Tcl also makes easy interface Web page with backend relational database engine Evaluation this application can not done since has not been completely developed yet However the pattern matching and key concept extraction component certainly show promise this point Thus with combination question answering conversational agents information retrieval and template matching techniques maybe the flight schedule query problem can dealt with feasibly Table Contents Discussion Conclusion and Future There are other problems that were overlooked What the user mistype their questions What the user does not follow correct English grammar rules this case current forms based methods flight schedule query the Web are definitely advantage Then again these Web sites are limited and return relatively large sets data that require further interpretation the part the user general natural language processing difficult subject Even with specific domain chosen problems are abound terms the bottom chart parser method ifa lexicon that deals with all possible flight schedule scenarios used dates times and flight numbers are given special identification parameters city names with multiple words are given special treatment and grammar rules are refined repeated testing then full proof flight schedule query system could possible However even the sentences could parsed the parsed result can not used readily integrating such system with web front end not straightforward because the resident LISP back end used for the chart parsing Even done rather resource intensive This led researching other possible ways make more feasible Hopefully the alternative method embodied the Tcl application discussed the previous section will prove promising Future WorkInterface LISP and the grammar lexicon web page Continue work Tcl application over the summer Table Contents References Allen James Natural Language Understanding Benjamin Cummings Redwood City Almasi Web Technology Make Information Available the Web Proceedings the Fourth Workshop Enabling Technologies Infrastructure for Collaborative Enterprises WET ICE Apr Berkeley Springs West Virginia IEEE Computer Society Press Los Alamitos Table Contents MIME Version Server CERN Date Tuesday Jan GMT Content Type text html Content Length Last Modified Wednesday Oct GMT Machine Learning Papers and AbstractsMachine Learning Papers and Abstracts view paper click the open book image Inductive Logic Programming for Natural Language Processing Raymond MooneyProceedings the International Inductive Logic Programming Workshop Stockholm Sweden August This paper reviews our recent work applying inductive logic programming the construction natural language processing systems have developed system CHILL that learns parser from training corpus parsed sentences inducing heuristics that control initial overly general shift reduce parser CHILL learns syntactic parsers well ones that translate English database queries directly into executable logical form The ATIS corpus airline information queries was used test the acquisition syntactic parsers and CHILL performed competitively with recent statistical methods English queries small database geography were used test the acquisition complete natural language interface and the parser that CHILL acquired was more accurate than existing hand coded system The paper also includes discussion several issues this work has raised regarding the capabilities and testing ILP systems well summary our current research directions Combining Symbolic and Connectionist Learning Methods Refine Certainty Factor Rule Bases Jeffrey Mahoney Thesis Department Computer Sciences University Texas Austin May This research describes the system RAPTURE which designed revise rule bases expressed certainty factor format Recent studies have shown that learning facilitated when biased with domain specific expertise and have also shown that many real world domains require some form probabilistic uncertain reasoning order successfully represent target concepts RAPTURE was designed take advantage both these results Beginning with set certainty factor rules along with accurately labelled training examples RAPTURE makes use both symbolic and connectionist learning techniques for revising the rules order that they correctly classify all the training examples modified version backpropagation used adjust the certainty factors the rules information gain heuristic used add new rules and the Upstart algorithm used create new hidden terms the rule base Results refining four real world rule bases are presented that demonstrate the effectiveness this combined approach Two these rule bases were designed identify particular areas strands DNA one for identifying infectious diseases and the fourth attempts diagnose soybean diseases The results RAPTURE are compared with those backpropagation KBANN and other learning systems RAPTURE generally produces sets rules that are more accurate that these other systems often creating smaller sets rules and using less training time Integrating EBL and ILP Acquire Control Rules for Planning Tara Estlin and Raymond MooneyProceedings the Third International Workshop Multi Strategy Learning Harpers Ferry May MSL Most approaches learning control information planning systems use explanation based learning generate control rules Unfortunately EBL alone often produces overly complex rules that actually decrease planning efficiency This paper presents novel learning approach for control knowledge acquisition that integrates explanation based learning with techniques from inductive logic programming EBL used constrain inductive search for selection heuristics that help planner choose between competing plan refinements SCOPE one the few systems address learning control information the newer partial order planners Specifically SCOPE learns domain specific control rules for version the UCPOP planning algorithm The resulting system shown produce significant speedup two different planning domains Comparative Experiments Disambiguating Word Senses Illustration the Role Bias Machine Learning Raymond MooneyProceedings the Conference Empirical Methods Natural Language Processing Philadelphia May This paper describes experimental comparison seven different learning algorithms the problem learning disambiguate the meaning word from context The algorithms tested include statistical neural network decision tree rule based and case based classification techniques The specific problem tested involves disambiguating six senses the word line using the words the current and proceeding sentence context The statistical and neural network methods perform the best this particular problem and discuss potential reason for this observed difference also discuss the role bias machine learning and its importance explaining performance differences observed specific problems Learning Parse Database Queries using Inductive Logic Programming John Zelle and Raymond MooneyProceedings the Thirteenth National Conference Aritificial Intelligence Portland August AAAI This paper presents recent work using the CHILL parser acquisition system automate the construction natural language interface for database queries CHILL treats parser acquisition the learning search control rules within logic program representing shift reduce parser and uses techniques from Inductive Logic Programming learn relational control knowledge Starting with general framework for constructing suitable logical form CHILL able train corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries Experimental results with complete database query application for geography show that CHILL able learn parsers that outperform pre existing hand crafted counterpart These results demonstrate the ability corpus based system produce more than purely syntactic representations They also provide direct evidence the utility empirical approach the level complete natural language application Novel Application Theory Refinement Student Modeling Paul Baffes and Raymond MooneyProceedings the Thirteenth National Conference Aritificial Intelligence Portland August AAAI Theory refinement systems developed machine learning automatically modify knowledge base render consistent with set classified training examples illustrate novel application these techniques the problem constructing student model for intelligent tutoring system ITS Our approach implemented ITS authoring system called Assert which uses theory refinement introduce errors into initially correct knowledge base that models incorrect student behavior The efficacy the approach has been demonstrated evaluating tutor developed with Assert with students tested classification task covering concepts from introductory course the programming language The system produced reasonably accurate models and students who received feedback based these models performed significantly better post test than students who received simple reteaching Qualitative Multiple Fault Diagnosis Continuous Dynamic Systems Using Behavioral Modes Siddarth Subramanian and Raymond MooneyProceedings the Thirteenth National Conference Aritificial Intelligence Portland August AAAI Most model based diagnosis systems such GDE and Sherlock have concerned discrete static systems such logic circuits and use simple constraint propagation detect inconsistencies However sophisticated systems such QSIM and QPE have been developed for qualitative modeling and simulation continuous dynamic systems present integration these two lines research implemented system called QDOCS for multiple fault diagnosis continuous dynamic systems using QSIM models The main contributions the algorithm include method for propagating dependencies while solving general constraint satisfaction problem and method for verifying the consistency behavior with model across time Through systematic experiments two realistic engineering systems demonstrate that QDOCS demonstrates the best balance generality accuracy and efficiency among competing methods Multi Strategy Learning Search Control for Partial Order Planning Tara Estlin and Raymond MooneyProceedings the Thirteenth National Conference Aritificial Intelligence Portland August AAAI Most research planning and learning has involved linear state based planners This paper presents SCOPE system for learning search control rules that improve the performance partial order planner SCOPE integrates explanation based and inductive learning techniques acquire control rules for partial order planner Learned rules are the form selection heuristics that help the planner choose between competing plan refinements Specifically SCOPE learns domain specific control rules for version the UCPOP planning algorithm The resulting system shown produce significant speedup two different planning domains Integrating Explanation Based and Inductive Learning Techniques Acquire Search Control for Planning Tara Estlin proposal Department Computer Sciences University Texas Austin Planning systems have become important tool for automating wide variety tasks Control knowledge guides planner find solutions quickly and crucial for efficient planning most domains Machine learning techniques enable planning system automatically acquire domain specific search control knowledge for different applications Past approaches learning control information have usually employed explanation based learning EBL generate control rules Unfortunately EBL alone often produces overly complex rules that actually decrease rather than improve overall planning efficiency This paper presents novel learning approach for control knowledge acquisition that integrates explanation based learning with techniques from inductive logic programming our learning system SCOPE EBL used constrain inductive search for control heuristics that help planner choose between competing plan refinements SCOPE one the few systems address learning control information for newer partial order planners Specifically this proposal describes how SCOPE learns domain specific control rules for the UCPOP planning algorithm The resulting system shown produce significant speedup two different planning domains and more effective than pure EBL approach Future research will performed three main areas First SCOPE learning algorithm will extended include additional techniques such constructive induction and rule utility analysis Second SCOPE will more thoroughly tested several real world planning domains have been identified possible testbeds and more depth comparisons will drawn between SCOPE and other competing approaches Third SCOPE will implemented different planning system order test its portability other planning algorithms This work should demonstrate that machine learning techniques can powerful tool the quest for tractable real world planning Lexical Acquisition Novel Machine Learning Problem Cynthia Thompson and Raymond Mooney Technical Report Artificial Intelligence Lab University Texas Austin This paper defines new machine learning problem which standard machine learning algorithms cannot easily applied The problem occurs the domain lexical acquisition The ambiguous and synonymous nature words causes the difficulty using standard induction techniques learn lexicon Additionally negative examples are typically unavailable difficult construct this domain One approach solve the lexical acquisition problem presented along with preliminary experimental results artificial corpus Future work includes extending the algorithm and performing tests more realistic corpus Advantages Decision Lists and Implicit Negative Inductive Logic Programming Mary Elaine Califf and Raymond Mooney Technical Report Artificial Intelligence Lab University Texas Austin This paper demonstrates the capabilities FOIDL inductive logic programming ILP system whose distinguishing characteristics are the ability produce first order decision lists the use output completeness assumption provide implicit negative examples and the use intensional background knowledge The development FOIDL was originally motivated the problem learning generate the past tense English verbs however this paper demonstrates its superior performance two different sets benchmark ILP problems Tests the finite element mesh design problem show that FOIDL decision lists enable produce better results than all other ILP systems whose results this problem have been reported Tests with selection list processing problems from Bratko introductory Prolog text demonstrate that the combination implicit negatives and intensionality allow FOIDL learn correct programs from far fewer examples than FOIL Learning Parse Decisions From Examples With Rich Context Ulf Hermjakob and Raymond Mooney Submitted the Annual Meeting the Association for Computational Linguistics ACL present knowledge and context based system for parsing natural language and evaluate sentences from the Wall Street Journal Applying machine learning techniques the system uses parse action examples acquired under supervision generate deterministic shift reduce parser the form decision structure relies heavily context encoded features which describe the morpholgical syntactical semantical and other aspects given parse state Corpus Based Lexical Acquisition For Semantic Parsing Cynthia Thompson proposal Department Computer Sciences University Texas Austin Building accurate and efficient natural language processing NLP systems important and difficult problem There has been increasing interest automating this process The lexicon the mapping from words meanings one component that typically difficult update and that changes from one domain the next Therefore automating the acquisition the lexicon important task automating the acquisition NLP systems This proposal describes system WOLFIE WOrd Learning From Interpreted Examples that learns lexicon from input consisting sentences paired with representations their meanings Preliminary experimental results show that this system can learn correct and useful mappings The correctness evaluated comparing known lexicon one learned from the training input The usefulness evaluated examining the effect using the lexicon learned WOLFIE assist parser acquisition system where previously this lexicon had hand built Future work the form extensions the algorithm further evaluation and possible applications discussed Refinement Bayesian Networks Combining Connectionist and Symbolic Techniques Sowmya Ramanchandran proposal Department Computer Sciences University Texas Austin Bayesian networks provide mathematically sound formalism for representing and reasoning with uncertain knowledge and are such widely used However acquiring and capturing knowledge this framework difficult There growing interest formulating techniques for learning Bayesian networks inductively While the problem learning Bayesian network given complete data has been explored some depth the problem learning networks with unobserved causes still open this proposal view this problem from the perspective theory revision and present novel approach which adapts techniques developed for revising theories symbolic and connectionist representations Thus assume that the learner given initial approximate network usually obtained from expert Our technique inductively revises the network fit the data better Our proposed system has two components one component revises the parameters Bayesian network known structure and the other component revises the structure the network The component for parameter revision maps the given Bayesian network into multi layer feedforward neural network with the parameters mapped weights the neural network and uses standard backpropagation techniques learn the weights The structure revision component uses qualitative analysis suggest revisions the network when fails predict the data accurately The first component has been implemented and will present results from experiments real world classification problems which show our technique effective will also discuss our proposed structure revision algorithm our plans for experiments evaluate the system well some extensions the system Refinement Based Student Modeling and Automated Bug Library Construction Paul Baffes and Raymond MooneyJournal Artificial Intelligence Education critical component model based intelligent tutoring sytems mechanism for capturing the conceptual state the student which enables the system tailor its feedback suit individual strengths and weaknesses useful such modeling technique must practical the sense that models are easy construct and effective the sense that using the model actually impacts student learning This research presents new student modeling technique which can automatically capture novel student errors using only correct domain knowledge and can automatically compile trends across multiple student models This approach has been implemented computer program ASSERT using machine learning technique called theory refinement which method for automatically revising knowledge base consistent with set examples Using knowledge base that correctly defines domain and examples student behavior that domain ASSERT models student errors collecting any refinements the correct knowledege base which are necessary account for the student behavior The efficacy the approach has been demonstrated evaluating ASSERT using students tested classification task covering concepts from introductory course the programming language Students who received feedback based the models automatically generated ASSERT performed significantly better post test than students who received simple teaching Comparative Results Using Inductive Logic Programming for Corpus based Parser Construction John Zelle and Raymond MooneySymbolic Connectionist and Statistical Approaches Learning for Natural Language Processing Wermter Riloff and Scheler Eds Spring Verlag This paper presents results from recent experiments with CHILL corpus based parser acquisition system CHILL treats language acquisition the learning search control rules within logic program Unlike many current corpus based approaches that use statistical learning algorithms CHILL uses techniques from inductive logic programming ILP learn relational representations CHILL very flexible system and has been used learn parsers that produce syntactic parse trees case role analyses and executable database queries The reported experiments compare CHILL performance that more naive application ILP parser acquisition The results show that ILP techniques employed CHILL are viable alternative statistical methods and that the control rule framework fundamental CHILL success Learning the Past Tense English Verbs Using Inductive Logic Programming Raymond Mooney and Mary Elaine CaliffSymbolic Connectionist and Statistical Approaches Learning for Natural Language Processing Wermter Riloff and Scheler Eds Spring Verlag This paper presents results using new inductive logic programming method called FOIDL learn the past tense English verbs The past tense task has been widely studied the context the symbolic connectionist debate Previous papers have presented results using various neural network and decision tree learning methods have developed technique for learning special type Prolog program called first order decision list defined ordered list clauses each ending cut FOIDL based FOIL Quinlan but employs intensional background knowledge and avoids the need for explicit negative examples particularly useful for problems that involve rules with specific exceptions such the past tense task present results showing that FOIDL learns more accurate past tense generator from significantly fewer examples than all other previous methods Hybrid Learning Search Control for Partial Order Planning Tara Estlin and Raymond Mooney New Directions Planning Ghallab and Milani Eds IOS Press This paper presents results applying version the DOLPHIN search control learning system speed partial order planner DOLPHIN integrates explanation based and inductive learning techniques acquire effective clause selection rules for Prolog programs version the UCPOP partial order planning algorithm has been implemented Prolog program and DOLPHIN used automatically learn domain specific search control rules that help eliminate backtracking The resulting system shown produce significant speedup several planning domains Revising Bayesian Network Parameters Using Connectionist Methods Sowmya Ramachandran and Raymond MooneyProceedings the International Conference Neural Networks ICNN Special Session Knowledge Based Artificial Neural Networks Washington June The problem learning Bayesian networks with hidden variables known hard problem Even the simpler task learning just the conditional probabilities Bayesian network with hidden variables hard this paper present approach that learns the conditional probabilities Bayesian network with hidden variables transforming into multi layer feedforward neural network ANN The conditional probabilities are mapped onto weights the ANN which are then learned using standard backpropagation techniques avoid the problem exponentially large ANNs focus Bayesian networks with noisy and noisy and nodes Experiments real world classification problems demonstrate the effectiveness our technique Qualitative Multiple Fault Diagnosis Continuous Dynamic Systems Using Behavioral Modes Siddarth Subramanian Thesis Department Computer Sciences University Texas Austin August systems like chemical plants power plants and automobiles get more complex online diagnostic systems are becomingly increasingly important One the ways rein the complexity describing and reasoning about large systems such these describe them using qualitative rather than quantitative models Model based diagnosis class diagnostic techniques that use direct knowledge about how system functions instead expert rules detailing causes for every possible set symptons broken system Our research builds standard methods for model based diagnosis and extends them the domain complex dynamic systems described using qualitative models motivate and describe out algorithm for diagnosing faults dynamic system given qualitative model and sequence qualitative states The main contributions this algorithm include method for propagating dependencies while solving general constraint satisfaction problem and method for verfying the compatibility behavior with model across time The algorithm can diagnose multiple faults and uses models faulty behavior behavioral modes then demonstrate these techniques using implemented program called QDOCS and test some realistic problems Through our experiments with model the reaction control system RCS the space shuttle and with level controller for reaction tank show that QDOCS demonstrates the best balance generality accuracy and efficiency among known systems Using Inductive Logic Programming Automate the Construction Natural Language Parsers John Zelle Thesis Department Computer Sciences University Texas Austin August Designing computer systems understand natural language input difficult task recent years there has been considerable interest corpus based methods for constructing natural language parsers These empirical approaches replace hand crafted grammars with linguistic models acquired through automated training over language corpora common thread among such methods date the use propositional probablistic representations for the learned knowledge This dissertation presents alternative approach based techniques from subfield machine learning known inductive logic programming ILP ILP which investigates the learning relational first order rules provides empirical method for acquiring knowledge within traditional symbolic parsing frameworks This dissertation details the architecture implementation and evaluation CHILL computer system for acquiring natural language parsers training over corpora parsed text CHILL treats language acquisition the learning search control rules within logic program that implements shift reduce parser Control rules are induced using novel ILP algorithm which handles difficult issues arising the induction search control heuristics Both the control rule framework and the induction algorithm are crucial CHILL success The main advantage CHILL over propositional counterparts its flexibility handling varied representations CHILL has produced parsers for various analyses including case role mapping detailed syntactic parse trees and logical form suitable for expressing first order database queries All these tasks are accomplished within the same framework using single general learning method that can acquire new syntactic and semantic categories for resolving ambiguities Experimental evidence from both aritificial and real world corpora demonstrate that CHILL learns parsers well better than previous artificial neural network probablistic approaches comparable tasks the database query domain which goes beyond the scope previous empirical approaches the learned parser outperforms existing hand crafted system These results support the claim that ILP techniques implemented CHILL represent viable alternative with significant potential advantages over neural network propositional and probablistic approaches empirical parser construction Inductive Logic Programming Method for Corpus based Parser Construction John Zelle and Raymond Mooney Submitted Computational Linguistics recent years there has been considerable research into corpus based methods for parser construction common thread this research has been the use propositional representations for learned knowledge This paper presents alternative approach based techniques from subfield machine learning known inductive logic programming ILP ILP which investigates the learning relational first order rules provides way using empricial methods acquire knowledge within traditional symbolic parsing frameworks describe novel method for constructing deterministic Prolog parsers from corpora parsed sentences also discuss several advantages this approach compared propositional alternatives and present experimental results learning complete parsers using several corpora including the ATIS corpus from the Penn Treebank Comparison Two Methods Employing Inductive Logic Programming for Corpus based Parser Constuction John Zelle and Raymond MooneyWorking Notes the IJCAI Workshop New Approaches Learning for Natural Language Processing Montreal Quebec August This paper presents results from recent experiments with CHILL corpus based parser acquisition system CHILL treats grammar acquisition the learning search control rules within logic program Unlike many current corpus based approaches that use propositional probabilistic learning algorithms CHILL uses techniques from inductive logic programming ILP learn relational representations The reported experiments compare CHILL performance that more naive application ILP parser acquisition The results show that ILP techniques employed CHILL are viable alternative propositional methods and that the control rule framework fundamental CHILL success Inducing Logic Programs without Explicit Negative Examples John Zelle Cynthia Thompson Mary Elaine Califf and Raymond MooneyProceedings the Fifth International Workshop Inductive Logic Programming Leuven Belguim Sepetember This paper presents method for learning logic programs without explicit negative examples exploiting assumption output completeness mode declaration supplied for the target predicate and each training input assumed accompanied all its legal outputs Any other outputs generated incomplete program implicitly represent negative examples however large numbers ground negative examples never need generated This method has been incorporated into two ILP systems CHILLIN and IFOIL both which use intensional background knowledge Tests two natural language acquisition tasks case role mapping and past tense learning illustrate the advantages the approach Acquisition Lexicon from Semantic Representations Sentences Cynthia Thompson Annual Meeting the Association Computational Linguistics Boston July ACL system WOLFIE that acquires mapping words their semantic representation presented and preliminary evaluation performed Tree least general generalizations TLGGs the representations input sentences are performed assist determining the representations individual words the sentences The best guess for meaning word the TLGG which overlaps with the highest percentage sentence representations which that word appears Some promising experimental results non artificial data set are presented Induction First Order Decision Lists Results Learning the Past Tense English Verbs Raymond Mooney and Mary Elaine Califf Journal Artificial Intelligence Research This paper presents method for inducing logic programs from examples that learns new class concepts called first order decision lists defined ordered lists clauses each ending cut The method called FOIDL based FOIL but employs intensional background knowledge and avoids the need for explicit negative examples particularly useful for problems that involve rules with specific exceptions such learning the past tense English verbs task widely studied the context the symbolic connectionist debate FOIDL able learn concise accurate programs for this problem from significantly fewer examples than previous methods both connectionist and symbolic Multiple Fault Diagnosis Using General Qualitative Models with Fault Modes Siddarth Subramanian and Raymond Mooney Working Notes the IJCAI Workshop Engneering Problems for Qualitative Reasoning Monreal Quebec August This paper describes approach diagnosis systems described qualitative differential equations represented QSIM models implemented system QDOCS described that performs multiple fault fault model based diagnosis using constraint satisfaction techniques qualitative behaviors systems described such models demonstrate the utility this system accurately diagnosing randomly generated faults using simulated behaviors portion the Reaction Control System the space shuttle Learning Qualitative Models for Systems with Multiple Operating Regions Sowmya Ramachandran Raymond Mooney and Benjamin Kuipers Proceedings the Eight International Workshop Qualitative Reasoning about Physical Systems Nara Japan June The problem learning qualitative models physical systems from observations its behaviour has been addressed several researchers recent years Most current techniques limit themselves learning single qualitative differential equation model the entire system However many systems have several qualitative differential equations underlying them this paper present approach learning the models for such systems Our technique divides the behaviours into segments each which can explained single qualitative differential equation The qualitative model for each segment can generated using any the existing techniques for learning single model show that results applying our technique several examples and demonstrate that effective Multiple Fault Diagnosis Using General Qualitative Models with Fault Modes Siddarth Subramanian and Raymond Mooney Working Papers the Fifth International Workshop Principles Diagnosis New Paltz This paper describes approach diagnosis systems described qualitative differential equations represented QSIM models implemented system QDOCS described that performs multiple fault fault model based diagnosis using constraint satisfaction techniques qualitative behaviors systems described such models demonstrate the utility this system accurately diagnosing randomly generated faults using simulated behaviors portion the Reaction Control System the space shuttle Automatic Student Modeling and Bug Library Construction using Theory Refinement Paul Baffes Thesis Department Computer Sciences University Texas Austin December The history computers education can characterized continuing effort construct intelligent tutorial programs which can adapt the individual needs student one one setting critical component these intelligent tutorials mechanism for modeling the conceptual state the student that the system able tailor its feedback suit individual strengths and weaknesses The primary contribution this research new student modeling technique which can automatically capture novel student errors using only correct domain knowledge and can automatically compile trends across multiple student models into bug libraries This approach has been implemented computer program ASSERT using machine learning technique called theory refinement which method for automatically revising knowledge base consistent with set examples Using knowledge base that correctly defines domain and examples student behavior that domain ASSERT models student errors collecting any refinements the correct knowledge base which are necessary account for the student behavior The efficacy the approach has been demonstrated evaluating ASSERT using students tested classification task using concepts from introductory course the programming language Students who received feedback based the models automatically generated ASSERT performed significantly better post test than students who received simple reteaching Inductive Learning For Abductive Diagnosis Cynthia Thompson and Raymond Mooney Proceedings the Twelfth National Conference Seattle July AAAI new inductive learning system LAB Learning for ABduction presented which acquires abductive rules from set training examples The goal find small knowledge base which when used abductively diagnoses the training examples correctly and generalizes well unseen examples This contrasts with past systems that inductively learn rules that are used deductively Each training example associated with potentially multiple categories disorders instead one with typical learning systems LAB uses simple hill climbing algorithm efficiently build rule base for set covering abductive system LAB has been experimentally evaluated and compared other learning systems and expert knowledge base the domain diagnosing brain damage due stroke Comparing Methods For Refining Certainty Factor Rule Bases Jeffrey Mahoney and Raymond Mooney Proceedings the Eleventh International Workshop Machine Learning Rutgers July This paper compares two methods for refining uncertain knowledge bases using propositional certainty factor rules The first method implemented the RAPTURE system employs neural network training refine the certainties existing rules but uses symbolic technique add new rules The second method based the one used the KBANN system initially adds complete set potential new rules with very low certainty and allows neural network training filter and adjust these rules Experimental results indicate that the former method results significantly faster training and produces much simpler refined rule bases with slightly greater accuracy Modifying Network Architectures For Certainty Factor Rule Base Revision Jeffrey Mahoney and Raymond Mooney Proceedings the International Symposium Integrating Knowledge and Neural Heuristics Pensacola May ISIKNH This paper describes RAPTURE system for revising probabilistic rule bases that converts symbolic rules into connectionist network which then trained via connectionist techniques uses modified version backpropagation refine the certainty factors the rule base and uses information gain heuristic Quinlan add new rules Work currently under way for finding improved techniques for modifying network architectures that include adding hidden units using the UPSTART algorithm Frean case made via comparison with fully connected connectionist techniques for keeping the rule base close the original possible adding new input units only needed Combining Top Down And Bottom Techniques Inductive Logic Programming John Zelle Raymond Mooney and Joshua Konvisser Proceedings the Eleventh International Workshop Machine Learning Rutgers July This paper describes new method for inducing logic programs from examples which attempts integrate the best aspects existing ILP methods into single coherent framework particular combines bottom method similar GOLEM with top down method similar FOIL also includes method for predicate invention similar CHAMP and elegant solution the noisy oracle problem which allows the system learn recursive programs without requiring complete set positive examples Systematic experimental comparisons both GOLEM and FOIL range problems are used clearly demonstrate the advantages the approach Inducing Deterministic Prolog Parsers From Treebanks Machine Learning Approach John Zelle and Raymond Mooney Proceedings the Twelfth National Conference Seattle July AAAI This paper presents method for constructing deterministic context sensitive Prolog parsers from corpora parsed sentences Our approach uses recent machine learning methods for inducing Prolog rules from examples inductive logic programming discuss several advantages this method compared recent statistical methods and present results learning complete parsers from portions the ATIS corpus Integrating ILP and EBL Raymond Mooney and John Zelle SIGART Bulletin Volume number Jan This paper presents review recent work that integrates methods from Inductive Logic Programming ILP and Explanation Based Learning EBL ILP and EBL methods have complementary strengths and weaknesses and number recent projects have effectively combined them into systems with better performance than either the individual approaches particular integrated systems have been developed for guiding induction with prior knowledge SMART FOCL GRENDEL refining imperfect domain theories FORTE AUDREY and learning effective search control knowledge AxA EBL DOLPHIN Extending Theory Refinement Rules Paul Baffes and Raymond Mooney Informatica recent years machine learning research has started addressing problem known theory refinement The goal theory refinement learner modify incomplete incorrect rule base representing domain theory make consistent with set input training examples This paper presents major revision the EITHER propositional theory refinement system Two issues are discussed First show how run time efficiency can greatly improved changing from exhaustive scheme for computing repairs iterative greedy method Second show how extend EITHER refine MofN rules The resulting algorithm Neither New EITHER more than order magnitude faster and produces significantly more accurate results with theories that fit the MofN format demonstrate the advantages NEITHER present experimental results from two real world domains Inductive Learning for Abductive Diagnosis Cynthia Thompson Thesis Department Computer Sciences University Texas Austin new system for learning induction called LAB presented LAB Learning for ABduction learns abductive rules based set training examples Our goal find small knowledge base which when used abductively diagnoses the training examples correctly addition generalizing well unseen examples This contrast past systems which inductively learn rules which are used deductively Abduction particularly well suited diagnosis which are given set symptoms manifestations and want our output set disorders which explain why the manifestations are present Each training example associated with potentially multiple categories instead one which the case with typical learning systems Building the knowledge base requires choice between multiple possibilities and the number possibilities grows exponentially with the number training examples One method choosing the best knowledge base described and implemented The final system experimentally evaluated using data from the domain diagnosing brain damage due stroke compared other learning systems and knowledge base produced expert The results are promising the rule base learned simpler than the expert knowledge base and rules learned one the other systems and the accuracy the learned rule base predicting which areas are damaged better than all the other systems well the expert knowledge base Learning Model Students Using Theory Refinement Detect Misconceptions Paul Baffes proposal Department Computer Sciences University Texas Austin new student modeling system called ASSERT described which uses domain independent learning algorithms model unique student errors and automatically construct bug libraries ASSERT consists two learning phases The first application theory refinement techniques for constructing student models from correct theory the domain being tutored The second learning cycle automatically constructs the bug library extracting common refinements from multiple student models which are then used bias future modeling efforts Initial experimental data will presented which suggests that ASSERT more effective modeling system than other induction techniques previously explored for student modeling and that the automatic bug library construction significantly enhances subsequent modeling efforts Learning Search Control Heuristics for Logic Programs Applications Speedup Learning and Language Acquisition John Zelle proposal Department Computer Sciences University Texas Austin This paper presents general framework learning search control heuristics for logic programs which can used improve both the efficiency and accuracy knowledge based systems expressed definite clause logic programs The approach combines techniques explanation based learning and recent advances inductive logic programming learn clause selection heuristics that guide program execution Two specific applications this framework are detailed dynamic optimization Prolog programs improving efficiency and natural language acquisition improving accuracy the area program optimization prototype system DOLPHIN able transform some intractable specifications into polynomial time algorithms and outperforms competing approaches several benchmark speedup domains prototype language acquisition system CHILL also described capable automatically acquiring semantic grammars which uniformly incorprate syntactic and semantic constraints parse sentences into case role representations Initial experiments show that this approach able construct accurate parsers which generalize well novel sentences and significantly outperform previous approaches learning case role mapping based connectionist techniques Planned extensions the general framework and the specific applications well plans for further evaluation are also discussed Combining FOIL and EBG Speed Logic Programs John Zelle and Raymond Mooney Proceedings the Thirteenth International Joint Conference Artificial Intelligence Chambery France IJCAI This paper presents algorithm that combines traditional EBL techniques and recent developments inductive logic programming learn effective clause selection rules for Prolog programs When these control rules are incorporated into the original program significant speed may achieved The algorithm shown improvement over competing EBL approaches several domains Additionally the algorithm capable automatically transforming some intractable algorithms into ones that run polynomial time Symbolic Revision Theories With Rules Paul Baffes and Raymond Mooney Proceedings the Thirteenth International Joint Conference Artificial Intelligence Chambery France IJCAI This paper presents major revision the EITHER propositional theory refinement system Two issues are discussed First show how run time efficiency can greatly improved changing from exhaustive scheme for computing repairs iterative greedy method Second show how extend EITHER refine rules The resulting algorithm NEITHER New EITHER more than order magnitude faster and produces significantly more accurate results with theories that fit the format demonstrate the advantages NEITHER present preliminary experimental results comparing EITHER and various other systems refining the DNA promoter domain theory Learning Semantic Grammars With Constructive Inductive Logic Programming John Zelle and Raymond Mooney Proceedings the Eleventh National Conference the American Association for Artificial Intelligence Washington July AAAI Automating the construction semantic grammars difficult and interesting problem for machine learning This paper shows how the semantic grammar acquisition problem can viewed the learning search control heuristics logic program Appropriate control rules are learned using new first order induction algorithm that automatically invents useful syntactic and semantic categories Empirical results show that the learned parsers generalize well novel sentences and out perform previous approaches based connectionist techniques Combining Connectionist and Symbolic Learning Refine Certainty Factor Rule Bases Jeffrey Mahoney and Raymond Mooney Connection Science Special issue Architectures for Integrating Neural and Symbolic Processing This paper describes Rapture system for revising probabilistic knowledge bases that combines connectionist and symbolic learning methods Rapture uses modified version backpropagation refine the certainty factors Mycin style rule base and uses information gain heuristic add new rules Results refining three actual expert knowledge bases demonstrate that this combined approach generally performs better than previous methods Refinement First Order Horn Clause Domain Theories Bradley Richards and Raymond Mooney Machine Learning Knowledge acquisition difficult and time consuming task and error prone any human activity The task automatically improving existing knowledge base using learning methods addressed new class systems performing theory refinement Until recently such systems were limited propositional theories This paper presents system FORTE First Order Revision Theories from Examples for refining first order Horn clause theories Moving first order representation opens many new problem areas such logic program debugging and qualitative modelling that are beyond the reach propositional systems FORTE uses hill climbing approach revise theories identifies possible errors the theory and calls library operators develop possible revisions The best revision implemented and the process repeats until further revisions are possible Operators are drawn from variety sources including propositional theory refinement first order induction and inverse resolution FORTE has been tested several domains including logic programming and qualitative modelling Encouraging Experimental Results Learning CNF Raymond Mooney Machine Learning This paper presents results comparing three inductive learning systems using different representations for concepts namely CNF formulae DNF formulae and decision trees The CNF learner performs surprisingly well Results five natural data sets show that frequently trains faster and produces more accurate and simpler concepts The probable explanation for its superior performance that the other systems are more susceptible the replication problem Belief Revision the Context Abductive Explanation Siddarth Subramanian Technical Report Artificial Intelligence Lab University Texas Austin March This proposal presents approach explanation that incorporates the paradigms belief revision and abduction present algorithm that combines these techniques and system called BRACE that preliminary implementation this algorithm show the applicability the BRACE approach wide range domains including scientific discovery device diagnosis and plan recognition Finally describe our proposals for new implementation new application domains for our system and extensions this approach First Order Horn Clause Abductive System and Its Use Plan Recognition and Diagnosis Hwee Tou and Raymond Mooney Submitted for journal publication diverse set intelligent activities including natural language understanding and diagnosis requires the ability construct explanations for observed phenomena this paper view explanation abduction where abductive explanation consistent set assumptions which together with background knowledge logically entails set observations have successfully built domain independent system ACCEL which knowledge about variety domains uniformly encoded first order Horn clause axioms general purpose abduction algorithm AAA efficiently constructs explanations the various domains caching partial explanations avoid redundant work Empirical results show that caching partial explanations can achieve more than order magnitude speedup run time have applied our abductive system two general tasks plan recognition text understanding and diagnosis medical diseases logic circuits and dynamic systems The results indicate that ACCEL general purpose system capable plan recognition and diagnosis yet efficient enough practical utility Abductive Plan Recognition and Diagnosis Comprehensive Empirical Evaluation Hwee Tou and Raymond Mooney Proceedings the Third International Conference Principles Knowledge Representation and Reasoning Cambridge October While has been realized for quite some time within that abduction general model explanation for variety tasks there have been empirical investigations into the practical feasibility general logic based abductive approach explanation this paper present extensive empirical results applying general abductive system ACCEL moderately complex problems plan recognition and diagnosis plan recognition ACCEL has been tested short narrative texts inferring characters plans from actions described text medical diagnosis ACCEL has diagnosed real world patient cases involving brain damage due stroke previously addressed set covering methods ACCEL also uses abduction accomplish model based diagnosis logic circuits full adder and continuous dynamic systems temperature controller and the water balance system the human kidney The results indicate that general purpose abduction effective and efficient mechanism for solving problems plan recognition and diagnosis Automatic Abduction Qualitative Models Bradley Richards Ina Kraan and Benjamin Kuipers Proceedings the Tenth National Conference Artificial Intelligence San Jose July describe method automatically abducing qualitative models from descriptions behaviors generate from either quantitative qualitative data models the form qualitative differential equations suitable for use QSIM Constraints are generated and filtered both comparison with the input behaviors and dimensional analysis the user provides complete information the input behaviors and the dimensions the input variables the resulting model unique maximally constrainted and guaranteed reproduce the input behaviors the user provides incomplete information our method will still generate model which reproduces the input behaviors but the model may longer unique Incompleteness can take several forms missing dimensions values variables entire variables Learning Relations Pathfinding Bradley Richards and Raymond Mooney Proceedings the Tenth National Conference Artificial Intelligence San Jose July First order learning systems FOIL FOCL FORTE generally rely hill climbing heuristics order avoid the combinatorial explosion inherent learning first order concepts However hill climbing leaves these systems vulnerable local maxima and local plateaus present method called relational pathfinding which has proven highly effective escaping local maxima and crossing local plateaus present our algorithm and provide learning results two domains family relationships and qualitative model building Speeding Logic Programs Combining EBG and FOIL John Zelle and Raymond Mooney Proceedings the Machine Learning Workshop Knowledge Compilation and Speedup Learning Aberdeen Scotland July This paper presents algorithm that combines traditional EBL techniques and recent developments inductive logic programming learn effective clause selection rules for Prolog programs When these control rules are incorporated into the original program significant speed may achieved The algorithm produces not only EBL like speed problem solvers but capable automatically transforming some intractable algorithms into ones that run polynomial time Combining Symbolic and Neural Learning Revise Probabilistic Theories Jeffrey Mahoney Raymond Mooney Proceedings the Machine Learning Workshop Integrated Learning Real Domains Aberdeen Scotland July This paper describes RAPTURE system for revising probabilistic theories that combines symbolic and neural network learning methods RAPTURE uses modified version backpropagation refine the certainty factors Mycin style rule base and uses information gain heuristic add new rules Results two real world domains demonstrate that this combined approach performs well better than previous methods Growing Layers Perceptrons Introducing the Extentron Algorithm Paul Baffes and John Zelle Proceedings the International Joint Conference Neural Networks Baltimore Maryland June The ideas presented here are based two observations perceptrons when the perceptron learning algorithm cycles among hyperplanes the hyperplanes may compared select one that gives best SPLIT the examples and always possible for the perceptron build hyperplane that separates least one example from all the rest describe the Extentron which grows multi layer networks capable distinguishing non linearly separable data using the simple perceptron rule for linear threshold units The resulting algorithm simple very fast scales well large problems retains the convergence properties the perceptron and can completely specified using only two parameters Results are presented comparing the Extentron other neural network paradigms and symbolic learning systems Using Theory Revision Model Students and Acquire Stereotypical Errors Paul Baffes and Raymond Mooney Proceedings the Fourteenth Annual Conference the Cognitive Science Society Bloomington July Student modeling has been identified important component the long term development Intelligent Computer Aided Instruction ICAI systems Two basic approaches have evolved model student misconceptions One uses static predefined library user bugs which contains the misconceptions modeled the system The other uses induction learn student misconceptions from scratch Here present third approach that uses machine learning technique called theory revision Using theory revision allows the system automatically construct bug library for use modeling while retaining the flexibility address novel errors Preliminary PAC Analysis Theory Revision Raymond Mooney Computational Learning Theory and Natural Learning Systems Vol Petsche Judd and Hanson Eds MIT Press This paper presents preliminary analysis the sample complexity theory revision within the framework PAC Probably Approximately Correct learnability theory formalizing the notion that the initial theory close the correct theory show that the sample complexity optimal propositional Horn clause theory revision algorithm delta epsilon where the syntactic distance between the initial and correct theories the size initial theory the number observable features and epsilon and delta are the standard PAC error and probability bounds The paper also discusses the problems raised the computational complexity theory revision Automated Debugging Logic Programs via Theory Revision Raymond Mooney Bradley Richards Proceedings the Second International Workshop Inductive Logic Programming Tokyo Japan June This paper presents results using theory revision system automatically debug logic programs FORTE recently developed system for revising function free Horn clause theories Given theory and set training examples performs hill climbing search attempt minimally modify the theory correctly classify all the examples FORTE makes use methods from propositional theory revision Horn clause induction FOIL and inverse resolution The system has has been successfully used debug logic programs written undergraduate students for programming languages course Batch versus Incremental Theory Refinement Raymond Mooney Proceedings AAAI Spring Symposium Knowledge Assimilation Standford March Most existing theory refinement systems are not incremental However any theory refinement system whose input and output theories are compatible can used incrementally assimilate data into evolving theory This done continually feeding its revised theory back its input theory incremental batch approach which the system assimilates batch examples each step seems most appropriate for existing theory revision systems Experimental results with the EITHER theory refinement system demonstrate that this approach frequently increases efficiency without significantly decreasing the accuracy the simplicity the resulting theory However the system produces bad initial changes the theory based only small amount data these bad revisions can snowball and result overall decrease performance Multistrategy Approach Theory Refinement Raymond Mooney Dirk Ourston Machine Learning Multistrategy Approach Vol Michalski Teccuci eds Morgan Kaufman San Mateo This chapter describes multistrategy system that employs independent modules for deductive abductive and inductive reasoning revise arbitrarily incorrect propositional Horn clause domain theory fit set preclassified training instances combining such diverse methods EITHER able handle wider range imperfect theories than other theory revision systems while guaranteeing that the revised theory will consistent with the training data EITHER has successfully revised two actual expert theories one molecular biology and one plant pathology The results confirm the hypothesis that using multistrategy system learn from both theory and data gives better results than using either theory data alone Integrating Theory and Data Category Learning Raymond Mooney Categorization Humans and Machines The Psychology Learning and Motivation Vol Nakamura Taraban Medin Eds Academic Press Orlando Recent results both machine learning and cognitive psychology demonstrate that effective category learning involves integration theory and data First theories can bias induction affecting what category definitions are extracted from set examples Second conflicting data can cause theories revised Third theories can alter the representation data through feature formation This chapter reviews two machine learning systems that attempt integrate theory and data one more these ways IOU uses domain theory acquire part concept definition and focus induction the unexplained aspects the data EITHER uses data revise imperfect theory and uses theory add abstract features the data Recent psychological experiments reveal that these machine learning systems exhibit several important aspects human category learning Specifically IOU has been used successfully model some recent experimental results the effect functional knowledge category learning Theory Refinement Combining Analytical and Empirical Methods Dirk Ourston and Raymond Mooney Artificial Intelligence This article describes comprehensive approach automatic theory revision Given imperfect theory the approach combines explanation attempts for incorrectly classified examples order identify the failing portions the theory For each theory fault correlated subsets the examples are used inductively generate correction Because the corrections are focused they tend preserve the structure the original theory Because the system starts with approximate domain theory general fewer training examples are required attain given level performance classification accuracy compared purely empirical system The approach applies classification systems employing propositional Horn clause theory The system has been tested variety application domains and results are presented for problems the domains molecular biology and plant disease diagnosis Induction Over the Unexplained Using Overly General Domain Theories Aid Concept Learning Raymond Mooney Machine Learning This paper describes and evaluates approach combining empirical and explanation based learning called Induction Over the Unexplained IOU IOU intended for learning concepts that can partially explained overly general domain theory eclectic evaluation the method presented which includes results from all three major approaches empirical theoretical and psychological Empirical results shows that IOU effective refining overly general domain theories and that learns more accurate concepts from fewer examples than purely empirical approach The application theoretical results from PAC learnability theory explains why IOU requires fewer examples IOU also shown able model psychological data demonstrating the effect background knowledge human learning Efficient First Order Horn Clause Abduction System Based the ATMS Hwee Tou and Raymond Mooney Proceedings the Ninth National Conference Artificial Intelligence pages Anaheim July This paper presents algorithm for first order Horn clause abduction that uses ATMS avoid redundant computation This algorithm either more efficient more general than any other previous abduction algorithm Since computing all minimal abductive explanations intractable also present heuristic version the algorithm that uses beam search compute subset the simplest explanations present empirical results broad range abduction problems from text understanding plan recognition and device diagnosis which demonstrate that our algorithm least order magnitude faster than alternative abduction algorithm that does not use ATMS Improving Shared Rules Multiple Category Domain Theories Dirk Ourston and Raymond Mooney Proceedings the Eighth International Machine Learning Workshop Evanston June This paper presents approach improving the classification performance multiple category theory correcting intermediate rules which are shared among the categories Using this technique the performance theory one category can improved through training entirely different category Examples the technique are presented and experimental results are given Constructive Induction Theory Refinement Raymond Mooney and Dirk Ourston Proceedings the Eighth International Machine Learning Workshop Evanston June This paper presents constructive induction techniques recently added the EITHER theory refinement system These additions allow EITHER handle arbitrary gaps the top middle and bottom incomplete domain theory Intermediate concept utilization employs existing rules the theory derive higher level features for use induction Intermediate concept creation employs inverse resolution introduce new intermediate concepts order fill gaps theory that span multiple levels These revisions allow EITHER make use imperfect domain theories the ways typical previous work both constructive induction and theory refinement result EITHER able handle wider range theory imperfections than does any other existing theory refinement system Theory Refinement with Noisy Data Raymond Mooney and Dirk Ourston Technical Report Artificial Intelligence Lab University Texas Austin March This paper presents method for revising approximate domain theory based noisy data The basic idea avoid making changes the theory that account for only small amount data This method implemented the EITHER propositional Horn clause theory revision system The paper presents empirical results artificially corrupted data show that this method successfully prevents over fitting other words when the data noisy performance novel test data considerably better than revising the theory completely fit the data When the data not noisy noise processing causes significant degradation performance Finally noise processing increases efficiency and decreases the complexity the resulting theory the Role Coherence Abductive Explanation Hwee Tou and Raymond Mooney Proceedings the Eighth National Conference Artificial Intelligence pages Boston Abduction important inference process underlying much human intelligent activities including text understanding plan recognition disease diagnosis and physical device diagnosis this paper describe some problems encountered using abduction understand text and present some solutions overcome these problems The solutions propose center around the use different criterion called explanatory coherence the primary measure evaluate the quality explanation addition explanatory coherence plays important role the construction explanations both determining the appropriate level specificity preferred explanation and guiding the heuristic search efficiently compute explanations sufficiently high quality estlin utexas edu Date Wed Jan GMT Server Apache Connection close Content Type text html Last Modified Thu Oct GMT ETag Content Length Accept Ranges bytes EVOLUTIONARY COMPUTATIONQuarterly Volume forthcoming Spring Summer Fall Winter per issue Founded ISSN Kenneth Jong EditorStephanie Forrest John Grefenstette Hiroaki Kitano Heinz Date Tue Nov GMT Server NCSA Content type text html Last modified Mon Sep GMT Content length Advanced Operating Systems Fall UNIVERSITY WISCONSIN MADISON Computer Sciences DepartmentCS Fall Bart MillerCS Advanced Operating SystemsPaper Assignment Due Wednesday September Description The goal this assignment think about and describe the memory management facility new and powerful computer You will use the ideas that you have read about and apply these different environment The computer that you are thinking about will have some interesting characteristics First will multiprocessor with CPU There will many CPU sharing the same memory see figure below This computer will support parallel programs consisting many processes cooperating single computation Parallel programs will share memory communicate and use mechanism such semaphores spin locks monitors synchronize Second will have large physical memory will common see machines with megabytes more RAM with page frames These large memories will useful supporting applications graphics vision CAD and databases Remember large page frames and physical memory and lots sharing You are describe how the Working Set concept can help efficiently allocate the memory and CPU this workstation design There are two areas that you will address First how can you use the concept Working Set efficiently execute parallel programs For example might have simple producer consumer pair processes How can schedule the CPU and memory make this program execute well What about more complex computations made many processes What about the competition between several parallel programs for resources How define resource demand and balance set How you define the last referenced time for page shared many processes Second how does the large address space affect resource scheduling memory scheduling dead issue applications with extremely large memory demands change the way allocate memory What about the cost gathering scheduling information and storing tables You paper will make design decisions that may require data about the type programs that will run the workstation and how these programs will behave You should describe what information you need and how you will about collecting the information make these design decisions You should also describe how you will verify these decisions and how you will set the parameters the various policies that you design you are thinking about your design you should think about the goal and features previous systems Which these goals are longer important What are the significant differences this new computer from ones that have read about You will course want consider what goals are still important Can you use solutions from the past will you satisfy these goals new ways Constraints The paper should most pages point font double spaced single sided and inch margins The paper must contain the following parts Title The title should descriptive and fit one line across the page Interesting titles are acceptable but avoid overly cute ones Abstract This the paper brief not description the paper should state the basic contents and conclusions the paper advertisement that will draw the reader your paper without being misleading should complete enough understand what will covered the paper Avoid phrases such The paper describes This technical paper and not mystery novel don afraid giving away the ending Body This the main part the paper should include introduction that prepares the reader for the remainder the paper Assume that the reader knowledgeable about Working Set and operating systems The introduction should motivate the rest the discussion and outline the approach The main part the paper should split into reasonable sections The last part the body the conclusion This discussion what the reader should have learned from the paper You can repeat things stated earlier the paper but only the extent that they contribute the final discussion References You must cite each paper that you have referenced This section appears the end the paper Figures paper without figures graphs diagrams boring rule thumb one figure for each pages These figures should typically take only small portion page Your paper must have figures not redescribe the assignment address the issues described above The paper must written using correct English grammar There should spelling mistakes paper that difficult read has poor grammar will returned ungraded Remember the word the day pithy Last modified Mon Sep CDT bart 