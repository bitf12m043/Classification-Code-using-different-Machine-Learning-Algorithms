MIME Version Server CERN Date Sunday Nov GMT Content Type text html Content Length Last Modified Wednesday Sep GMT Query Humming Musical Information Retrieval Audio Database ACM Multimedia Electronic Proceedings November San Francisco California Query Humming Musical Information Retrieval Audio Database Asif GhiasDepartment Computer Science Upson Hall Cornell University Ithaca ghias cornell edu Jonathan LoganDepartment Computer Science Upson Hall Cornell University Ithaca logan ghs com David Chamberlin School Electrical Engineering Phillips Hall Cornell University Ithaca chamberlin engr sgi com Brian SmithDepartment Computer Science Upson Hall Cornell University Ithaca bsmith cornell edu ACM Copyright Notice Abstract The emergence audio and video data types databases will require new information retrieval methods adapted the specific characteristics and needs these data types effective and natural way querying musical audio database humming the tune song this paper system for querying audio database humming described along with scheme for representing the melodic information song relative pitch changes Relevant difficulties involved with tracking pitch are enumerated along with the approach followed and the performance results system indicating its effectiveness are presented Table ContentsIntroductionSystem ArchitectureTracking Pitch Hummed Queries Tracking pitchSearching the database Evaluation Robustness Performance Future directions and Related Work References Introduction Next generation databases will include image audio and video data addition traditional text and numerical data These data types will require query methods that are more appropriate and natural the type respective data For instance natural way query image database retrieve images based operations images sketches supplied input Similarly natural way querying audio database songs hum the tune song Such system would useful any multimedia database containing musical data providing alternative and natural way querying One can also imagine widespread use such system commercial music industry music radio and stations music stores and even for one personal use this paper address the issue how specify hummed query and report efficient query execution implementation using approximate pattern matching Our approach hinges upon the observation that melodic contour defined the sequence relative differences pitch between successive notes can used discriminate between melodies Handel indicates that melodic contour one the most important methods that listeners use determine similarities between melodies currently use alphabet three possible relationships between pitches and representing the situations where note above below the same the previous note which can pitch tracked quite robustly With the current implementation our system are successfully able retrieve most songs within notes Our database currently comprises collection all parts melody and otherwise from songs suggesting that three way discrimination would useful for finding particular song among private music collection but that higher resolutions will probably necessary for larger databases This paper organized follows The first section describes the architecture the current system The second section describes what pitch why important representing the melodic contents songs several techniques for tracking pitch tried and discarded and the method settled Next discuss pattern matching used the current implementation the database The last two sections describe our evaluation the current system and specify some future extensions that are considering incorporating the existing system System Architecture There are three main components the our system pitch tracking module melody database and query engine The architecture illustrated Figure Operation the system straight forward Queries are hummed into microphone digitized and fed into pitch tracking module The result contour representation the hummed melody fed into the query engine which produces ranked list matching melodies Figure System Architecture The database melodies was acquired processing public domain MIDI songs and stored flat file database Pitch tracking performed Matlab chosen for its built audio processing capabilities and the ease testing number algorithms within Hummed queries may recorded variety formats depending upon the platform specific audio input capabilities Matlab have experimented with bit Khz WAV format Pentium system and bit Khz format Sun Sparcstation The query engine uses approximate pattern matching algorithm described below order tolerate humming errors Tracking Pitch Hummed Queries This section describes how user input the system humming converted into sequence relative pitch transitions note the input classified one three ways note either the same the previous note higher than previous note lower than the previous note Thus the input converted into string with three letter alphabet For example the introductory theme Beethoven Symphony would converted into the sequence the first note ignored has previous pitch accomplish this conversion sequence pitches the melody must isolated and tracked This not straight forward sounds however there still considerable controversy over exactly what pitch The general concept pitch clear given note the pitch the frequency that most closely matches what hear Performing this conversion computer can become troublesome because some intricacies human hearing are still not understood For instance play the and harmonics some fundamental frequency actually hear the fundamental frequency not the harmonics even though the fundamental frequency not present This phenomenon was first discovered Schouten some pioneer investigations carried out from Schouten studied the pitch periodic sound waves produced optical siren which the fundamental was canceled completely The pitch the complex tone however was the same that prior the elimination the fundamental Since were interested tracking pitch humming examined methods for automatically tracking pitch human voice Before can estimate the pitch acoustic signal must first understand how this signal created which requires forming model sound production the source The vibrations the vocal cords voiced sounds are caused consequence forces that are exerted the laryngeal walls when air flows through the glottis the gap between the vocal cords Hess describes model the vocal cords proposed Hirano For the purposes this paper though sufficient know that the glottis repeatedly opens and closes thus providing bursts air through the vocal tract The vocal tract can modeled linear passive transmission system with transfer function add additional transfer function which takes into account the radiation the output impedance the vocal tract can approximately set zero the neutral position where the vocal tract can regarded uniform tube the resonances the vocal tract occur sound wavelengths With average value vocal tract length and sound propagation speed the frequencies these resonances will The frequencies are called formant frequencies The resulting sound that hear considered the convolution the excitation pulse created the glottis and the formant frequencies Therefore want model speech signal start with train excitation pulses shown figure For the formant frequencies use equation with This gives formant frequencies and Combining these frequencies and adding exponential envelope produces the formant structure shown figure convolving the train excitation pulses with the formant structure get synthesized pitch shown figure Figure Excitation signal used create the synthesized pitch The period the train excitations making the pitch Figure Formant structure created using and the formant frequencies Figure Synthesized pitch created convolving the train excitation pulses spaced and the formant structure Now that have model the human voice how can converted pitch The most prevalent view pitch that what hear pitch actually the frequency which the bursts air occur can track those bursts air can find the pitch the segment Tracking pitch tried three methods for tracking pitch Autocorrelation Maximum Likelihood Cepstrum Analysis Autocorrelation Autocorrelation one the oldest the classical pitch trackers Autocorrelation isolates and tracks the peak energy levels the signal which measure the pitch Referring back figure see that the signal peaks where the impulses occur Therefore tracking the frequency this peaks should give the pitch the signal order get the frequency these peaks can employ autocorrelation defined Unfortunately autocorrelation subject aliasing picking integer multiple the actual pitch and computationally complex found our implementation autocorrelation require approximately seconds for seconds KHz bit audio MHz pentium workstation Maximum Likelihood Maximum Likelihood modification Autocorrelation that increases the accuracy the pitch and decreases the chances aliasing Unfortunately the computational complexity this method makes autocorrelation look blindingly fast straight forward implementation Matlab takes approximately one hour evaluate seconds audio MHz Pentium workstation With some optimizations improved the performance approximately minutes per seconds audio but this still far too slow for our purposes Therefore discarded this method For detailed explanation this method the reader may refer Cepstrum Analysis Cepstrum analysis the definitive classical method pitch extraction For explanation the reader directed Oppenheim and Schafer original work more compact form found that this method did not give very accurate results for humming The output these methods can construed sequence frequency estimations for successive pitches the input convert these estimates into three step contour representation comparing each estimated pitch with the previous one our system adjacent pitches are considered the same they are within quarter step each other equal tempered musical scale but this parameter adjustable After analyzing the costs and benefits these methods decided use modified form autocorrelation for our implementation Searching the database Having described how the user input hummed tune converted into string letter alphabet now discuss our method for searching audio database Our method searching the database simple Songs the database are preprocessed convert the melody into stream characters and the converted user input the key compared with all the songs The pattern matching uses fuzzy search allow for errors within the matches These errors reflect the inaccuracies the way people hum well errors the representation the songs themselves For performing the key search within the database need efficient approximate pattern matching algorithm approximate mean that the algorithm should able take into account various forms errors Figure summarizes the various forms errors anticipated typical pattern matching scheme Figure Three forms anticipated errors with one mismatch The algorithm that adopted for this purpose described Baesa Yates and Perleberg This algorithm addresses the problem string matching with mismatches The problem consists finding all instances pattern string text string such that there are most mismatches characters that are not the same for each instance When mismatches have the simple string matching problem solvable time When every substring length qualifies match since every character can mismatched Each the errors the figure above corresponds worth mentioning that several algorithms have been developed that address the problem approximate string matching Running times have ranged from for the brute force algorithm log The algorithm that adopted offers better performance for average cases than most other algorithms The worst case for this algorithm occurs when the key consists occurrences single distinct character and contour representation song consists instances that character this case the running time However this neither common nor useful situation for our purposes the average case alphabet which each character equally likely occur the running time where the size the alphabet The database incorporates the key searching scheme using pattern matching techniques explained above envisioned the following design goals for the database For given query the database returns list songs ranked how well they matched the query not just one best match The number matches that the database should retrieve depends upon the error tolerance used during the key search This error tolerance could set one two possible ways either can user definable parameter the database can itself determine this parameter based for example heuristics that depends the length the key This design gives the user opportunity perform queries even the user not sure some notes within the tune From the results the query the user can identify the song interest the list too large the user can perform new query restricted search list consisting songs just retrieved consequence this scheme that the user can identify sets songs that contain similar melodies Evaluation This section describes the results experimental evaluation the system Our evaluation tested the tolerance the system with respect input errors whether from mistakes the user humming from problems with the pitch tracking Robustness The effectiveness this method directly related the accuracy with which pitches that are hummed can tracked and the accuracy the melodic information within the database Under ideal circumstances can achieve close accuracy tracking humming where ideal circumstances mean the user places small amount space between each note and hits each note strongly For this purpose humming short notes encouraged Even more ideal for the user aspirate the notes much possible perhaps going far voice vowel haaa haaa haaa have currently only experimented with male voices The evaluation database currently contains total songs Each song was converted from public domain General MIDI sources Melodies from different musical genres were included including both classical and popular music few simple heuristics were used cut down the amount irrelevant information from the data MIDI channel was ignored this reserved for percussion the General MIDI standard However the database still contains great deal information unrelated the main theme the melody Even with this limitation discovered that sequences pitch transitions were sufficient discriminate the songs consequence using fast approximate string matching algorithm search keys can matched with any portion the melody rather than just the beginning the size the database grows larger however this may not prove advantage Performance The version the pitch tracker using modified form autocorrelation takes between and seconds Sparc workstation process typical sequences hummed notes brute force search the database unsurprisingly shows linear growth with the size the database but remains below seconds for songs Sparc Therefore the search time currently effectively limited the efficiency the pitch tracker Contour representations for each song are currently stored separate files opening and closing files becomes significant overhead Performance could improved packing all the songs into one file using database manager plan modularize our code make independent any particular database schema Future directions and Related Work plan improve the performance and speed and robustness the pitch tracking algorithm using cubic spline wavelet The cubic spline wavelet peaks discontinuities the signal the air impulses One the most significant features the wavelet analysis that can computed time Currently the pitch tracker the slowest link our system using wavelets for this purpose has obvious advantages The pattern matching algorithm its present form does not discriminate the various forms pattern matching errors discussed earlier but only accounts for them collectively Some forms errors may more common than others depending upon the way people casually hum different tunes For example drop out errors reflected dropped notes tunes are more common than transposition duplication errors Tuning the key search that more tolerant drop out errors for example may yield better results The melodic contours the source songs are currently generated automatically from MIDI data which convenient but not optimal More accuracy and less redundant information could obtained entering the melodic themes for particular songs hand From research standpoint interesting question how extract melodies from complex audio signals Finally would like characterize the improvement gained increasing the resolution the relative pitch differences considering query alphabets three five and more possible relationships between adjacent pitches Early experiments using alphabet five relative pitch differences same higher much higher lower much lower verified that changes this sort are promising One drawback introducing more resolution that the user must somewhat more accurate the intervals they actually hum will explore the various tradeoffs involved important issue precisely where draw the line between notes that are little higher from the previous note and those that are much higher Previous work efficiently searching database melodies humming seems limited Mike Hawley briefly discusses method querying collection melodic themes searching for exact matches sequences relative pitches input MIDI keyboard have incorporated approximate pattern matching implementing actual audio database MIDI songs and most significantly allowing queries hummed Kageyama and Takashima published paper retrieving melodies using hummed melody Japanese journal but were unable locate translated version Footnotes The terms vocal folds and vocal chords are more less used synonyms the literature The modifications include low pass filtering and center clipping described Sondhi paper which help eliminate the formant structure that generally causes difficulty for autocorrelation based pitch detectors References Ricardo Baesa Yates and Chris Perleberg Fast and practical approximate string matching Combinatorial Pattern Matching Third Annual Symposium pages Ricardo Baesa Yates and Gonnet Fast string matching with mismatches Information and Computation Stephen Handel Listening Introduction the Perception Auditory Events The MIT Press Michael Jerome Hawley Structure out Sound PhD thesis MIT September Wolfgang Hess Pitch Determination Speech Signals Springer Verlag Berlin Heidelberg Hirano Structure and vibratory behavior the vocal folds Sawashima and Cooper editors Dynamic aspects speech production pages University Tokyo Press Rabiner Dubnowski and Schafer Real time digital hardware pitch detector IEEE Transactions Acoustics Speech and Signal Processing ASSP Feb Kageyama and Takashima melody retrieval method with hummed melody language Japanese Transactions the Institute Electronics Information and Communication Engineers August Landau and Vishkin Efficient string matching with mismatches Theoretical Computer Science Oppenheim speech analysis synthesis system based homomorphic filtering Acoustical Society America February Alan Oppenheim and Ronald Schafer Discrete time Signal Processing Prentice Hall Englewood Cliffs Plomp Aspects tone sensation Academic Press London Sondhi New methods pitch extraction IEEE Trans Audio Electroacoust Special Issue Speech Communication and Processing Part June James Wise James Caprio and Thomas Parks Maximum likelihood pitch estimation IEEE Trans Acoustics Speech Signal Processing October MIME Version Server CERN Date Monday Jan GMT Content Type text html Content Length Last Modified Wednesday Jan GMT Fun Stuff for Mark JohnstoneMark JohnstoneFun Stuff Here picture cat His name Maow Here are some his baby pictures Click here hear him say his name Here picture dream house Neuschwanstein was undergrad Computer Science Davis There was bar Davis that put your name plaque you drank different beers within months They called Around the World Beers Here with two best friends pointing our names spend spare time looking out the window office Cozumel Date Tue Jan GMT Server NCSA Content type text html Last modified Tue Apr GMT Content length Introduction Next Adaptive information retrievalUp Belew Research Statement Previous Belew Research Statement Introduction research focus characterization adaptive knowledge representations Issues representation have always played central role artificial intelligence well computer science and theories mind more generally But would argue that most this work has implicitly explicitly assumed that the representational language wielded manually humans encoding explicit characterization what they believe true the world Philosophical difficulties aside some modern machine learning techniques are capable automatically developing elaborate representations the world central result the mathematical theory induction that the selection appropriate language for representing learned concepts absolutely critical their identification therefore appropriate reconsider basic notions what makes for good knowledge representation with constraints imposed the learning process considered sine qua non along with those expressive adequacy valid inference etc more typically considered have found productive pursue this general interest through two more specific research projects The first these uses connectionist neural networks representation for the information retrieval problem This construction allows system learn more effective indexing representation free text documents simple product the browsing behaviors its users Second and more recently have investigated Genetic Algorithm GAs particularly interactions between neural networks and the both algorithmic techniques and models natural phenomena learning and evolution resp have found that work these two areas allows stereoscopic view encompassing both low level biological constraints and high level cultural issues that are the heart modern and cognitive science rik ucsd edu Date Mon Nov GMT Server NCSA Content type text html Last modified Mon Jan GMT Content length Programming Assignment UNIVERSITY WISCONSIN MADISON Computer Sciences DepartmentCS Spring Bart MillerProgramming Assignment Due Thursday February Processing There are several goals for this assignment First you will get chance familiarize yourself with the programming language Second you will learn how use some the facilities and library functions provided UNIX and Third you will write code that will useful for future assignments Your assignment write program that takes input file reads through line line some simple processing each line and then produces some output Your program called writer will invoked writer filename Your program will open file filename and process described below Program Details UNIX Manual Pages You should become familiar with the UNIX manuals and the online man facility This will great help working these assignments For example you wanted know how the fork create process system call works you would type man fork The UNIX manual organized into many sections You will mainly interested the first three sections Section for commands like Section for UNIX system calls calls directly the UNIX kernel such fork open read You will typically not use Section Most what you use will the UNIX library routines Section These are calls such atof strcpy More details about the online manual will given Discussion Sections Program Details Your program will first print out the name the input file Then will open file perhaps using the ifstream constructor read each line using the getline method and process them For more information input output you can read the book type man iostream man fstream Each line the form character string number number Each these three pieces will separated any number blank characters spaces tabs The numbers can have decimal points and fractional parts For each input line you will print standard output using cout line containing the character string the two numbers and the sum the two numbers The program will continue until the end the input file UNIX supplies several library routines make this assignment easier For example convert ASCII string number you can use atoi atof pronounced ASCII integer and ASCII float Use the man command look the details copy strings you can use strcpy compare strings you can use strcmp man string look these routines Command line parameters UNIX and make command line parameters easily available The main procedure your program should look like include iostream include fstream int main int argc char argv cout The command line processed the shell into list character strings one for each argument including the command name You can reference the integer argc tell you the number arguments The array argv the list strings you typed the command appearing the beginning this assignment argc would contain the value argv would contain the string writer and argv would contain the string filename Deliverables You should hand print out your program and output from your program the sample files that will provide will announce class where find these files Last modified Fri Jan CST bart 