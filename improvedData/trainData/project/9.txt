MIME Version Server CERN Date Wednesday Nov GMT Content Type text html Content Length Last Modified Saturday Mar GMT CUCS IBM Computer Science IBM Using the CUCS The machine called granita The eight nodes are granita through granita you have CUCS login you can use the Log into granita granita which designated interactive nodes Shells installed bsh csh ksh tcsh bash tsh you experience problems during your first login try remove operating system specific stuff from your shell configuration file for example AIX does not have the arch command you can use uname instead The file usr lpp bos README contains information about the release AIX used our addition man you can use InfoExplorer get more information about commands and usage the machine use this program set your remote display properly and type info Use poe run parallel jobs that use neither Active Massages nor Split and info man poe read more about poe Read below about how run parallel programs that use Active Messages Split More information about IBM hardware Cornell Theory Center Homegrown software general local software installed usr sww sure that usr sww bin and usr sww gnu bin are your path Split CSplit simple extension for parallel computing provides global address space though global pointers which can dereferenced just like regular pointers Split phase assignment statements allow programmers hide the latency remote accesses overlapping computation and communication Examples and makefiles can found sww split bench bench Before working with Split source sww etc setenv Users non csh shells should execute commands sww etc setenv non csh compile Split programs create Makefile look samples various directories sww split bench bench and type gmake You must include Make split your Makefile Split programs are run the same way Active Messages programs using amr scripts located usr sww bin For example run program foo processors type amr fooDebugging Split debug Split program the following steps need done include split debug insert splitc debug the first statement executed after splitc main compile and run your program described the previous section you will see the following message node most commonly run granita Debugging Split hit enter continue before hitting return log onto the node you want debug you want debug the master node open new shell the directory where your program source located run gdb inside gdb file run and then attach pid where pid the the proc the run process the node being debugged hit return node let computation proceed once you attached gdb run run stopped gdb and you can set breakpoints look stack frames etc Active MessagesActive Messages low overhead communication layer that offers high performance communication many parallel machines native Active Messages layer now available for the The main performance characteristics are one word round trip latency and asymptotic network bandwidth The library found usr sww lib libsp gam and the header file usr sww include Before running programs that use Active Messages source sww etc setenv and read usr sww gam doc RunningPrgms The amr scripts are located also usr sww bin MPIMPI popular message passing interface for portable parallel programs have implementation MPI based the MPICH library running over Active Messages the The header files are located usr sww include The library file located usr sww lib The easiest way compile and link with the script file ampicc which built top xlC ampicc foo foo You can also compile MPI programs with xlC gcc and split please look the examples the directory sww ampi examples for information about this MPI programs are run exactly like ordinary Active Messages programs amr foo sure source sww etc setenv Other software Software available granita and granita also includes tcsh bash Set xlC Fortran xlf xpdbx matlab GNU software installed sww gnu includes emacs gmake gcc gdb bison Some replicated locally usr local gnu bin Problems you experience difficulties with the please contact the czar Grzegorz Czajkowski MIME Version Server CERN Date Monday Jan GMT Content Type text html Content Length Last Modified Tuesday Dec GMT SSGRG Title PageWelcome the home page the Software Systems Generator Research Group Software system generators are tools for assembling complex software from interchangeable reusable components have developed GenVoca domain independent model software construction that defines systems algebraic equations where terms are components GenVoca has been successfully applied many domains including database management systems avionics and data structures Our results have demonstrated GenVoca generators can substantially improve productivity and application run time performance this your first visit and you have questions what the best place start take look Getting Started Research Group Members Getting Started Project Index Publications Software Distributions Related Web Pages UTCS General Members Don Batory ProfessorAngela Dappert StudentGuillermo Jimenez PerezPh StudentJeff ThomasPh StudentLance Tokuda StudentYannis Smaragdakis StudentK ShepherdResearch AssociateFormer Members and Graduation DatesDinesh DasPh May Millie VillarrealPh December Bart GeraciPostdoc Sep Sep Marty SirkinPh March Sankar DasariM May Overview Getting Started Software components that are used generators build software systems are not typical software modules Components encapsulate feature domain that many systems that domain may share For this possible components must encapsulate refinements many different parts classes software system Some these refinements require the manipulation metadata and reflective computations Thus likely that our basic approach goes beyond simple object orientation that large scale program transformations get feel for the basic issues involved and the breadth GenVoca applicability recommend the following papers for starters and read them this order Scalable Software Libraries Creating Reference Architectures The Design and Implementation Composition Validation and Subjectivity you are looking for specific results improvement productivity performance that can delivered generators the relationship our work design patterns check out order Reengineering Complex Application Lightweight DBMS Generator Memory Simulators and Software GeneratorsAutomated Software Evolution via Design Patterns For further information please contact Don Batory batory utexas edu Periodically release lecture notes for tutorial Software System Generators Architectures and Reuse When available lecture notes are distributed tar file containing compressed postscript files Last modified December Don Batory batory utexas edu Date Wed Nov GMT Server NCSA Content type text html Last modified Sun Sep GMT Content length Active MessagesActive Messages Updated Active Messages Interface Specification This interface generalizes previous active messages interfaces support broader spectrum applications such client server programs file systems operating systems well continuing support for parallel programs With recent advances local area networks networks workstations differ from massively parallel processors primarily packaging cost and software emphasis The key open architectural question the nature the network interface the communication architecture its hardware organization and logical abstraction basis for communication Active Messages represent RISC approach communication providing simple primitives rather than solutions which expose the full hardware performance higher layers Active Messages are intended serve substrate for building libraries that provide higher level communication abstractions and for generating communication code from parallel language compiler rather than for direct use programmers currently use Berkeley the Fast Communication layers sockets RPC and MPI the xFS parallel file system the Split and compilers well other libraries like Scalapack This project investigates Active Messages broad range hardware including dedicated message processor per node Intel Paragon and Myrinet FDDI interface the graphics bus high end workstation with Medusa and conventional interface the next generation LAN Sparc with Sahi ATM will thus demonstrate concepts construction and evaluate them real programs real machines The result will clearer understanding the communication architecture and trade offs the hardware organization the network interface Search for Papers Software Releases Lanai Active Messages People Professors David Culler Students Brent ChunCedric KrumbeinAlan MainwaringRich MartinChad Yoshikawa Last Modified Wed Jun PDT cal now Berkeley EDU Date Thu Nov GMT Server NCSA Content type text html Last modified Mon Mar GMT Content length EXODUS Project Home PageEXODUS Extensible Object Oriented Database System Toolkit NOTE Document under construction The Exodus project has been succeded the SHORE project but still provide minimal support for users Both the Exodus Storage Manager and compiler for the persistent programming language are available via ftp ftp wisc edu licenses are required more information needed contact exodus wisc edu Principal Investigators Mike Carey David DeWittSee Also Publications related EXODUS SHORE the successor EXODUS Latest Exodus Storage Manager and compiler Contributed software for the Storage Manager mailing list for Exodus users exodus all wisc edu Benchmark benchmark for OODBS Date Prepared April Michael Zwilling zwilling wisc edu 