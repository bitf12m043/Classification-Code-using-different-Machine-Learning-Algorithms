Date Tue Nov GMT Server Apache dev Connection close Content Type text html Last Modified Tue Sep GMT ETag Content Length Accept Ranges bytes Vision and Touch Guided ManipulationVision and Touch Guided Manipulation GroupMIT Artificial Intelligence Lab Nonlinear Systems Lab The Vision and Touch Guided Manipulation group the MIT Artificial Intelligence Lab conducts research wide variety topics related manipulator and end effector design dextrous manipulation adaptive nonlinear control and vision guided manipulation employ techniques from various fields including Mechanical Design Stability Theory Machine Learning Approximation Theory and Computer Vision The group headed Kenneth Salisbury mechanics and Professor Jean Jacques Slotine autonomy and vision Other groups the MIT Lab headed Ken are the Haptic Interfaces Group and the Robot Hands Group Professor Slotine also heads the Nonlinear Systems Laboratory The people and associated with the Vision and Touch Guided Manipulation Group are Brian Anthony touch sensing Mark Cannon wavelet networks graduated Brian Eberman system integration graduated Brian Hoffman active vision Jesse Hong coordination vision manipulation Akhil Madhani wrist hand mechanism uumlnter Niemeyer adaptive control and system integration Daniel Theobald visual processing Ichiro Watanabe machine learning Introduction Our Robots Our Research References Introduction our RobotsThe Whole Arm Manipulator The MIT Whole Arm Manipulator WAM Arm very fast force controllable robot arm designed Salisbury group the Lab The concept Whole Arm Manipulation was originally aimed enabling robots use all their surfaces manipulate and perceive objects the environment Central this concept and our group design efforts general has been focus controlling the forces interaction between robots and the environment permit this the WAM arm employs novel cable transmissions which are stiff low friction and backdrivable This turn permits lightweight design achieve good bandwidth force control while contact with the environment the arm design maximizes the lowest resonant frequency the system and employs impedance matching ratio between motor and arm masses This also enables the arm achieve high accelerations while moving free space Prof Slotine and his students have developed system architectures and control algorithms for both force controlled tasks and tasks requiring rapid and accurate free space motion The algorithms also provide fast and stable adaptation the arm large variations loads and environments The Talon new wrist hand mechanism has been developed and replaces previous forearm mounted system The new wrist hand known the Talon provides additional powered freedoms one for grasping forces and two for orientation The motors for the device are located the forearm minimize end effector mass and maximize its workspace The grasping mechanism comprised group fingers which move against group fingers such that two groups may made mesh together while encircling objects Finger inner surfaces are serrated provide for high contact friction against rough rock surfaces and curved enhance capturing large and small objects Fingers may deflect compliantly accomodate object geometry and finger deflections may sensed provide for monitoring grasp state also have studied the design miniature end effector suitable for grasping small rocks and cylindrical objects Similar spirit the Talon the new miniature end effector utilizes slightly different kinematics enlarge its feasible grasping volume The Fast Eye Gimbals more recent component our system our active vision system which comprised two resolution color CCD cameras with focal length lenses mounted two degree freedom gimbals have utilized cameras with narrow field view give higher resolution images typical objects This implies however that the cameras have actuated order pan and tilt that they can cover broad scenes leading active vision system and associated trade off between controller precision and image resolution narrowness field view The actuators which have implemented were designed our lab and are known the Fast Eye Gimbals FEGs The FEGs provide directional positioning for our cameras using similar drive mechanism the WAM The two joints are cable driven and have ranges motion degrees and degrees the base and upper joint axes respectively These two FEGs are currently strategically mounted ceiling rafters with wide baseline for higher position accuracy using stereo vision methods The independent nature the FEGs allow position each one different locations order vary the baseline orientation the coordinate frame well easily add additional cameras provide additional perspectives Introduction Our Robots Our Research References Research ProjectsRobust Grasping Unstructured Environments One our current projects funded NASA JPL develop fundamental understanding the problem combining real time vision and touch sensor data with robot control yield robust autonomous and semi autonomous grasping and grasp stabilization The research focused providing conceptual and experimental support planned and going NASA missions utilizing earth orbiting and planetary surface robotics have implemented high speed active vision system multi processor operating system and basic algorithms for acquisition and grasp stationary spherical and cylindrical objects using coordinated robotic vision touch sensing and control Preliminary experiments the tracking moving objects have also been completed Concurrently research into integrated wrist hand design used for performing sensor guided grasps and preliminary design for next generation miniature end effector are being completed Robotic Catching Free Flying Objects Another direction our research funded Fujitsu Furukawa and the Sloan Foundation accomplish real time robust catching free flying objects are currently focusing spherical balls various sizes are also experimenting with additional objects with different dynamic characteristics such sponge balls cylindrical cans and paper airplanes Our system uses low cost vision processing hardware for simple information extraction Each camera signal processed independently vision boards designed other members the MIT Laboratory the Cognachrome Vision Tracking System These vision boards provide with the center area major axis number pixels and aspect ratio the color keyed image The two Fast Eye Gimbals allow locate and track fast randomly moving objects using Kalman like filtering methods assuming fixed model for the behavior the motion Independent the tracking algorithms use least squares techniques fit polynomial curves prior object location data determine the future path With this knowledge hand can calculate path for the WAM match trajectories with the object accomplish catching and smooth object WAM post catching deceleration addition the basic least squares techniques for path prediction study experimentally nonlinear estimation algorithms give long term real time prediction the path moving objects with the goal robust acquisition The algorithms are based stable line construction approximation networks composed state space basis functions localized both space and spatial frequency initial step have studied the network performance predicting the path light objects thrown air Further application may include motion prediction objects rolling bouncing breaking rough terrains Some recent successful results for the application this network have been obtain catching sponge balls and even paper airplanes Click view WAM catching Click view WAM Airplane catching copy Photo courtesy Hank Morgan Introduction Our Robots Our Research References Partial List ReferencesAutonomous Rock Acquisition Theobald Hong Madhani Hoffman Niemeyer Cadapan Slotine Salisbury Proceedings the AIAA Forum Advanced Development Space Robotics Madison Wisconsin August Experiments Hand Eye Coordination Using Active Vision Hong and Slotine Proceedings the Fourth International Symposium Experimental Robotics ISER Stanford California June July Robotic Catching and Manipulation Using Active Vision Hong Thesis Department Mechanical Engineering MIT September Space Frequency Localized Basis Function Networks for Nonlinear System Estimation and Control Cannon and Slotine Neurocomputing Adaptive Visual Tracking and Gaussian Network Algorithms for Robotic Catching Kimura and Slotine DSC Vol Advances Robust and Nonlinear Control Systems Winter Annual Meeting the ASME Anaheim November Experiments Robotic Catching Hove and Slotine Proceedings the American Control Conference Vol Boston June Performance Adaptive Manipulator Control Niemeyer and Slotine International Journal Robotics Research December Preliminary Design Whole Arm Manipulation System WAM Salisbury Townsend Eberman DiPietro Proceedings IEEE International Conference Robotics and Automation Philadelphia April The Effect Transmission Design Force Controlled Manipulator Performance Townsend PhD Thesis Department Mechanical Engineering MIT April See also MIT Lab Technical Report Whole Arm Manipulation Salisbury Proceedings International Symposium Robotics Research Santa Cruz August Design and Control Two Axis Gimbal System for Use Active Vision Swarup Thesis Dept Mechanical Engineering MIT Cambridge High Speed Low Latency Portable Vision Sensing System Wright SPIE September Introduction Our Robots Our Research References Maintainer jesse mit edu Comments wam mit edu Last Updated Mon Aug EDT jesse mit edu copy All rights reserved 