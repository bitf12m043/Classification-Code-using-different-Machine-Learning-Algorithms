Date Tue Dec GMT Server NCSA Content type text html Last modified Tue Jan GMT Content length Research Summary Shun Tak LeungResearch SummaryMy current research centers compiler directed program restructuring techniques improve the cache locality array accesses loops Specifically studying the use array restructuring optimize for spatial locality and parallel execution reduce false sharing have also worked improving the performance and applicability runtime parallelization earlier project advisor Prof John Zahorjan For list publications these and other subjects click here Array RestructuringMy current research focuses compiler directed program restructuring techniques improve cache locality Specifically studying the use array restructuring optimize array accesses loops work combines the development algorithms within formal framework implementation prototype compiler and extensive experimentation with benchmark loops shows how array restructuring can applied automatically and efficiently wide class applications Array restructuring approach enhancing the locality array accesses loops These accesses are targeted because they account for major portion the memory traffic many array based scientific computations Moreover since they are typically executed many times the effort spent optimizing few them the program text can yield huge benefits execution performance Under the array restructuring approach the compiler analyzes how each array accessed and lays out the array appropriately according the access pattern trivial example two dimensional array accessed rows the compiler may decide store row major order whereas accessed columns the compiler would choose column major storage contrast traditionally the storage order fixed for all arrays forcing programmers concerned about program performance write programs such way that the data access pattern matches the fixed data layout far possible research array restructuring motivated part the observation that array restructuring many ways complements loop restructuring alternative approach that changes the execution order loop iterations rather than the storage order array elements but has received much less attention For example array restructuring can easily applied complicated loops that may hamper many automatic loop restructuring techniques Also array restructuring can improve spatial locality without jeopardizing temporal locality whereas loop restructuring affects both types locality However while loop restructuring has been widely studied relatively little known about how apply array restructuring automatically and efficiently research shows how array restructuring can applied automatically and efficiently wide class programs This not only provides new set techniques complement existing loop restructuring techniques but also produces insights and experience that will believe contribute integrated approach combining the strengths the two Specifically work makes four contributions framework represent array transformations algorithms automate array restructuring within this framework prototype compiler implement these algorithms and experiments evaluate their effectiveness FrameworkI have formulated framework represent general class array transformations this framework array restructured the original array replaced another array the restructured array that contains the same elements but different order Correspondence between elements these two arrays defined invertible linear transformation their index vectors other words instead using index vector find element the original array apply linear transformation that vector and use the result find the corresponding element the restructured array may appear that the extra transformation imposes significant overhead but fact this not the case for the following reason Traditionally the memory address array element linear function the indices This condition the basis most compiler optimizations for reducing indexing overhead Applying extra linear transformation the index vectors does not invalidate this condition and therefore does not entail any extra indexing overhead property essential for the efficiency and thus viability array restructuring AlgorithmsI have developed algorithms within this framework for the key steps array restructuring algorithms solve these problems with simple linear algebraic techniques the common case where the array indices are linear functions loop variables These algorithms have also been adapted deal with more general access patterns well The first step array restructuring analyze the access pattern each array and choose transformation optimize for locality this can represent each array access linear mapping relate the access locality properties the mapping mathematical properties and select linear transformation effect desired changes the mapping and thus the access itself Second need compute the set elements accessed the loop determine which elements the restructured array must contain This achieved representing loop and array bounds sets linear inequalities geometrically convex polyhedra which are manipulated with known mathematical techniques Third elements the restructured array have laid out memory such way that each element can efficiently located given its indices This non trivial problem for example the case two dimensional arrays general array transformations may cause rows the restructured array have different lengths and start different column positions violating the basic assumptions the traditional way laying out array elements solution apply further transformation that reduces the problem more traditional form without jeopardizing the locality improvement achieved prior transformations Finally the program code transformed appropriately Transformed array accesses are generated from their linear mapping representations computed earlier PrototypeI have implemented prototype compiler perform array restructuring automatically based the SUIF compiler from Stanford University SUIF itself comprises number compiler passes over intermediate program representation implementation consists array restructuring pass about lines added after SUIF own optimization passes and runtime library about lines and ResultsI have performed series experiments using the NASA kernels from the SPEC benchmarks and other loops from the literature The experiments were designed study how array restructuring affects performance for range problem sizes well how compares and interacts with various loop restructuring techniques They were carried out four different platforms representing two types machines single processor workstations Alpha based DEC and PowerPC based IBM and shared memory multiprocessors based SGI Power Challenge and Kendall Square Research KSR which has proprietary processor Experimental results have been encouraging DEC workstation array restructuring decreased the execution time most the loops over some cases and increased none The average improvement was including loops for which the compiler did not apply array restructuring all This occurred for wide range problem sizes Results for IBM were similar both platforms performance improved because array restructuring led better spatial locality For the same reason performance KSR and SGI Power Challenge showed similar improvements for execution any number processors Moreover several cases where false sharing had existed array restructuring removed this performance bottleneck producing performance benefits that increased with the number processors Experiments also showed that both applicability and performance array restructuring techniques complemented many common loop restructuring techniques including those performed production quality optimizing compiler from SGI was successfully applied loops that these techniques could not automatically transform achieved comparable often better performance where both were applicable the few cases where did not perform well simple forms loop restructuring would have sufficed again suggesting that loop and array restructuring are complementary More can found technical report more concise version here Runtime ParallelizationRuntime parallelization two step strategy parallelizing loops that may contain substantial parallelism but cannot parallelized compile time because insufficient dependence information parallelize such loop the compiler generates two code fragments the inspector and the executor run time the inspector computes parallel schedule the iterations based dependence information not available compile time The executor performs the iterations parallel using this schedule research runtime parallelization has touched both the inspector and the executor have proposed two ways speed the inspector This work appeared the Fourth ACM SIGPLAN Symposium Principles and Practice Parallel Programming The paper also available technical report have also studied various forms the executor improve its performance and extend its applicability complex dependence patterns This research reported technical report experiments the KSR shared address space multiprocessor show that false sharing and poor spatial locality could seriously degrade executor performance have proposed and experimentally evaluated two simple techniques address these problems restructuring arrays according the parallel execution schedule This research reported technical report Shun Tak Leung Department Computer Science Engineering University Washington Box Seattle Email shuntak washington edu Fax Last modified January 