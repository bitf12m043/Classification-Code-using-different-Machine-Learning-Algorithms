Date Tue Dec GMT Server NCSA Content type text html ZPL Overview ZPL OverviewZPL new array programming language designed for engineering and scientific programs that would previously have been written Fortran Because its design goals were machine independence and high performance ZPL programs run fast both sequential and parallel computers Because implicitly parallel the programmer does NOT express the parallelism ZPL programs are simple and easy write this page ZPL described high level answering the obvious questions about and its implementation The page concludes with ZPL fact sheet What array language scalar languages like Fortran Pascal and Ada operations apply only single values expresses the addition two numbers such languages adding two arrays requires indexing and looping for ltn for ltn FORTRAN This need loop and index perform operations arrays both tedious and error prone ZPL operations are generalized apply both scalars and arrays Thus expresses the sum two scalars and were declared scalars arrays they were declared arrays When applied arrays the operations act corresponding elements illustrated the loops above Indeed when the ZPL compiler encounters the statement and and are two dimensional arrays generates code that effectively the same the loops shown above array language therefore simplifies programming Why create new array language Programming languages are created all the time computer science but the widespread adoption new programming language extremely rare event The recent use object oriented languages shows that does occur from time time Nevertheless the cardinal rule you want your research applied practice not invent new language much better extend enhance existing language that has established user base Parallelism the opinion ZPL designers phenomenon that cannot fully exploited through the medium existing programming languages even existing array languages such Fortran and APL Greenlaw Case after case demonstrates that effective parallel computations are typically accomplished through paradigm shift away from sequential solutions This shift which more frequently discontinuous than the term shift implies inhibited languages designed for sequential computers new language can avoid these problems and facilitate the paradigm shift Further choosing its primitives carefully new research parallel compilation can apply ZPL has been designed from first principles see below realize these goals Isn programming with arrays hard Programmers unfamiliar with them may find array languages little different initially but technical programmers meaning scientists engineers mathematicians statisticians etc will generally find them natural Indeed many science and engineering problems are formulated way that perhaps closer array languages than scalar languages trivial example consider the computation the mean and standard deviation Sample items The textbook definitions these quantities are ZPL and sigma are computed single statements which mirror the definitions Sample Mean sigma sqrt sqr Sample Std deviation The array Sample contains the items and the operator sums them direct translation The computation analogous and illustrates several features ZPL including subtracting from each item Sample this called promoting scalar array promoting scalar function sqr array function applying each item the array etc These properties ZPL promotion are simply programming language terminology for natural concepts technically educated people already know After using ZPL for few months graduate student research assistant civil engineering rebelled when told program again High performance widely claimed why believe for ZPL For some languages high performance part the name For ZPL high performance part the description backed experimental evidence Dikaiakos Lewis Lin This evidence takes different forms but always relative other means achieving good performance For example Fortran programs run sequentially programs customized parallel platforms with user specified communication are regarded reasonable ways establish good baselines since these usually represent the best alternatives achieving good performance The evidence ZPL high performance derives from several types experiments Lin Lin one which will mentioned here SIMPLE fluid dynamics program developed Lawrence Livermore National Laboratories benchmark new computers and compilers The computation has been widely used the study parallel computing parallel version the original line Fortran program was developed Gannon and Panetta Gannon high quality variable grain version written requires approximately lines Lee This program customized the Intel Paragon and the Kendal Square Research KSR was compared the line ZPL program for SIMPLE Lin The speedups these programs are shown for experiments involving iterations size problem The experiments indicate that the high level ZPL performs well the low level program for these two machines Other information suggests that similar behavior can expected any MIMD parallel computer Lin Why does ZPL have such good performance ZPL does not have parallel directives other forms explicit parallelism Instead exploits the fact that when programmers describe computations terms arrays many scalar operations must performed implement the array operations This implied computation can parceled out different processors get concurrency Thus the parallelism comes simply from the semantics the array operations What does ZPL was designed from first principles mean ZPL actually the dataparallel sublanguage more powerful parallel programming language called Advanced ZPL Lin ZPL ZPL fully general parallel language for power users programmers with extreme performance requirements and the sophistication use more demanding technology ZPL not yet implemented and its completion not expected for least two years Advanced ZPL known previously Orca implements programming model called Phase Abstractions Griswold The Phase Abstractions model capable expressing task parallelism pipelined parallelism and other parallel programming paradigms not just data parallelism The Phase Abstractions programming model built and generalizes parallel machine model called the CTA Snyder The CTA abstracts the family multiple instruction multiple data MIMD computers The two models are the mechanism which the benefits and costs parallel computation are succinctly conveyed ZPL programmers Snyder The models balance the conflicting requirements that write efficient code the programmer needs make decisions based how the program will executed but machine independent portable the programmer must avoid reliance any particular machine facilities The relationships this approach others have been described Snyder and feasibility studies indicate that the approach works Lin The Phase Abstractions programming model recognizes three different programming levels Process level composition instructions Phase level composition processes into parallel algorithm Problem level composition phases solve the overall application The letter name this highest problem solving programming level motivates the language name Learning the Language simple introduction some the basic ZPL concepts available online Walk through ZPL program tutorial introduction programming ZPL available the ZPL Programmer Guide The ZPL Language Manual defines the language specifics Sample programs and scientific research papers are also available Writing Your First Program Perhaps the simplest way write and run ZPL program YOUR Unix machine use the Web Compiler You paste ZPL program your own one ours into window and click compile The program packaged and sent machine the CSE Department compiled into ANSI and returned you make this file will result executable that can run your sequential computer Parallel Use ZPL run parallel computer ZPL must first targeted that parallel computer This operation that typically NOT performed ZPL applications programmers but straightforward for parallel computer systems administrators The present platforms which ZPL runs are Intel ParagonCray Research DKendal Square Research KSR PVM running scientific workstationSequential Unix platforms For information targeting new platform click here Once ZPL has been targeted your type parallel computer and the libraries installed your facility you are ready use ZPL parallel NOT necessary install the ZPL compiler your workstation because for the near term all ZPL compilation will performed the University Washington This assist rapidly disseminating compiler improvements the user community You can have stale version the compiler However provide some software that you WILL want install your workstation which will simplify this remote compilation and give you the convenience similar compiling locally learn more about running ZPL parallel click here ZPL Fact SheetName ZPL short for the level Programming Language see discussion programming model above Origin ZPL was designed and implemented the Orca Project the Computer Science and Engineering Department the University Washington Type ZPL uses the array abstraction implement dataparallel programming model standalone subset Advanced ZPL History Implementation the ZPL compiler began March generated code approximately months later ZPL will officially released during the fourth quarter Approach ZPL translated into conventional abstract syntax tree representation which program analysis and optimizations are performed ANSI code generated the object code This program machine independent and implements certain operations abstract form This code compiled using the native compiler the target machine with custom libraries this second compilation the abstract operations are customized the specific platform Team The creators ZPL are Brad Chamberlain Sung Eun Choi Marios Dikaiakos George Forman Christopher Lewis Calvin Lin Larry Snyder and Derrick Weathersby with assistance from Ruth Anderson and Kurt Partridge Funding The foundational research for the ZPL compiler was funded part the Office Naval Research The compiler itself was funded part the Advanced Research Projects Agency References Dikaiakos Dikaiakos Lin Manoussaki and Woodward The Portable Parallel Implementation Two Novel Mathematical Biology Algorithms ZPL the Int Conference Supercomputing Gannon Gannon and Panetta Restructuring Simple for the CHiP Architecture Parallel Computing Greenlaw Greenlaw and Snyder Achieving Speedups for APL SIMD Distributed Memory Machine Int Parallel Programming Griswold Griswold Harrison Notkin and Snyder Scalable Abstractions for Parallel Programming Proc Distributed Memory Computer Conference IEEE Lee Lee Lin and Snyder Programming SIMPLE for Parallel Portability Languages and Compilers for Parallel Computing Uptal Banerjee David Gelernter Alexamdru Nicolau and David Padua eds Lewis Lewis Lin Snyder and Turkiyyah Portable Parallel Body Solver the SIAM Conference Parallel Processing for Scientific Computing Lin Lin The portability parallel programs across MIMD computers Dissertation University Washington Lin Lin and Snyder comparison programming models for shared memory multiprocessors Proceedings the International Conference Parallel Processing Lin Lin and Snyder SIMPLE Performance Results ZPL Languages and Compilers for Parallel Computing Pingali Banerjee Gelernter Nicolau and Padua eds Lin Lin Snyder Anderson Chamberlain Choi Forman Lewis and Weathersby ZPL HPF Comparison Performance and Programming Style CSE Technical Report University Washington Snyder Snyder Foundations Practical Parallel Programming Languages Ferrante and Hey eds Portability and performance for parallel processing John Wiley and Sons Ltd Snyder Snyder Type Architecture Shared Memory and the Corollary Modest Potential Annual Review Computer Science Snyder Snyder Experimental Validation Models Parallel Computation Hofmann and van Leeuwen Lecture Notes Computers Science Springer Verlag ZPL CSE zpl info washington edu 