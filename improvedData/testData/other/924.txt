Date Tue Dec GMT Server NCSA Content type text html Converting Thread Level Parallelism Instruction Level Parallelism via Simultaneous Multithreading Converting Thread Level Parallelism Instruction Level Parallelism via Simultaneous Multithreading Jack Susan Eggers Joel Emer Henry Levy Rebecca Stamm and Dean Tullsen achieve high performance contemporary computer systems rely two forms parallelism instruction level parallelism ILP and thread level parallelism TLP Wide issue superscalar processors exploit ILP executing multiple instruction from signel program single cycle Multiprocessors exploit TLP executing different threads parallel different processors Unfortunately both parallel processing styles statically partition processor resources thus preventing them from adapting dynamically changing levels TLP and ILP program With insufficient TLP processors will idle with insufficient ILP multiple issue hardware superscalar wasted This paper explores parallel processing alternative architecture simultaneous multithreading SMT which allows multiple threads compete for and share all the processor resources every cycle The most compelling reason for running parallel applications SMT processor its ability use thread level parallelism and instruction level parallelism interchangeably permitting multiple threads share the processor functional units simultaneously the processor can use both ILP and TLP tolerate variations parallelism When program has only single thread all the SMT processor resources can dedicated that thread when more TLP exists this parallelism can compensate for lack per thread ILP this work examine two alternative chip parallel architectures enabled the greatly increased chip densities expected the near future compare SMT and small scale chip multiprocessors their ability exploit both ILP and TLP First identify the hardware bottlenecks that prevent multiprocessors from efficiently exploiting ILP Then show that because its dynamic resource sharing SMT avoids these inefficiencies and benefits from being able run more threads single processor The use TLP especially advantageous when per thread ILP limited The ease adding additional thread contexts SMT relative addition additional processors allows simultaneous multithreading expose more parallelism further increasing processor utilization and attaining average speedup versus four processor single chip multiprocessor with comparable execution resources also assess how the memory hierarchy affected the use additional thread level parallelism show that inter thread interference and the increased memory requirements have small impacts total program performance and not inhibit significant program speedups Submitted for publication July get the PostScript file click here jlo washington edu 