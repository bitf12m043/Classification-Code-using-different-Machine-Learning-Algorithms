Date Tue Dec GMT Server NCSA Content type text html Last modified Tue Oct GMT Content length Improving Balanced Scheduling with Compiler Optimizations that Increase Instruction Level Parallelism Improving Balanced Scheduling with Compiler Optimizations that Increase Instruction Level Parallelism Jack and Susan Eggers Traditional list schedulers order instructions based optimistic estimate the load latency imposed the hardware and therefore cannot respond variations memory latency caused cache hits and misses non blocking architectures contrast balanced scheduling schedules instructions based estimate the amount instruction level parallelism the program scheduling independent instructions behind loads based what the program can provide rather than what the implementation stipulates the best case cache hit balanced scheduling can hide variations memory latencies more effectively Since its success depends the amount instruction level parallelism the code balanced scheduling should perform even better when more parallelism available this study combine balanced scheduling with three compiler optimizations that increase instruction level parallelism loop unrolling trace scheduling and cache locality analysis Using code generated for the DEC Alpha the Multiflow compiler simulated non blocking processor architecture that closely models the Alpha Our results show that balanced scheduling benefits from all three optimizations producing average speedups that range from across the optimizations More importantly because its ability tolerate variations load interlocks improves its advantage over traditional scheduling Without the optimizations balanced scheduled code average times faster than that generated traditional scheduler with them its lead increases Proceedings the ACM SIGPLAN Conference Programming Language Design and Implementation Jolla California June pages get the PostScript file click here jlo washington edu 